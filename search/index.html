<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <!-- JQuery (used for bootstrap and jekyll search) -->
    <script src="/assets/js/jquery-3.2.1.min.js" ></script>
    
    <!-- Main JS (navbar.js and katex_init.js)-->
    <script defer=true src="/assets/js/main.min.js"></script>
    
    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">

    <link rel="stylesheet" href="/assets/css/mermaid.css">

    <!--Favicon-->
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- Canonical -->
    <link rel="canonical" href="http://localhost:4000/search/">

    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="小白" href="http://localhost:4000///feed.xml"/>

    <!-- Font Awesome -->
    <!-- <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" type="text/css" href="/assets/css/font-awesome.min.css">

    <!-- Google Fonts -->
    
    <link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css"> 
    

    <!-- KaTeX 0.8.3 -->
    
    <!--<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.8.3/katex.min.js"></script> -->
    <link rel="stylesheet" type="text/css" href="/assets/css/katex.min.css">
    <script src="/assets/js/katex.min.js">
    </script>
    

    <!-- Google Analytics -->
    
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-89143952-2', 'auto');
        ga('send', 'pageview');

    </script>
    

    <!-- Baidu Analytics -->
    
    <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = 'https://hm.baidu.com/hm.js?2a8326534823f90fa4eef816aea2ef08';
          var s = document.getElementsByTagName("script")[0]; 
          s.parentNode.insertBefore(hm, s);
        })();
    </script>        
    
    
    <!-- seo tags -->
    <!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Search | 小白成长史</title>
<meta name="generator" content="Jekyll v3.7.3" />
<meta property="og:title" content="Search" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="php mysql 分布式 区块链" />
<meta property="og:description" content="php mysql 分布式 区块链" />
<link rel="canonical" href="http://localhost:4000/search/" />
<meta property="og:url" content="http://localhost:4000/search/" />
<meta property="og:site_name" content="小白成长史" />
<script type="application/ld+json">
{"description":"php mysql 分布式 区块链","@type":"WebPage","url":"http://localhost:4000/search/","headline":"Search","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <!-- Manual seo tags -->
    <!--
    <title>Search | 小白</title>
    <meta name="description" content="">
    -->
</head>

  <body>
    <header class="site-header">
    
    <!-- Logo and title -->
	<div class="branding">
		<a href="/">
			<img class="avatar" src="/assets/img/photo.jpeg" alt=""/>
		</a>

		<h1 class="site-title">
			<a href="/">小白</a>
		</h1>
	</div>
    
    <!-- Toggle menu -->
    <nav class="clear">
    <a id="pull" class="toggle" href="#">
    <i class="fa fa-bars fa-lg"></i>
    </a>
    
    <!-- Menu -->
    <ul>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
         
        
        
        
        <li class="separator">
            |
        </li>
        <li>
            <a class="clear" href="/search">
                <i class="fa fa-search" aria-hidden="true"></i>
            </a>
        </li>
        
        
        <li class="separator">
            |
        </li>
        <li>
            <a class="clear" href="/tags">
                <i class="fa fa-tags" aria-hidden="true"></i>
            </a>
        </li>
        
        
    </ul>
        
	</nav>
</header>

    <div class="content">
      <article class="feature-image">
  <header id="main" style="background-image: url('/assets/img/pexels/search-map.jpeg')">
    <h1 id="Search" class="title">
        Search
    </h1>
    
    
    <h2 class="subtitle">What are you looking for?</h2>
    
      
  </header>
  <section class="post-content"><!-- Html Elements for Search -->
<input type="text" id="search-input" placeholder="Enter keywords..." class="search-bar">
<br>
<br>
<ul id="results-container"></ul>

<section>
    <!-- Script pointing to jekyll-search.js -->
    <script src="/assets/js/simple-jekyll-search.min.js" type="text/javascript"></script>

    <script type="text/javascript">
        SimpleJekyllSearch({
            searchInput: document.getElementById('search-input'),
            resultsContainer: document.getElementById('results-container'),
            json: [
                    
                     
                        {
                          "title"    : "mysql系列教程 - innodb锁",
                          "category" : "",
                          "tags"     : " MYSQL",
                          "url"      : "/2018/06/23/mysql-innodb-lock.html",
                          "date"     : "June 23, 2018",
                          "excerpt"  : "lock和latch锁分为两种类型 lock 和 latch ，它们之间的差异如下表所示：            -      lock      latch                  对象      事务      线程              保护      数据库内容      内存数据结构              持续时间      整个事务过程      临界资源              模式      行锁、表锁、意向锁      读写锁、互斥量         ...",
                          "content"  : "lock和latch锁分为两种类型 lock 和 latch ，它们之间的差异如下表所示：            -      lock      latch                  对象      事务      线程              保护      数据库内容      内存数据结构              持续时间      整个事务过程      临界资源              模式      行锁、表锁、意向锁      读写锁、互斥量              死锁      通过waits-for graph、time out等机制进行死锁检测和处理      无死锁检测与处理机制。仅通过应用程序加锁的顺序保证无死锁情况发生              存在于      Lock Manager 的哈希表中      每个数据结构的对象中      下面讲到的锁都是针对lock来讲。锁类型  共享锁（S） ：允许事务读一行数据。  排他锁（x） ：允许事务删除或更新一行数据。以下情况会加锁：            锁类型      加锁情况                  行S      读取行记录              行X      增删改行记录              表S      全表扫描              表X      修改表结构      对行做增删改操作如果事务T1已经获得行r的共享锁，那么事务T2可以立即获得行r的共享锁，这种就叫做锁兼容。如果事务T3想获得行r的排他锁，就必须等待T1、T2释放它们的共享锁，这种就叫做锁不兼容。共享锁与排他锁的兼容性如下表所示：            -      X      S                  X      不兼容      不兼容              S      不兼容      兼容      innodb支持多粒度锁定，即可以同时存在行锁和表锁。并支持另外一种锁方式，称为意向锁。因为数据本身也分为以下几层数据库 &gt; 表 &gt; 页 &gt; 行所以，如果如果对某一层加锁，就需要对其所有上层加意向锁，意向锁也分为意向共享锁（IS），意向排他锁（IX）。  对行加共享锁前，会对表加意向共享锁；对行加排他锁前，会对表加意向排他锁。表级意向锁和表级锁的兼容性如下表所示：            -      IS      IX      S      X                  IS      兼容      兼容      兼容      不兼容              IX      兼容      兼容      不兼容      不兼容              S      兼容      不兼容      兼容      不兼容              X      不兼容      不兼容      不兼容      不兼容      例如对记录r加X锁之前，必须对表1加上IX锁，如果已经有事务对表1进行了S表锁，由于不兼容，需要等待表锁操作完成。查看锁innodb1.0版本之前，用户只能通过以下命令查看当前数据库锁的请求。SHOW FULL PROCESSLIST;SHOW ENGINE INNODB STATUS;从innodb1.0版本开始，在INFORMATION_SCHEMA架构中添加了表INNODB_TRX、INNODB_LOCKS、INNODB_LOCK_WAITS。通过这3张表，用户可以更简单的监控当前事务并分析可能存在的锁问题。INNODB_TRX表由以下字段组成：| 字段 | 说明 || :- | :- || trx_id | InnoDB存储引擎内部唯一的事务ID| trx_state | 当前事务的状态。| trx_started | 事务的开始时间。| trx_requested_lock_id | 等待事务的锁ID。如trx_state的状态为LOCK WAIT,那么该值代表当前的等待之前事务占用锁资源的ID.若trx_state不是LOCK WAIT,则该值为NULL。| trx_wait_started | 事务等待开始的时间。| trx_weight | 事务的权重，反映了一个事务修改和锁住的行数。在InnoDB存储引擎中，当发生死锁需要回滚时，InnoDB存储会选 择该值最小的进行回滚。| trx_mysql_thread_id | Mysql中的线程ID,SHOW PROCESSLIST显示的结果。| trx_query | 事务运行的sql语句。实际例子：通过state可以观察到trx_id为730FEE的事务当前正在运行，而trx_id为731F4的事务处于LOCK WAIT状态，且运行的SQL语句是select * from parent lock in shar mode。该表只是显示了当前运行的innoDB事务，并不能准确的判断锁的一些情况。如果需要查看锁，还需要访问 INNODB_LOCKS。INNODB_LOCKS表由如下字段组成：            字段      说明                  lock_id      锁的ID。              lock_trx_id      事务ID。              lock_mode      锁的模式。              lock_type      锁的类型，表锁还是行锁。              lock_table      要加锁的表。              lock_index      锁的索引。              lock_space      InnoDB存储引擎表空间的ID号。              lock_page      被锁住的页的数量。若是表锁，则该值为NULL。              lock_rec      被锁住的行的数量。若是表锁，则该值为NULL。              lock_data      被锁住的行的主键值。当是表锁，该值为NULL。      按照上面的例子，继续查看表INNODB_LOCKS。用户可以清楚的看到当前锁的信息，trx_id为730FEE的事务想表parent加了一个X的行锁。ID为7311F4的事务想表parent申请了一个S的行锁。lock_data都是1，申请相同的资源，因此会有等待。这样可以解析INNODB_TRX为什么一个事务的trx_state是RUNNING另一个是LOCK WAITLE另外需要注意的是，发现lock_data并不是可信的值。例如当用户运行一个范围查找时，lock_data可能只返回第一行的主键值。与此同时，如果当前资源被锁住了。若锁住的页因为InnoDB存储引擎缓冲池的容量，导致页从缓冲池中被刷出，则查看INNODB_LOCKS表时，该值同样显示为NULL。即InnoDB存储引擎不会从磁盘进行再一次的查找在通过INNODB_LOCKS馋看了每张表上锁的情况后，用户可以判断由此引发的等待情况。当事务较小时，用户就可以人为地、直观地进行判断了。但是当事务量非常大，其中锁和等待也时常发生。这个时候就不容易判断。但是可以通过INNODB_LOCK_WAITS可以很直观的反应出当前事务的等待。INNODB_LOCK_WAIT表由以下字段组成：            字段      说明                  requesting_trx_id      申请锁资源的事务ID              requesting_lock_id      申请的锁的ID。              blocking_trx_id      阻塞的事务的ID。              blocking_lock_id      阻塞的事务的ID。      按照上面的例子，运行如下查询：通过上述的SQL语句，用户可以清楚的看到哪个事务阻塞了另一个事务。当然这只是给出了事务和锁ID，如果需要，用户可以根据表INNODB_TRX、INNODB_LOCKS、INNODB_LOCK_WAITS得到更为直观的详细信息。例如，用户可以执行如下联合查询一致性非锁定读一致性的非锁定读是指innodb存储引擎通过行多版本控制的方式来读取当前执行时间数据库中的行数据。就是说如果读取的行已被加了X锁，这时不需要等待X锁的释放，而是读取行记录的快照数据（即该行的之前版本的数据），该实现是通过undo段来实现，而undo本身是用来在事务中回滚数据，因此快照数据本身是没有额外的消耗的。读取快照是不需要上锁的，因为没有事务需要对历史数据进行修改操作。由于读取的行数据必须不能被其他事务修改，所以对使用场景有要求，在事务隔离级别READ COMMIT（提交读）和REPEATABLE READ（可重复读，默认）下，innodb使用一致性非锁定读。  在READ COMMIT隔离级别下，对于快照数据，一致性非锁定读总是读取被锁定行的最新一份快照。  在REPEATABLE READ隔离级别下，对于快照数据，一致性非锁定读总是读取事务开始时的行数据版本。自增长与锁当对含有自增长的计数器的表进行插入操作时，这个计数器会被初始化，执行如下的语句来得到计数器的值：select max(auto_inc_col) from test for update;插入操作会根据这个自增长的计数器值加1赋予自增长列。这个实现方式称作为AUTO-INC Locking。这种锁采用一种特殊的表锁机制，为了提高插入的性能，锁不是在一个事务完成后才释放，而是在完成对自增长值插入的SQL语句后立即释放。虽然AUTO-INC Locking从一定程度上提高了并发插入的效率，但还是存在一些性能问题。首先，对于有自增长值的列的并发插入性能较差，事务必须等待前一个插入的完成。其次，对于INSERT—-SELECT的大数据量的插入会影响插入的性能，因为另一个事务中的插入会被阻塞。从MySQL5.1.22版本开始，InnoDB存储引擎引擎中提供了一种轻量级互斥量的自增长实现机制，这种机制大大提高了自增长值插入的性能。并且从该版本开始，InnoDB存储引擎提供了一个参数innodb_autoinc_lock_mode来控制自增长的模式，该参数的默认值为1.在继续讨论新的自增长方式实现方式之前，需要对自增长的插入进行分类，如下：            插入类型      说明                  insert-like      指所有的插入语句，如insert，replace，insert—select,replace—select,load data等              simple inserts      指能在插入之前就确定插入行数的语句。这些语句包含insert、replace等，需要注意的是：simple inserts不包含insert—on duplicater key update这类SQL语句              bulk inserts      指在插入之前不能确定得到插入行数的语句，如insert—select，replace–select，load data              mixed-mode inserts      指插入中有一部分的值是自增长的，有一部分是确定的，如INSERT INTO t1(c1,c2) VALAUES (1,’a’),(null,’b’),(5,’e’); 或者指 INSERT … ON DUPLICATE KEY UPDATE 这类sql语句。      接着来分析参数innodb_autoinc_lock_mode，如下表所示：            innodb_autoinc_lock_mode      说明                  0      这是MySQL5.1.22版本之前自增长的实现方式，即通过表锁的AUTO-INC Locking方式，因为有了新的自增长实现方式，0这个选项不应该是新版用户的首选项              1      这是该参数的默认值。对于simple inserts，该值会用互斥量去对内存中的计数器进行累加的操作，对于bulk inserts，还是使用传统表锁的AUTO-INC Locking方式。在这种配置下，如果不考虑回滚操作，对于自增长列的增长还是连续的，并且在这种方式下，statement-based方式的replication还是能很好地工作。需要注意的是，如果已经使用AUTO-INC Locking方式去产生自增长的值，而这时需要进行simple inserts的操作时，还是需要等待AUTO-INC Locking的释放              2      在这个模式下，对于所有的insert-like自增长的产生都是通过互斥量，而不是通过AUTO-INC Locking的方式，显然这时性能最高的方式。然而会带来一定的问题。因为并发插入的存在，在每次插入时，自增长的值可能不是连续的。最重要的是，基于Statment-base replication会出现问题。因此，使用这个模式，任何时候都应该使用row-base replication，这样才能保证最大的并发性能及replication主从数据的一致。      外键和锁对于外键值的插入或更新，首先需要查询父表中的记录，即select父表，但是对父表的select操作，不是使用一致性非锁定锁，因为这样会发生数据不一致的问题，因此这时使用的是select … lock in share mode方式，即主动对父表加一个S锁，如果这时父表上已经加了X锁，子表的操作会被阻塞。"
                        } ,
                     
                        {
                          "title"    : "fabric - 架构&amp;执行流程",
                          "category" : "",
                          "tags"     : " 超级账本, fabric",
                          "url"      : "/2018/05/27/hyperledger-fabric.html",
                          "date"     : "May 27, 2018",
                          "excerpt"  : "本文简单讲述fabric架构&amp;执行流程，帮助同学快速理解&amp;入门。架构IdentityIdentity，也就是身份管理，Fabric是目前为止在设计上最贴近联盟链思想的区块链。联盟链考虑到商业应用对安全、隐私、监管、审计、性能的需求，提高准入门槛，成员必须被许可才能加入网络。Fabric成员管理服务为整个区块链网络提供身份管理、隐私、保密和可审计的服务。成员管理服务通过公钥基础设施PKI和去中心化共识机制使得非许可的区块链变成许可制的区块链。Smart ContractFab...",
                          "content"  : "本文简单讲述fabric架构&amp;执行流程，帮助同学快速理解&amp;入门。架构IdentityIdentity，也就是身份管理，Fabric是目前为止在设计上最贴近联盟链思想的区块链。联盟链考虑到商业应用对安全、隐私、监管、审计、性能的需求，提高准入门槛，成员必须被许可才能加入网络。Fabric成员管理服务为整个区块链网络提供身份管理、隐私、保密和可审计的服务。成员管理服务通过公钥基础设施PKI和去中心化共识机制使得非许可的区块链变成许可制的区块链。Smart ContractFabric的智能合约smart contract称为链码chaincode，是一段代码，它处理网络成员所同意的业务逻辑。和以太坊相比，Fabric链码和底层账本是分开的，升级链码时并不需要迁移账本数据到新链码当中，真正实现了逻辑与数据的分离。链码可采用Go、Java、Node.js语言编写。链码被编译成一个独立的应用程序，fabric用Docker容器来运行chaincode，里面的base镜像都是经过签名验证的安全镜像，包括OS层和开发chaincode的语言、runtime和SDK层。一旦chaincode容器被启动，它就会通过gRPC与启动这个chaincode的Peer节点连接。Ledger | TranscationsFabric使用建立在HTTP/2上的P2P协议来管理分布式账本。采取可插拔的方式来根据具体需求来设置共识协议，比如PBFT，Raft，PoW和PoS等。Ledger如上图所示，账本Ledger主要包含两块：blockchain和state。blockchain就是一系列连在一起的block，用来记录历史交易。state对应账本的当前最新状态，它是一个key-value数据库，Fabric默认采用Level DB, 可以替换成其他的Key-value数据库，如Couch DB。举个例子。我们采用区块链实现一个弹珠交易的系统。我们开发了一个Chaincode,每个弹珠有以下几个属性：Name, owner, color, size.  可以定义一个JSON对象，用name做KEY, JSON对象做Value，存储在Level DB或者CouchDB中。transcationFabric上的transction交易分两种，部署交易和调用交易。  部署交易    把Chaincode部署到peer节点上并准备好被调用，当一个部署交易成功执行时，Chaincode就被部署到各个peer节点上。好比把一个web service或者EJB部署到应用服务器上的不同实例上。  调用交易    客户端应用程序通过Fabric提供的API调用先前已部署好的某个chaincode的某个函数执行交易，并相应地读取和写入KV数据库，返回是否成功或者失败。APIs, Events, SDKsFabric提供API方便应用开发，对服务端的ChainCode，目前支持用Go、Java或者Node.js开发。对客户端应用，Fabric目前提供Node.js和Java SDK。未来计划提供Python 和Go SDK，Fabric还提供RESTAPI。对于开发者，还可以通过CLI快速去测试chaincode，或者去查询交易状态。在区块链网络里，节点和chaincode会发送events来触发一些监听动作，方便与其他外部系统的集成。执行流程首先理解几个概念  MSP    MSP(Membership Service Provider), 这类节点主管区块链网络中其他的节点的授权，准入，踢除。通过给不同节点颁发证书的方式，授予不同类型的节点相应的权限。  Ordering Node    中文可以称作排序节点。通常在一个网络中至少有一个或多个排序节点，这类节点负责 按照指定的算法，将交易进行排序，并返回给Committing Peer。其并不关心具体的交易细节。  Endorsing Peer    这类节点的主要负责接收交易请求，验证这笔交易之后，并做一些预处理之后，并将签名后的数据传回给客户端。  Committing Peer    这类节点做是区块链网络中的全节点，它们需要记录完整的区块信息，并且验证每笔交易的正确性，是最终将交易打包进区块链的节点。交易的执行路程如下1.首先从客户端发起一笔交易提交到Endorsing Peer，进行预处理。2.预处理通过之后，将签名数据，传回给客户端。3.客户端发起请求，将收到的签名数据传给Ordering Node。4.Ordering Node对交易进行排序，然后传给Committing Peer。5.Committing Peer这里将排序好的交易进行验证，并打包，通过指定的共识算法达成一致，形成新的区块。6.最后将交易结果返回给客户端。ps:中间过程的每一步，都伴随着权限的验证。会根据MSP颁发的证书，进行判断。参考Hyperledger Fabric 1.0架构及原理超级账本之——Fabric"
                        } ,
                     
                        {
                          "title"    : "fabric - Node.js SDK",
                          "category" : "",
                          "tags"     : " 超级账本, fabric",
                          "url"      : "/2018/05/27/hyperledger-fabric-sdk.html",
                          "date"     : "May 27, 2018",
                          "excerpt"  : "这里使用官方示例。如果之前没有部署过环境，先按照fabric入门（一）安装进行环境部署。安装首先进入示例目录cd fabric-samples/balance-transfer/有两种方法可以运行示例：方法一（推荐）1.通过docker启动网络docker-compose -f artifacts/docker-compose.yaml up2.安装fabric-client和fabric-ca-client的node模块npm install3.启动nodePORT=4000 node ...",
                          "content"  : "这里使用官方示例。如果之前没有部署过环境，先按照fabric入门（一）安装进行环境部署。安装首先进入示例目录cd fabric-samples/balance-transfer/有两种方法可以运行示例：方法一（推荐）1.通过docker启动网络docker-compose -f artifacts/docker-compose.yaml up2.安装fabric-client和fabric-ca-client的node模块npm install3.启动nodePORT=4000 node app方法二直接执行runApp.shcd fabric-samples/balance-transfer./runApp.sh这个方法你必须安装jq网络配置由于我们是使用docker，所以我们需要修改项目的网络配置。修改network-config.yaml，把里面的localhost修改为docker实际ip地址，这里我的IP为192.168.99.100---## The network connection profile provides client applications the information about the target# blockchain network that are necessary for the applications to interact with it. These are all# knowledge that must be acquired from out-of-band sources. This file provides such a source.#name: \"balance-transfer\"## Any properties with an \"x-\" prefix will be treated as application-specific, exactly like how naming# in HTTP headers or swagger properties work. The SDK will simply ignore these fields and leave# them for the applications to process. This is a mechanism for different components of an application# to exchange information that are not part of the standard schema described below. In particular,# the \"x-type\" property with the \"hlfv1\" value example below is used by Hyperledger Composer to# determine the type of Fabric networks (v0.6 vs. v1.0) it needs to work with.#x-type: \"hlfv1\"## Describe what the target network is/does.#description: \"Balance Transfer Network\"## Schema version of the content. Used by the SDK to apply the corresponding parsing rules.#version: \"1.0\"## The client section will be added on a per org basis see org1.yaml and org2.yaml##client:## [Optional]. But most apps would have this section so that channel objects can be constructed# based on the content below. If an app is creating channels, then it likely will not need this# section.#channels:  # name of the channel  mychannel:    # Required. list of orderers designated by the application to use for transactions on this    # channel. This list can be a result of access control (\"org1\" can only access \"ordererA\"), or    # operational decisions to share loads from applications among the orderers.  The values must    # be \"names\" of orgs defined under \"organizations/peers\"    orderers:      - orderer.example.com    # Required. list of peers from participating orgs    peers:      peer0.org1.example.com:        # [Optional]. will this peer be sent transaction proposals for endorsement? The peer must        # have the chaincode installed. The app can also use this property to decide which peers        # to send the chaincode install request. Default: true        endorsingPeer: true        # [Optional]. will this peer be sent query proposals? The peer must have the chaincode        # installed. The app can also use this property to decide which peers to send the        # chaincode install request. Default: true        chaincodeQuery: true        # [Optional]. will this peer be sent query proposals that do not require chaincodes, like        # queryBlock(), queryTransaction(), etc. Default: true        ledgerQuery: true        # [Optional]. will this peer be the target of the SDK's listener registration? All peers can        # produce events but the app typically only needs to connect to one to listen to events.        # Default: true        eventSource: true      peer1.org1.example.com:        endorsingPeer: false        chaincodeQuery: true        ledgerQuery: true        eventSource: false      peer0.org2.example.com:        endorsingPeer: true        chaincodeQuery: true        ledgerQuery: true        eventSource: true      peer1.org2.example.com:        endorsingPeer: false        chaincodeQuery: true        ledgerQuery: true        eventSource: false    # [Optional]. what chaincodes are expected to exist on this channel? The application can use    # this information to validate that the target peers are in the expected state by comparing    # this list with the query results of getInstalledChaincodes() and getInstantiatedChaincodes()    chaincodes:      # the format follows the \"cannonical name\" of chaincodes by fabric code      - mycc:v0## list of participating organizations in this network#organizations:  Org1:    mspid: Org1MSP    peers:      - peer0.org1.example.com      - peer1.org1.example.com    # [Optional]. Certificate Authorities issue certificates for identification purposes in a Fabric based    # network. Typically certificates provisioning is done in a separate process outside of the    # runtime network. Fabric-CA is a special certificate authority that provides a REST APIs for    # dynamic certificate management (enroll, revoke, re-enroll). The following section is only for    # Fabric-CA servers.    certificateAuthorities:      - ca-org1    # [Optional]. If the application is going to make requests that are reserved to organization    # administrators, including creating/updating channels, installing/instantiating chaincodes, it    # must have access to the admin identity represented by the private key and signing certificate.    # Both properties can be the PEM string or local path to the PEM file. Note that this is mainly for    # convenience in development mode, production systems should not expose sensitive information    # this way. The SDK should allow applications to set the org admin identity via APIs, and only use    # this route as an alternative when it exists.    adminPrivateKey:      path: artifacts/channel/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/keystore/5890f0061619c06fb29dea8cb304edecc020fe63f41a6db109f1e227cc1cb2a8_sk    signedCert:      path: artifacts/channel/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts/Admin@org1.example.com-cert.pem  # the profile will contain public information about organizations other than the one it belongs to.  # These are necessary information to make transaction lifecycles work, including MSP IDs and  # peers with a public URL to send transaction proposals. The file will not contain private  # information reserved for members of the organization, such as admin key and certificate,  # fabric-ca registrar enroll ID and secret, etc.  Org2:    mspid: Org2MSP    peers:      - peer0.org2.example.com      - peer1.org2.example.com    certificateAuthorities:      - ca-org2    adminPrivateKey:      path: artifacts/channel/crypto-config/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp/keystore/1995b11d6573ed3be52fcd7a5fa477bc0f183e1f5f398c8281d0ce7c2c75a076_sk    signedCert:      path: artifacts/channel/crypto-config/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp/signcerts/Admin@org2.example.com-cert.pem## List of orderers to send transaction and channel create/update requests to. For the time# being only one orderer is needed. If more than one is defined, which one get used by the# SDK is implementation specific. Consult each SDK's documentation for its handling of orderers.#orderers:  orderer.example.com:    url: grpcs://192.168.99.100:7050    # these are standard properties defined by the gRPC library    # they will be passed in as-is to gRPC client constructor    grpcOptions:      ssl-target-name-override: orderer.example.com      grpc-max-send-message-length: 15    tlsCACerts:      path: artifacts/channel/crypto-config/ordererOrganizations/example.com/orderers/orderer.example.com/tls/ca.crt## List of peers to send various requests to, including endorsement, query# and event listener registration.#peers:  peer0.org1.example.com:    # this URL is used to send endorsement and query requests    url: grpcs://192.168.99.100:7051    # this URL is used to connect the EventHub and registering event listeners    eventUrl: grpcs://192.168.99.100:7053    grpcOptions:      ssl-target-name-override: peer0.org1.example.com    tlsCACerts:      path: artifacts/channel/crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt  peer1.org1.example.com:    url: grpcs://192.168.99.100:7056    eventUrl: grpcs://192.168.99.100:7058    grpcOptions:      ssl-target-name-override: peer1.org1.example.com    tlsCACerts:      path: artifacts/channel/crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/ca.crt  peer0.org2.example.com:    url: grpcs://192.168.99.100:8051    eventUrl: grpcs://192.168.99.100:8053    grpcOptions:      ssl-target-name-override: peer0.org2.example.com    tlsCACerts:      path: artifacts/channel/crypto-config/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt  peer1.org2.example.com:    url: grpcs://192.168.99.100:8056    eventUrl: grpcs://192.168.99.100:8058    grpcOptions:      ssl-target-name-override: peer1.org2.example.com    tlsCACerts:      path: artifacts/channel/crypto-config/peerOrganizations/org2.example.com/peers/peer1.org2.example.com/tls/ca.crt## Fabric-CA is a special kind of Certificate Authority provided by Hyperledger Fabric which allows# certificate management to be done via REST APIs. Application may choose to use a standard# Certificate Authority instead of Fabric-CA, in which case this section would not be specified.#certificateAuthorities:  ca-org1:    url: https://192.168.99.100:7054    # the properties specified under this object are passed to the 'http' client verbatim when    # making the request to the Fabric-CA server    httpOptions:      verify: false    tlsCACerts:      path: artifacts/channel/crypto-config/peerOrganizations/org1.example.com/ca/ca.org1.example.com-cert.pem    # Fabric-CA supports dynamic user enrollment via REST APIs. A \"root\" user, a.k.a registrar, is    # needed to enroll and invoke new users.    registrar:      - enrollId: admin        enrollSecret: adminpw    # [Optional] The optional name of the CA.    caName: ca-org1  ca-org2:    url: https://192.168.99.100:8054    httpOptions:      verify: false    tlsCACerts:      path: artifacts/channel/crypto-config/peerOrganizations/org2.example.com/ca/ca.org2.example.com-cert.pem    registrar:      - enrollId: admin        enrollSecret: adminpw    # [Optional] The optional name of the CA.    caName: ca-org2然后重新启动你的node服务。测试注册和enroll新的user在org1curl -s -X POST http://localhost:4000/users -H \"content-type: application/x-www-form-urlencoded\" -d 'username=Jim&amp;orgName=org1'输出{  \"success\": true,  \"secret\": \"RaxhMgevgJcm\",  \"message\": \"Jim enrolled Successfully\",  \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\"}创建channelcurl -s -X POST \  http://localhost:4000/channels \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\" \  -d '{	\"channelName\":\"mychannel\",	\"channelConfigPath\":\"../artifacts/channel/mychannel.tx\"}'ps: authorization Bearer后跟之前的enroll的tokenorg1加入channelcurl -s -X POST \  http://localhost:4000/channels/mychannel/peers \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\" \  -d '{	\"peers\": [\"peer1\",\"peer2\"]}'安装链码curl -s -X POST \  http://localhost:4000/chaincodes \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\" \  -d '{	\"peers\": [\"peer1\",\"peer2\"],	\"chaincodeName\":\"mycc\",	\"chaincodePath\":\"github.com/example_cc\",	\"chaincodeVersion\":\"v0\"}'初始化链码curl -s -X POST \  http://localhost:4000/channels/mychannel/chaincodes \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\" \  -d '{	\"chaincodeName\":\"mycc\",	\"chaincodeVersion\":\"v0\",	\"args\":[\"a\",\"100\",\"b\",\"200\"]}'交易curl -s -X POST \  http://localhost:4000/channels/mychannel/chaincodes/mycc \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\" \  -d '{	\"fcn\":\"move\",	\"args\":[\"a\",\"b\",\"10\"]}'查询curl -s -X GET \  \"http://localhost:4000/channels/mychannel/chaincodes/mycc?peer=peer1&amp;fcn=query&amp;args=%5B%22a%22%5D\" \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\"根据区块号码查询curl -s -X GET \  \"http://localhost:4000/channels/mychannel/blocks/1?peer=peer1\" \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\"根据transactionID查询交易curl -s -X GET http://localhost:4000/channels/mychannel/transactions/TRX_ID?peer=peer1 \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\"ps：这里的后的字符为invoke返回的transactionID获取ChainInfocurl -s -X GET \  \"http://localhost:4000/channels/mychannel?peer=peer1\" \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\"获取已安装的chaincodecurl -s -X GET \  \"http://localhost:4000/chaincodes?peer=peer1&amp;type=installed\" \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\"获取已实例化的chaincodecurl -s -X GET \  \"http://localhost:4000/chaincodes?peer=peer1&amp;type=instantiated\" \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\"获取channelscurl -s -X GET \  \"http://localhost:4000/channels?peer=peer1\" \  -H \"authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE0OTQ4NjU1OTEsInVzZXJuYW1lIjoiSmltIiwib3JnTmFtZSI6Im9yZzEiLCJpYXQiOjE0OTQ4NjE5OTF9.yWaJhFDuTvMQRaZIqg20Is5t-JJ_1BP58yrNLOKxtNI\" \  -H \"content-type: application/json\""
                        } ,
                     
                        {
                          "title"    : "fabric - chaincode(链码)",
                          "category" : "",
                          "tags"     : " 超级账本, fabric",
                          "url"      : "/2018/05/27/hyperledger-fabric-chaincode.html",
                          "date"     : "May 27, 2018",
                          "excerpt"  : "Chaincode是一段由Go语言编写（支持其他编程语言，如Java），并能实现预定义接口的程序。Chaincode运行在一个受保护的Docker容器当中，与背书节点的运行互相隔离。Chaincode可通过应用提交的交易对账本状态初始化并进行管理。一段chaincode通常处理由网络中的成员一致认可的业务逻辑，故我们很可能用“智能合约”来代指chaincode。一段chiancode创建的（账本）状态是与其他chaincode互相隔离的，故而不能被其他chaincode直接访问。不过，如果...",
                          "content"  : "Chaincode是一段由Go语言编写（支持其他编程语言，如Java），并能实现预定义接口的程序。Chaincode运行在一个受保护的Docker容器当中，与背书节点的运行互相隔离。Chaincode可通过应用提交的交易对账本状态初始化并进行管理。一段chaincode通常处理由网络中的成员一致认可的业务逻辑，故我们很可能用“智能合约”来代指chaincode。一段chiancode创建的（账本）状态是与其他chaincode互相隔离的，故而不能被其他chaincode直接访问。不过，如果是在相同的网络中，一段chiancode在获取相应许可后则可以调用其他chiancode来访问它的账本。每个chaincode程序都必须实现 chiancode接口 ，接口中的方法会在响应传来的交易时被调用。特别地，Init（初始化）方法会在chaincode接收到instantiate（实例化）或者upgrade(升级)交易时被调用，进而使得chaincode顺利执行必要的初始化操作，包括初始化应用的状态；Invoke（调用）方法会在响应invoke（调用）交易时被调用以执行交易。开发存放位置你需要为chaincode应用创建一个位于$GOPATH/src/目录下的子目录。mkdir -p $GOPATH/src/sacc &amp;&amp; cd $GOPATH/src/sacc编写代码这里我们写一个简单的资产管理chaincode1.创建文件touch sacc.go2.引入必要依赖package mainimport (    \"fmt\"    \"github.com/hyperledger/fabric/core/chaincode/shim\"    \"github.com/hyperledger/fabric/protos/peer\")3.初始化实现Init函数// Init is called during chaincode instantiation to initialize any data.func (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {})下面，我们将调用ChaincodeStubInterface.GetStringArgs函数来获取Init所需的参数，并进行有效性检查。在我们的例子中，我们希望传入参数是一组键值对。// Init is called during chaincode instantiation to initialize any// data. Note that chaincode upgrade also calls this function to reset// or to migrate data, so be careful to avoid a scenario where you// inadvertently clobber your ledger’s data!func (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {  // Get the args from the transaction proposal  args := stub.GetStringArgs()  if len(args) != 2 {    return shim.Error(\"Incorrect arguments. Expecting a key and a value\")  }}接下来，既然我们已经确定调用有效，那么我们就将初始状态放心地存入账本。为了实现该目标，我们将调用ChaincodeStubInterface并以键值为参数传入。如果一切正常，那么我们会收到表明初始化成功的peer.Response返回对象。// Init is called during chaincode instantiation to initialize any// data. Note that chaincode upgrade also calls this function to reset// or to migrate data, so be careful to avoid a scenario where you// inadvertently clobber your ledger’s data!func (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {  // Get the args from the transaction proposal  args := stub.GetStringArgs()  if len(args) != 2 {    return shim.Error(\"Incorrect arguments. Expecting a key and a value\")  }  // Set up any variables or assets here by calling stub.PutState()  // We store the key and the value on the ledger  err := stub.PutState(args[0], []byte(args[1]))  if err != nil {    return shim.Error(fmt.Sprintf(\"Failed to create asset: %s\", args[0]))  }  return shim.Success(nil)}4.调用chaincode首先，添加Invoke函数签名。// Invoke is called per transaction on the chaincode. Each transaction is// either a 'get' or a 'set' on the asset created by Init function. The 'set'// method may create a new asset by specifying a new key-value pair.func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {}就如上述Init函数一样，我们需要调用ChaincodeStubInterface来获取参数。Invoke函数所需的传入参数正是应用想要调用的chaincode的名称。在我们的例子中，我们的应用只有两个简单的功能函数：set和get;前者允许对资产的数值进行设定;后者允许获取当前资产的状态。我们先调用ChaincodeStubInterface.GetFunctionAndParameters来获取chaincode应用所需的函数名与参数。// Invoke is called per transaction on the chaincode. Each transaction is// either a 'get' or a 'set' on the asset created by Init function. The Set// method may create a new asset by specifying a new key-value pair.func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {    // Extract the function and args from the transaction proposal    fn, args := stub.GetFunctionAndParameters()}下面，我们将使set与get这两个函数名正式生效，并调用这些chaincode应用函数，经由shim.Success或shim.Error函数返回一个合理的响应。这两个shim成员函数可以将响应序列化为gRPC protobuf消息。// Invoke is called per transaction on the chaincode. Each transaction is// either a 'get' or a 'set' on the asset created by Init function. The Set// method may create a new asset by specifying a new key-value pair.func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {    // Extract the function and args from the transaction proposal    fn, args := stub.GetFunctionAndParameters()    var result string    var err error    if fn == \"set\" {            result, err = set(stub, args)    } else {            result, err = get(stub, args)    }    if err != nil {            return shim.Error(err.Error())    }    // Return the result as success payload    return shim.Success([]byte(result))}5.调用chaincode应用如上文所述，我们的chaincode应用实现了两个函数，并可以被Invoke函数调用。下面我们就来真正实现这些函数。注意，就像上文一样，我们调用chaincode shim API中的ChaincodeStubInterface.PutState和ChaincodeStubInterface.GetState函数来访问账本。// Set stores the asset (both key and value) on the ledger. If the key exists,// it will override the value with the new onefunc set(stub shim.ChaincodeStubInterface, args []string) (string, error) {    if len(args) != 2 {            return \"\", fmt.Errorf(\"Incorrect arguments. Expecting a key and a value\")    }    err := stub.PutState(args[0], []byte(args[1]))    if err != nil {            return \"\", fmt.Errorf(\"Failed to set asset: %s\", args[0])    }    return args[1], nil}// Get returns the value of the specified asset keyfunc get(stub shim.ChaincodeStubInterface, args []string) (string, error) {    if len(args) != 1 {            return \"\", fmt.Errorf(\"Incorrect arguments. Expecting a key\")    }    value, err := stub.GetState(args[0])    if err != nil {            return \"\", fmt.Errorf(\"Failed to get asset: %s with error: %s\", args[0], err)    }    if value == nil {            return \"\", fmt.Errorf(\"Asset not found: %s\", args[0])    }    return string(value), nil}7.整合全部代码终于到了写main函数的最后关头，它将调用shim.Start函数。下面是包含整个chaincode程序的代码：package mainimport (    \"fmt\"    \"github.com/hyperledger/fabric/core/chaincode/shim\"    \"github.com/hyperledger/fabric/protos/peer\")// SimpleAsset implements a simple chaincode to manage an assettype SimpleAsset struct {}// Init is called during chaincode instantiation to initialize any// data. Note that chaincode upgrade also calls this function to reset// or to migrate data.func (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {    // Get the args from the transaction proposal    args := stub.GetStringArgs()    if len(args) != 2 {            return shim.Error(\"Incorrect arguments. Expecting a key and a value\")    }    // Set up any variables or assets here by calling stub.PutState()    // We store the key and the value on the ledger    err := stub.PutState(args[0], []byte(args[1]))    if err != nil {            return shim.Error(fmt.Sprintf(\"Failed to create asset: %s\", args[0]))    }    return shim.Success(nil)}// Invoke is called per transaction on the chaincode. Each transaction is// either a 'get' or a 'set' on the asset created by Init function. The Set// method may create a new asset by specifying a new key-value pair.func (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {    // Extract the function and args from the transaction proposal    fn, args := stub.GetFunctionAndParameters()    var result string    var err error    if fn == \"set\" {            result, err = set(stub, args)    } else { // assume 'get' even if fn is nil            result, err = get(stub, args)    }    if err != nil {            return shim.Error(err.Error())    }    // Return the result as success payload    return shim.Success([]byte(result))}// Set stores the asset (both key and value) on the ledger. If the key exists,// it will override the value with the new onefunc set(stub shim.ChaincodeStubInterface, args []string) (string, error) {    if len(args) != 2 {            return \"\", fmt.Errorf(\"Incorrect arguments. Expecting a key and a value\")    }    err := stub.PutState(args[0], []byte(args[1]))    if err != nil {            return \"\", fmt.Errorf(\"Failed to set asset: %s\", args[0])    }    return args[1], nil}// Get returns the value of the specified asset keyfunc get(stub shim.ChaincodeStubInterface, args []string) (string, error) {    if len(args) != 1 {            return \"\", fmt.Errorf(\"Incorrect arguments. Expecting a key\")    }    value, err := stub.GetState(args[0])    if err != nil {            return \"\", fmt.Errorf(\"Failed to get asset: %s with error: %s\", args[0], err)    }    if value == nil {            return \"\", fmt.Errorf(\"Asset not found: %s\", args[0])    }    return string(value), nil}// main function starts up the chaincode in the container during instantiatefunc main() {    if err := shim.Start(new(SimpleAsset)); err != nil {            fmt.Printf(\"Error starting SimpleAsset chaincode: %s\", err)    }}编译chaincodego get -u --tags nopkcs11 github.com/hyperledger/fabric/core/chaincode/shimgo build --tags nopkcs11测试1.安装必要的docker镜像如果之前没有部署过环境，可以直接按照fabric入门（一）安装步骤进行安装。2.安装Hyperledger Fabric样例下面进入到安装好的fabric-samples下的chaincode-docker-devmode目录。cd chaincode-docker-devmode3.安装chaincode现在请在chaincode-docker-devmode目录下面打开三个独立的终端。1号终端docker-compose -f docker-compose-simple.yaml up上述指令启动了一个带有SingleSampleMSPSoloorderer profile的网络，并将节点在“开发者模式”下启动。它还启动了另外两个容器：一个包含chaincode运行环境;另一个是CLI命令行，可与chaincode进行交互。创建并加入channel（管道）的指令内嵌于CLI容器中，所以我们下面马上跳转到chaincode调用部分。2号终端docker exec -it chaincode bash执行完上述指令后，您应该会看到如下内容：root@d2629980e76b:/opt/gopath/src/chaincode#（此时您已经进入chaincode容器）下面编译您的chaincode:cd saccgo build现在运行chaincode：CORE_PEER_ADDRESS=peer:7052 CORE_CHAINCODE_ID_NAME=mycc:0 ./sacc3号终端即便您处于–peer-chaincodedev模式，安装chaincode这一步仍必不可少，这样生命周期系统chaincode才能正常进行检查。也许这一步会在日后的–peer-chaincodedev模式中省去。下面我们将进入CLI容器进行chaincode调用。docker exec -it cli bashpeer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 04.初始化(3号终端)peer chaincode instantiate -n mycc -v 0 -c '{\"Args\":[\"a\",\"10\"]}' -C myc5.交易(3号终端)现在我们执行一次将a的值设为20的调用：peer chaincode invoke -n mycc -c '{\"Args\":[\"set\", \"a\", \"20\"]}' -C myc最后查询a的值，我们会看到20。peer chaincode query -n mycc -c '{\"Args\":[\"query\",\"a\"]}' -C myc"
                        } ,
                     
                        {
                          "title"    : "搭建以太坊私有网络(ubuntn)",
                          "category" : "",
                          "tags"     : " 区块链, 以太坊",
                          "url"      : "/2018/05/18/eth-private-network-ubuntu.html",
                          "date"     : "May 18, 2018",
                          "excerpt"  : "mac版请参考搭建以太坊私有网络安装node&amp;npmsudo apt-get install nodejs-legacysudo apt-get install npm# 升级npmsudo npm install npm@latest -g# 升级nodesudo npm i -g n# 安装最新版可执行# sudo n stable# 由于mist限制node不能大于9，所以只升级到9sudo n 9安装gogeth 需要1.9版本以上sudo add-apt-reposito...",
                          "content"  : "mac版请参考搭建以太坊私有网络安装node&amp;npmsudo apt-get install nodejs-legacysudo apt-get install npm# 升级npmsudo npm install npm@latest -g# 升级nodesudo npm i -g n# 安装最新版可执行# sudo n stable# 由于mist限制node不能大于9，所以只升级到9sudo n 9安装gogeth 需要1.9版本以上sudo add-apt-repository ppa:longsleep/golang-backportssudo apt-get updatesudo apt-get install golang-go安装libiconvwget https://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.15.tar.gztar zxvf libiconv-1.15.tar.gzcd libiconv-1.15sudo ./configure --prefix=/usr/localsudo makesudo make installsudo ldconfig // 刷新动态链接库缓存 安装Yarncurl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.listsudo apt-get update &amp;&amp; sudo apt-get install yarn安装Electron v1.7.9yarn global add electron@1.7.9安装meteor JavaScript应用程序框架curl https://install.meteor.com/ | sh安装Gulpyarn global add gulp安装gethgit clone https://github.com/ethereum/go-ethereum.gitcd go-ethereummake geth把安装后的geth执行文件挪到/usr/bin安装Ganachewget https://github.com/trufflesuite/ganache/releases/download/v1.1.0/ganache-1.1.0-x86_64.AppImagechmod a+x ganache-1.1.0-x86_64.AppImage执行ganache-1.1.0-x86_64.AppImage安装Trufflesudo npm install -g truffle安装mist下载zip包https://github.com/ethereum/mist/releases/download/v0.10.0/Mist-linux64-0-10-0.zip解压unzip Mist-linux64-0-10-0.zip运行运行geth# 进入自定义指定目录cd $yourpath# 初始化geth init ./genesis.json --datadir ./chain# 进入后台geth --datadir ./chain --nodiscover console 2&gt;&gt; eth_output.logs运行mist./mist --rpc $yourpath/chain/geth.ipc --node-networkid 1234 --node-datadir $yourpath/chain/PS: 如果页面加载不出来，需要使用代理常见问题  安装geth报错build/env.sh go run build/ci.go install ./cmd/geth&gt;&gt;&gt; /usr/lib/go-1.10/bin/go install -ldflags -X main.gitCommit=4e7dc34ff1a7469b95eb16f5b4084c26a0ab3662 -v ./cmd/gethgithub.com/ethereum/go-ethereum/vendor/github.com/karalabe/hid# github.com/ethereum/go-ethereum/vendor/github.com/karalabe/hid/tmp/go-build654371927/b223/_x002.o：在函数‘get_usb_string’中：vendor/github.com/karalabe/hid/hidapi/libusb/hid.c:444：对‘libiconv_open’未定义的引用vendor/github.com/karalabe/hid/hidapi/libusb/hid.c:456：对‘libiconv’未定义的引用vendor/github.com/karalabe/hid/hidapi/libusb/hid.c:471：对‘libiconv_close’未定义的引用collect2: error: ld returned 1 exit statusutil.go:45: exit status 2exit status 1Makefile:15: recipe for target 'geth' failedmake: *** [geth] Error 1解决方案：根据提示找到对应文件sudo vim vendor/github.com/karalabe/hid/hid_enabled.go安装libiconv，并添加链接参数：-liconv#cgo linux,!android LDFLAGS: -lrt -liconv"
                        } ,
                     
                        {
                          "title"    : "fabric入门（五）安装和实例化链码",
                          "category" : "",
                          "tags"     : " 超级账本, fabric",
                          "url"      : "/2018/05/13/hyperledger-fabric-5.html",
                          "date"     : "May 13, 2018",
                          "excerpt"  : "安装启动链码首先，在将示例代码安装到4个peer节点中的其中一个。这个命令将源代码放到peer节点的文件系统中。peer chaincode install -n mycc -v 1.0 -p github.com/hyperledger/fabric-samples/chaincode/chaincode_example02/go/chaincode_example02接下来，在信道上实例化chaincode。这将初始化信道上的链码，设置链码的背书策略，为目标peer节点启动一个chai...",
                          "content"  : "安装启动链码首先，在将示例代码安装到4个peer节点中的其中一个。这个命令将源代码放到peer节点的文件系统中。peer chaincode install -n mycc -v 1.0 -p github.com/hyperledger/fabric-samples/chaincode/chaincode_example02/go/chaincode_example02接下来，在信道上实例化chaincode。这将初始化信道上的链码，设置链码的背书策略，为目标peer节点启动一个chaincode容器注意-P参数。这是我们需要指定的当这个chaincode的交易需要被验证的时侯的背书策略。在下面的命令中，你会注意到我们指定 -P “OR (‘Org0MSP.member’,’Org1MSP.member’)” 作为背书策略。这意味着我们需要Org1或者Org2组织中的其中一个的节点的背书即可（即只有一个背书）。如果我们改变语法为AND那么我们就需要2个背书者。peer chaincode instantiate -o orderer.example.com:7050 --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -v 1.0 -c '{\"Args\":[\"init\",\"a\", \"100\", \"b\",\"200\"]}' -P \"OR ('Org1MSP.member','Org2MSP.member')\"调用现在让我们从a账户转10到b账户。这个交易将创建一个新的区块并更新state DB。调用语法如下：peer chaincode invoke -o orderer.example.com:7050  --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem  -C $CHANNEL_NAME -n mycc -c '{\"Args\":[\"invoke\",\"a\",\"b\",\"10\"]}'查询让我们确认下我们之前的调用被正确地执行了。我们初始化了a的值为100，在上一次调用的时侯转移了10给b。因此，查询a应该展示90。查询的语法如下：peer chaincode query -C $CHANNEL_NAME -n mycc -c '{\"Args\":[\"query\",\"a\"]}'我们应该看到以下内容：Query Result: 90"
                        } ,
                     
                        {
                          "title"    : "fabric入门（四）启动网络",
                          "category" : "",
                          "tags"     : " 超级账本, fabric",
                          "url"      : "/2018/05/13/hyperledger-fabric-4.html",
                          "date"     : "May 13, 2018",
                          "excerpt"  : "启动网络我们将利用docker-compose脚本来启动我们的区块链网络。在开始前，我们先注释掉docker-compose-cli.yml的一段command: /bin/bash代码，不然该脚本将在网络启动时执行所有命令. cli:    container_name: cli    image: hyperledger/fabric-tools:$IMAGE_TAG    tty: true    stdin_open: true    environment:      - GOP...",
                          "content"  : "启动网络我们将利用docker-compose脚本来启动我们的区块链网络。在开始前，我们先注释掉docker-compose-cli.yml的一段command: /bin/bash代码，不然该脚本将在网络启动时执行所有命令. cli:    container_name: cli    image: hyperledger/fabric-tools:$IMAGE_TAG    tty: true    stdin_open: true    environment:      - GOPATH=/opt/gopath      - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock      #- CORE_LOGGING_LEVEL=DEBUG      - CORE_LOGGING_LEVEL=INFO      - CORE_PEER_ID=cli      - CORE_PEER_ADDRESS=peer0.org1.example.com:7051      - CORE_PEER_LOCALMSPID=Org1MSP      - CORE_PEER_TLS_ENABLED=true      - CORE_PEER_TLS_CERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.crt      - CORE_PEER_TLS_KEY_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/server.key      - CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt      - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp    working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer    #command: /bin/bash    volumes:        - /var/run/:/host/var/run/        - ./../chaincode/:/opt/gopath/src/github.com/chaincode        - ./crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/        - ./scripts:/opt/gopath/src/github.com/hyperledger/fabric/peer/scripts/        - ./channel-artifacts:/opt/gopath/src/github.com/hyperledger/fabric/peer/channel-artifacts    depends_on:      - orderer.example.com      - peer0.org1.example.com      - peer1.org1.example.com      - peer0.org2.example.com      - peer1.org2.example.com    networks:      - byfn启动网络CHANNEL_NAME=$CHANNEL_NAME TIMEOUT=&lt;pick_a_value&gt; docker-compose -f docker-compose-cli.yaml up -d执行完如图所示：创建&amp;加入信息进入cli容器，后面命令都是在cli容器中进行docker exec -it cli bash回想一下，我们使用configtxgen工具生成信道配置-channel.tx。我们将这个配置作为请求的一部分传递给order。export CHANNEL_NAME=mychannelpeer channel create -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/channel.tx --tls $CORE_PEER_TLS_ENABLED --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem返回一个创世区块--我们将使用它加入信道。它包含了channel.tx中的配置信息。接下来让其他节点加入信道org1.peer1export CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051export CORE_PEER_LOCALMSPID=\"Org1MSP\"export CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtpeer channel join -b mychannel.blockorg1.peer1export CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=peer1.org1.example.com:7051export CORE_PEER_LOCALMSPID=\"Org1MSP\"export CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls/ca.crtpeer channel join -b mychannel.blockorg2.peer0export CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=peer0.org2.example.com:7051export CORE_PEER_LOCALMSPID=\"Org2MSP\"export CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtpeer channel join -b mychannel.blockorg2.peer1export CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=peer1.org2.example.com:7051export CORE_PEER_LOCALMSPID=\"Org2MSP\"export CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer1.org2.example.com/tls/ca.crtpeer channel join -b mychannel.block"
                        } ,
                     
                        {
                          "title"    : "fabric入门（三）加密&amp;交易生成器",
                          "category" : "",
                          "tags"     : " 超级账本, fabric",
                          "url"      : "/2018/05/13/hyperledger-fabric-3.html",
                          "date"     : "May 13, 2018",
                          "excerpt"  : "通过查看./byfn.sh这个shell启动脚本，我们知道一开始的执行流程。#Create the network using docker composeif [ \"${MODE}\" == \"up\" ]; then  networkUpelif [ \"${MODE}\" == \"down\" ]; then ## Clear the network  networkDownelif [ \"${MODE}\" == \"generate\" ]; then ## Genera...",
                          "content"  : "通过查看./byfn.sh这个shell启动脚本，我们知道一开始的执行流程。#Create the network using docker composeif [ \"${MODE}\" == \"up\" ]; then  networkUpelif [ \"${MODE}\" == \"down\" ]; then ## Clear the network  networkDownelif [ \"${MODE}\" == \"generate\" ]; then ## Generate Artifacts  generateCerts  replacePrivateKey  generateChannelArtifactselif [ \"${MODE}\" == \"restart\" ]; then ## Restart the network  networkDown  networkUpelif [ \"${MODE}\" == \"upgrade\" ]; then ## Upgrade the network from v1.0.x to v1.1  upgradeNetworkelse  printHelp  exit 1fi首先是generateCerts这个方法function generateCerts (){  which cryptogen  if [ \"$?\" -ne 0 ]; then    echo \"cryptogen tool not found. exiting\"    exit 1  fi  echo  echo \"##########################################################\"  echo \"##### Generate certificates using cryptogen tool #########\"  echo \"##########################################################\"  if [ -d \"crypto-config\" ]; then    rm -Rf crypto-config  fi  set -x  cryptogen generate --config=./crypto-config.yaml  res=$?  set +x  if [ $res -ne 0 ]; then    echo \"Failed to generate certificates...\"    exit 1  fi  echo}里面用到的cryptogen用来为我们生成各种网络实体的加密材料（x509证书）。这些证书是身份的代表，它们允许在我们的网络实体进行交流和交易时进行签名/验证身份验证。Cryptogen消费一个包含网络拓扑的crypto-config.yaml，并允许我们为组织和属于这些组织的组件生成一组证书和密钥。每个组织都配置了唯一的根证书(ca-cert),它将特定组件（peers和orders）绑定到该组织。通过为每一个组织分配唯一的CA证书，我们正在模仿一个经典的网络，这个网络中的成员将使用自己的证书颁发机构。Hyperledger Fabric中的交易和通信是通过存储在keystore中的实体的私钥签名，然后通过公钥手段进行验证（signcerts）。所以我们第一步运行以下命令，生成的证书和密钥将被保存到名为crypto-config的文件夹中。cryptogen generate --config=./crypto-config.yaml接下来的replacePrivateKey方法主要用于e2e网络，我们暂时用不到，先跳过。接下来是generateChannelArtifacts这个方法，用来生成order的创世区块，信道的交易配置以及两个anchor peer transactions一个对应一个Peer组织。function generateChannelArtifacts() {  which configtxgen  if [ \"$?\" -ne 0 ]; then    echo \"configtxgen tool not found. exiting\"    exit 1  fi  echo \"##########################################################\"  echo \"#########  Generating Orderer Genesis block ##############\"  echo \"##########################################################\"  # Note: For some unknown reason (at least for now) the block file can't be  # named orderer.genesis.block or the orderer will fail to launch!  set -x  configtxgen -profile TwoOrgsOrdererGenesis -outputBlock ./channel-artifacts/genesis.block  res=$?  set +x  if [ $res -ne 0 ]; then    echo \"Failed to generate orderer genesis block...\"    exit 1  fi  echo  echo \"#################################################################\"  echo \"### Generating channel configuration transaction 'channel.tx' ###\"  echo \"#################################################################\"  set -x  configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID $CHANNEL_NAME  res=$?  set +x  if [ $res -ne 0 ]; then    echo \"Failed to generate channel configuration transaction...\"    exit 1  fi  echo  echo \"#################################################################\"  echo \"#######    Generating anchor peer update for Org1MSP   ##########\"  echo \"#################################################################\"  set -x  configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org1MSP  res=$?  set +x  if [ $res -ne 0 ]; then    echo \"Failed to generate anchor peer update for Org1MSP...\"    exit 1  fi  echo  echo \"#################################################################\"  echo \"#######    Generating anchor peer update for Org2MSP   ##########\"  echo \"#################################################################\"  set -x  configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate \  ./channel-artifacts/Org2MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org2MSP  res=$?  set +x  if [ $res -ne 0 ]; then    echo \"Failed to generate anchor peer update for Org2MSP...\"    exit 1  fi  echo}首先，我们需要设置一个环境变量来告诉configtxgen哪里去寻找configtx.yaml。然后，我们将调用configtxgen工具去创建orderer genesis block：export FABRIC_CFG_PATH=$PWDconfigtxgen -profile TwoOrgsOrdererGenesis -outputBlock ./channel-artifacts/genesis.block接下来，我们需要创建channel transaction配置。请确保替换$CHANNEL_NAME或者将CHANNEL_NAME设置为整个说明中可以使用的环境变量：export CHANNEL_NAME=mychannelconfigtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID $CHANNEL_NAME接下来，我们将在正在构建的通道上定义Org1的anchor peer。请再次确认$CHANNEL_NAME已被替换或者为以下命令设置了环境变量：configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org1MSP现在，我们将在同一个通道定义Org2的anchor peer：configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org2MSP"
                        } ,
                     
                        {
                          "title"    : "fabric入门（二）启动&amp;关闭网络",
                          "category" : "",
                          "tags"     : " 超级账本, fabric",
                          "url"      : "/2018/05/13/hyperledger-fabric-2.html",
                          "date"     : "May 13, 2018",
                          "excerpt"  : "进入官方示例cd $GOPATH/src/github.com/hyperledger/fabric-samples/first-network第一步生成我们各种网络实体的所有证书和密钥，genesis block用于引导排序服务，以及配置Channel所需要的一组交易配置集合。  运行以下命令：./byfn.sh -m generate接下来可以使用以下命令来启动整个网络。./byfn.sh -m up如果看到一个大大的END说明执行成功了。===================== A...",
                          "content"  : "进入官方示例cd $GOPATH/src/github.com/hyperledger/fabric-samples/first-network第一步生成我们各种网络实体的所有证书和密钥，genesis block用于引导排序服务，以及配置Channel所需要的一组交易配置集合。  运行以下命令：./byfn.sh -m generate接下来可以使用以下命令来启动整个网络。./byfn.sh -m up如果看到一个大大的END说明执行成功了。===================== All GOOD, BYFN execution completed ===================== _____   _   _   ____| ____| | \ | | |  _ \|  _|   |  \| | | | | || |___  | |\  | | |_| ||_____| |_| \_| |____/可以通过以下命令来关闭刚才打开的网络：./byfn.sh -m down为了能详细了解里面的操作流程，接下来我们不通过这个方式来启动，而是拆分./byfn.sh这个shell脚本来执行。请点击查看fabric入门（三）启动&amp;关闭网络"
                        } ,
                     
                        {
                          "title"    : "fabric入门（一）安装",
                          "category" : "",
                          "tags"     : " 超级账本, fabric",
                          "url"      : "/2018/05/13/hyperledger-fabric-1.html",
                          "date"     : "May 13, 2018",
                          "excerpt"  : "安装镜像镜像可以自己安装，也可以借助官网的samples来帮我们实现。从官网可以看到，安装需要执行一个脚本：curl -sSL https://goo.gl/6wtTN5 | bash -s 1.1.0不过这个需要翻墙，可以直接把文本下载下来。#!/bin/bash## Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0## if version not passed in, defa...",
                          "content"  : "安装镜像镜像可以自己安装，也可以借助官网的samples来帮我们实现。从官网可以看到，安装需要执行一个脚本：curl -sSL https://goo.gl/6wtTN5 | bash -s 1.1.0不过这个需要翻墙，可以直接把文本下载下来。#!/bin/bash## Copyright IBM Corp. All Rights Reserved.## SPDX-License-Identifier: Apache-2.0## if version not passed in, default to latest released versionexport VERSION=1.1.0# if ca version not passed in, default to latest released versionexport CA_VERSION=$VERSION# current version of thirdparty images (couchdb, kafka and zookeeper) releasedexport THIRDPARTY_IMAGE_VERSION=0.4.6export ARCH=$(echo \"$(uname -s|tr '[:upper:]' '[:lower:]'|sed 's/mingw64_nt.*/windows/')-$(uname -m | sed 's/x86_64/amd64/g')\")export MARCH=$(uname -m)printHelp() {  echo \"Usage: bootstrap.sh [&lt;version&gt;] [&lt;ca_version&gt;] [&lt;thirdparty_version&gt;][-d -s -b]\"  echo  echo \"-d - bypass docker image download\"  echo \"-s - bypass fabric-samples repo clone\"  echo \"-b - bypass download of platform-specific binaries\"  echo  echo \"e.g. bootstrap.sh 1.1.1 -s\"  echo \"would download docker images and binaries for version 1.1.1\"}dockerFabricPull() {  local FABRIC_TAG=$1  for IMAGES in peer orderer ccenv javaenv tools; do      echo \"==&gt; FABRIC IMAGE: $IMAGES\"      echo      docker pull hyperledger/fabric-$IMAGES:$FABRIC_TAG      docker tag hyperledger/fabric-$IMAGES:$FABRIC_TAG hyperledger/fabric-$IMAGES  done}dockerThirdPartyImagesPull() {  local THIRDPARTY_TAG=$1  for IMAGES in couchdb kafka zookeeper; do      echo \"==&gt; THIRDPARTY DOCKER IMAGE: $IMAGES\"      echo      docker pull hyperledger/fabric-$IMAGES:$THIRDPARTY_TAG      docker tag hyperledger/fabric-$IMAGES:$THIRDPARTY_TAG hyperledger/fabric-$IMAGES  done}dockerCaPull() {      local CA_TAG=$1      echo \"==&gt; FABRIC CA IMAGE\"      echo      docker pull hyperledger/fabric-ca:$CA_TAG      docker tag hyperledger/fabric-ca:$CA_TAG hyperledger/fabric-ca}samplesInstall() {  # clone (if needed) hyperledger/fabric-samples and checkout corresponding  # version to the binaries and docker images to be downloaded  if [ -d first-network ]; then    # if we are in the fabric-samples repo, checkout corresponding version    echo \"===&gt; Checking out v${VERSION} branch of hyperledger/fabric-samples\"    git checkout v${VERSION}  elif [ -d fabric-samples ]; then    # if fabric-samples repo already cloned and in current directory,    # cd fabric-samples and checkout corresponding version    echo \"===&gt; Checking out v${VERSION} branch of hyperledger/fabric-samples\"    cd fabric-samples &amp;&amp; git checkout v${VERSION}  else    echo \"===&gt; Cloning hyperledger/fabric-samples repo and checkout v${VERSION}\"    git clone -b master https://github.com/hyperledger/fabric-samples.git &amp;&amp; cd fabric-samples &amp;&amp; git checkout v${VERSION}  fi}# Incrementally downloads the .tar.gz file locally first, only decompressing it# after the download is complete. This is slower than binaryDownload() but# allows the download to be resumed.binaryIncrementalDownload() {      local BINARY_FILE=$1      local URL=$2      curl -f -s -C - ${URL} -o ${BINARY_FILE} || rc=$?      # Due to limitations in the current Nexus repo:      # curl returns 33 when there's a resume attempt with no more bytes to download      # curl returns 2 after finishing a resumed download      # with -f curl returns 22 on a 404      if [ \"$rc\" = 22 ]; then	  # looks like the requested file doesn't actually exist so stop here	  return 22      fi      if [ -z \"$rc\" ] || [ $rc -eq 33 ] || [ $rc -eq 2 ]; then          # The checksum validates that RC 33 or 2 are not real failures          echo \"==&gt; File downloaded. Verifying the md5sum...\"          localMd5sum=$(md5sum ${BINARY_FILE} | awk '{print $1}')          remoteMd5sum=$(curl -s ${URL}.md5)          if [ \"$localMd5sum\" == \"$remoteMd5sum\" ]; then              echo \"==&gt; Extracting ${BINARY_FILE}...\"              tar xzf ./${BINARY_FILE} --overwrite	      echo \"==&gt; Done.\"              rm -f ${BINARY_FILE} ${BINARY_FILE}.md5          else              echo \"Download failed: the local md5sum is different from the remote md5sum. Please try again.\"              rm -f ${BINARY_FILE} ${BINARY_FILE}.md5              exit 1          fi      else          echo \"Failure downloading binaries (curl RC=$rc). Please try again and the download will resume from where it stopped.\"          exit 1      fi}# This will attempt to download the .tar.gz all at once, but will trigger the# binaryIncrementalDownload() function upon a failure, allowing for resume# if there are network failures.binaryDownload() {      local BINARY_FILE=$1      local URL=$2      echo \"===&gt; Downloading: \" ${URL}      # Check if a previous failure occurred and the file was partially downloaded      if [ -e ${BINARY_FILE} ]; then          echo \"==&gt; Partial binary file found. Resuming download...\"          binaryIncrementalDownload ${BINARY_FILE} ${URL}      else          curl ${URL} | tar xz || rc=$?          if [ ! -z \"$rc\" ]; then              echo \"==&gt; There was an error downloading the binary file. Switching to incremental download.\"              echo \"==&gt; Downloading file...\"              binaryIncrementalDownload ${BINARY_FILE} ${URL}	  else	      echo \"==&gt; Done.\"          fi      fi}binariesInstall() {  echo \"===&gt; Downloading version ${FABRIC_TAG} platform specific fabric binaries\"  binaryDownload ${BINARY_FILE} https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric/hyperledger-fabric/${ARCH}-${VERSION}/${BINARY_FILE}  if [ $? -eq 22 ]; then     echo     echo \"------&gt; ${FABRIC_TAG} platform specific fabric binary is not available to download &lt;----\"     echo   fi  echo \"===&gt; Downloading version ${CA_TAG} platform specific fabric-ca-client binary\"  binaryDownload ${CA_BINARY_FILE} https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric-ca/hyperledger-fabric-ca/${ARCH}-${CA_VERSION}/${CA_BINARY_FILE}  if [ $? -eq 22 ]; then     echo     echo \"------&gt; ${CA_TAG} fabric-ca-client binary is not available to download  (Available from 1.1.0-rc1) &lt;----\"     echo   fi}dockerInstall() {  which docker &gt;&amp; /dev/null  NODOCKER=$?  if [ \"${NODOCKER}\" == 0 ]; then	  echo \"===&gt; Pulling fabric Images\"	  dockerFabricPull ${FABRIC_TAG}	  echo \"===&gt; Pulling fabric ca Image\"	  dockerCaPull ${CA_TAG}	  echo \"===&gt; Pulling thirdparty docker images\"	  dockerThirdPartyImagesPull ${THIRDPARTY_TAG}	  echo	  echo \"===&gt; List out hyperledger docker images\"	  docker images | grep hyperledger*  else    echo \"=========================================================\"    echo \"Docker not installed, bypassing download of Fabric images\"    echo \"=========================================================\"  fi}DOCKER=trueSAMPLES=trueBINARIES=true# Parse commandline args pull out# version and/or ca-version strings firstif echo $1 | grep -q '\d'; then  VERSION=$1;shift  if echo $1 | grep -q '\d'; then    CA_VERSION=$1;shift    if echo $1 | grep -q '\d'; then      THIRDPARTY_IMAGE_VERSION=$1;shift    fi  fifi# prior to 1.2.0 architecture was determined by uname -mif [[ $VERSION =~ ^1\.[0-1]\.* ]]; then  export FABRIC_TAG=${MARCH}-${VERSION}  export CA_TAG=${MARCH}-${CA_VERSION}  export THIRDPARTY_TAG=${MARCH}-${THIRDPARTY_IMAGE_VERSION}else  # starting with 1.2.0, multi-arch images will be default  : ${CA_TAG:=\"$CA_VERSION\"}  : ${FABRIC_TAG:=\"$VERSION\"}  : ${THIRDPARTY_TAG:=\"$THIRDPARTY_IMAGE_VERSION\"}fiBINARY_FILE=hyperledger-fabric-${ARCH}-${VERSION}.tar.gzCA_BINARY_FILE=hyperledger-fabric-ca-${ARCH}-${CA_VERSION}.tar.gz# then parse optswhile getopts \"h?dsb\" opt; do  case \"$opt\" in    h|\?)      printHelp      exit 0    ;;    d)  DOCKER=false    ;;    s)  SAMPLES=false    ;;    b)  BINARIES=false    ;;  esacdoneif [ \"$SAMPLES\" == \"true\" ]; then  echo  echo \"Installing hyperledger/fabric-samples repo\"  echo  samplesInstallfiif [ \"$BINARIES\" == \"true\" ]; then  echo  echo \"Installing Hyperledger Fabric binaries\"  echo  binariesInstallfiif [ \"$DOCKER\" == \"true\" ]; then  echo  echo \"Installing Hyperledger Fabric docker images\"  echo  dockerInstallfi保存为install.sh，并执行bash ./install.sh这个脚本会去Docker Hub上下载相应的镜像到本地的docker里面，所以运行脚本前需要启动docker服务。  同时，还会去下载对应平台的二进制文件，也就是bin目录。整个下载过程还是相当卡的，所以还是建议用代理来执行。执行完成后如下图所示：下载源码git clone https://github.com/hyperledger/fabric由于接下来的实例，需要用到指定路径，所以下载完成后，需要完成以下两个步骤：1.把它挪到$GOPATH路径下 $GOPATH/src/github.com/hyperledger/fabric2.设置软链接sudo ln -s $GOPATH /opt/3.把$GOPATH/src/github.com/hyperledger/fabric/bin添加到环境变量"
                        } ,
                     
                        {
                          "title"    : "网络基础 - 用户数据报协议(UDP)",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/30/network-udp.html",
                          "date"     : "April 30, 2018",
                          "excerpt"  : "用户数据报协议（User Datagram Protocol, UDP）是在现代网络中最常使用的另外一种第4层协议。如果说TCP是为了满足带有内在错误检测的可靠数据传输，那么UDP主要是为了提供高速的传输。处于这个原因，UDP是一种尽力服务，通常会被称为无连接协议。一个无连接协议并不会正式的建立和结束主机之前的连接，也不会像TCP那样存在握手和终止进程。无连接协议意味着不可靠服务，这将使得UDP流量不稳定。依赖于UDP的协议通常都会有其内置的可靠性服务，或者使用ICMP的一些功能来保证连接...",
                          "content"  : "用户数据报协议（User Datagram Protocol, UDP）是在现代网络中最常使用的另外一种第4层协议。如果说TCP是为了满足带有内在错误检测的可靠数据传输，那么UDP主要是为了提供高速的传输。处于这个原因，UDP是一种尽力服务，通常会被称为无连接协议。一个无连接协议并不会正式的建立和结束主机之前的连接，也不会像TCP那样存在握手和终止进程。无连接协议意味着不可靠服务，这将使得UDP流量不稳定。依赖于UDP的协议通常都会有其内置的可靠性服务，或者使用ICMP的一些功能来保证连接更可靠一些。举例来说，应用层协议DNS和DHCP需要高度依赖数据包在网络上的传输速度，其使用UDP作为它们的传输层协议，但是它们自己进行错误检查以及重传计时。UDP 头  源端口用来传输数据包的端口。  目标端口数据包将要被传输到的端口。  数据包长度数据包的字节长度。  校验和用来确保UDP头和数据到达时的完整性。"
                        } ,
                     
                        {
                          "title"    : "网络基础 - 传输控制协议(TCP)",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/30/network-tcp.html",
                          "date"     : "April 30, 2018",
                          "excerpt"  : "传输控制协议（Transmission Control Protocol, TCP）的最终目的是为数据提供可靠的端到端传输。TCP 头数据结构如下图所示：  源端口（Source Port）用来传输数据包的端口。  目的端口（Destination Port）数据包将要被发送到的端口。  序号（Sequence Number）这个数字用来表示一个TCP片段。这个域用来保证数据流的部分没有缺失。  确认号（Acknowledgment Number）这个数字是通信中希望从另一设备得到的下一个...",
                          "content"  : "传输控制协议（Transmission Control Protocol, TCP）的最终目的是为数据提供可靠的端到端传输。TCP 头数据结构如下图所示：  源端口（Source Port）用来传输数据包的端口。  目的端口（Destination Port）数据包将要被发送到的端口。  序号（Sequence Number）这个数字用来表示一个TCP片段。这个域用来保证数据流的部分没有缺失。  确认号（Acknowledgment Number）这个数字是通信中希望从另一设备得到的下一个数据包的序号。  标记（Flags）URG、ACK、PSH、RST、SYN 和 FIN 标记都是用来表示所传输的TCP数据包的类型。  窗口大小（Window Size）TCP接收者缓冲的字节大小。  校验和（Checksum）用来保证TCP头和数据的内容在抵达目的地时的完整性。  紧急指针（Urgent Pointer）如果设置了URG位，这个域将被检查作为额外的指令，告诉CPU从数据包的哪里开始读取数据。  选项（Options）各种可选的域，可以在TCP数据包中进行指定。TCP端口在使用TCP进行通信时，我们有65535个端口可以使用，并通常将这些端口分成两个部分。  1~1023 是标准端口组，特定服务会用到这些通常位于标准端口分组中的标准端口。  1024~65535 是临时端口组，当一个服务想在任意时间使用端口进行通信时，现代操作系统都会随机的选择一个源端口，让这个通信使用唯一源端口。这些源端口通常就位于临时端口组。三次握手主要达到的目的：  保证源主机确定目标主机在线，并且可以进行通信。  让源主机检查它是否正在监听试图去连接的端口。  允许源主机向接收者发送它的起始序列号，是的两台主机可以将数据包流保持有序。具体步骤如下：sequenceDiagram    participant A as 主机A    participant B as 主机B    A-&gt;&gt;B: SYN    B-&gt;&gt;A: SYN/ACK    A-&gt;&gt;B: ACK具体说明：  请求新的 TCP 连接时，客户端要向服务器发送⼀个⼩的 TCP 分组（通常是 40 ～ 60 个字节）。这个分组中设置了⼀个特殊的 SYN 标记，说明这是⼀个连接请求。（如上图a）。  如果服务器接受了连接，就会对⼀些连接参数进⾏计算，并向客户端回送⼀个 TCP 分组，这个分组中的 SYN 和 ACK 标记都被置位，说明连接请求已被接受（如上图b）。  最后，客户端向服务器回送⼀条确认信息，通知它连接已成功建⽴（如上图c）。现代的 TCP 栈都允许客户端在这个确认分组中发送数据。TCP终止具体步骤如下：sequenceDiagram    participant A as 主机A    participant B as 主机B    A-&gt;&gt;B: FIN/ACK    B-&gt;&gt;A: ACK    B-&gt;&gt;A: FIN/ACK    A-&gt;&gt;B: ACK具体说明：  主机A通过发送一个设置了FIN和ACK标志的TCP数据包，告诉主机B通信的完成。  主机B以一个ACK数据包响应，并传输自己的FIN/ACK数据包。  主机A响应一个ACK数据包，然后结束通信过程。TCP重置在理想情况中，每一个连接都会以TCP终止来正常的结束。但在现实中，连接经常会突然断掉。举例来说，者可能由于一个潜在的攻击者正在进行端口扫描，或者仅仅是主机配置错误。在这种情况下，就需要使用设置了RST标志的TCP数据包。RST标志用来表示连接被异常中止或拒绝连接请求。"
                        } ,
                     
                        {
                          "title"    : "网络基础 - IP协议",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/30/network-ip.html",
                          "date"     : "April 30, 2018",
                          "excerpt"  : "IPv4IP地址是一个32位的二进制数，通常被分割为4个“8位二进制数”（也就是4个字节）。IP地址通常用“点分十进制”表示成（a.b.c.d）的形式，其中，a,b,c,d都是0~255之间的十进制整数。例：点分十进IP地址（100.4.5.6），实际上是32位二进制数（01100100.00000100.00000101.00000110）。IP地址呗分成4个独立部分，是因为每个IP地址都包含有两个部分：网络地址和主机地址。网络地址用来标识设备所连接到的局域网，而主机地址则标识这个网络中...",
                          "content"  : "IPv4IP地址是一个32位的二进制数，通常被分割为4个“8位二进制数”（也就是4个字节）。IP地址通常用“点分十进制”表示成（a.b.c.d）的形式，其中，a,b,c,d都是0~255之间的十进制整数。例：点分十进IP地址（100.4.5.6），实际上是32位二进制数（01100100.00000100.00000101.00000110）。IP地址呗分成4个独立部分，是因为每个IP地址都包含有两个部分：网络地址和主机地址。网络地址用来标识设备所连接到的局域网，而主机地址则标识这个网络中的设备本身。而如何划分这四个部分，是由另一组名为网络掩码(netmask, network mask)的地址信息决定的，有时也成为子网掩码(subnet mask)。网络掩码也是32位长，并且被设为1的每一位都标识者IP地址的对应部分是属于网络地址的，而剩下设为0的部分则标识者主机地址。IP地址和网络掩码为简便起见，通常会被写成无类型域间选路*(Classless Inter-Domain Routing, CIDR)。在这种形式下，一个完整的IP地址后面会有一个左斜杠，以及一个用来标识IP地址中网络部分位数的数字。举例，IP地址10.10.1.22和网络掩码255.255.0.0，在CIDR表示下会写成10.10.1.22/16.报文结构IPv4报文的首部包含14个字段，其中13个是必须的，第14个是可选的（红色标出），并命名为：“选项”字段。首部中的字段均以大端序包装，在以下的图表和讨论中，最高有效位（Most Significant bit）被标记为0。  版本（Version）版本字段占4bit，通信双方使用的版本必须一致。对于IPv4，字段的值是4。  首部长度（Internet Header Length， IHL）占4bit，首部长度说明首部有多少32位字（4字节）。由于IPv4首部可能包含数目不定的选项，这个字段也用来确定数据的偏移量。这个字段的最小值是5（二进制0101），相当于5*4=20字节（RFC 791），最大十进制值是15。  区分服务（Differentiated Services，DS）占8bit，最初被定义为服务类型字段，实际上并未使用，但1998年被IETF重定义为区分服务RFC 2474。只有在使用区分服务时，这个字段才起作用，在一般的情况  下都不使用这个字段。例如需要实时数据流的技术会应用这个字段，一个例子是VoIP。  显式拥塞通告（ Explicit Congestion Notification，ECN）在RFC 3168中定义，允许在不丢弃报文的同时通知对方网络拥塞的发生。ECN是一种可选的功能，仅当两端都支持并希望使用，且底层网络支持时才被使用。  全长（Total Length）这个16位字段定义了报文总长，包含首部和数据，单位为字节。这个字段的最小值是20（20字节首部+0字节数据），最大值是216-1=65,535。IP规定所有主机都必须支持最小576字节的报文，这是假定上层数据长度512字节，加上最长IP首部60字节，加上4字节富裕量，得出576字节，但大多数现代主机支持更大的报文。当下层的数据链路协议的最大传输单元（MTU）字段的值小于IP报文长度时间，报文就必须被分片.  标识符（Identification）占16位，这个字段主要被用来唯一地标识一个报文的所有分片，因为分片不一定按序到达，所以在重组时需要知道分片所属的报文。每产生一个数据报，计数器加1，并赋值给此字段。一些实验性的工作建议将此字段用于其它目的，例如增加报文跟踪信息以协助探测伪造的源地址。  标志 （Flags）这个3位字段用于控制和识别分片，它们是：  位0：保留，必须为0；  位1：禁止分片（Don’t Fragment，DF），当DF=0时才允许分片；  位2：更多分片（More Fragment，MF），MF=1代表后面还有分片，MF=0 代表已经是最后一个分片。  如果DF标志被设置为1，但路由要求必须分片报文，此报文会被丢弃。这个标志可被用于发往没有能力组装分片的主机。  当一个报文被分片，除了最后一片外的所有分片都设置MF为1。最后一个片段具有非零片段偏移字段，将其与未分片数据包区分开，未分片的偏移字段为0。  分片偏移 （Fragment Offset）这个13位字段指明了每个分片相对于原始报文开头的偏移量，以8字节作单位。  存活时间（Time To Live，TTL）这个8位字段避免报文在互联网中永远存在（例如陷入路由环路）。存活时间以秒为单位，但小于一秒的时间均向上取整到一秒。在现实中，这实际上成了一个跳数计数器：报文经过的每个路由器都将此字段减1，当此字段等于0时，报文不再向下一跳传送并被丢弃，最大值是255。常规地，一份ICMP报文被发回报文发送端说明其发送的报文已被丢弃。这也是traceroute的核心原理。  协议 （Protocol）占8bit，这个字段定义了该报文数据区使用的协议。  首部检验和 （Header Checksum）这个16位检验和字段只对首部查错，不包括数据部分。在每一跳，路由器都要重新计算出的首部检验和并与此字段进行比对，如果不一致，此报文将会被丢弃。重新计算的必要性是因为每一跳的一些首部字段（如TTL、Flag、Offset等）都有可能发生变化，不检查数据部分是为了减少工作量。数据区的错误留待上层协议处理——用户数据报协议（UDP）和传输控制协议（TCP）都有检验和字段。此处的检验计算方法不使用CRC。  源地址一个IPv4地址由四个字节共32位构成，此字段的值是将每个字节转为二进制并拼在一起所得到的32位值。  例如，10.9.8.7是00001010000010010000100000000111。  但请注意，因为NAT的存在，这个地址并不总是报文的真实发送端，因此发往此地址的报文会被送往NAT设备，并由它被翻译为真实的地址。  目的地址与源地址格式相同，但指出报文的接收端。  选项附加的首部字段可能跟在目的地址之后，但这并不被经常使用，从1到40个字节不等。请注意首部长度字段必须包括足够的32位字来放下所有的选项（包括任何必须的填充以使首部长度能够被32位整除）。当选项列表的结尾不是首部的结尾时，EOL（选项列表结束，0x00）选项被插入列表末尾。  数据使用IP传递的实际数据。分片和组装一个数据包的分片主要是基于第2层数据链路协议所使用的最大传输单元（Maximum Transmission Unit, MTU）的大小，以及使用这些第2层协议设备的配置情况。多数情况下，第2层使用的数据链路协议是以太网。以太网的默认MTU是1500，也就是说，以太网的网络上所能传输的最大数据包大小是1500字节。当设备收到IP报文时，分析其目的地址并决定要在哪个链路上发送它。MTU决定了数据载荷的最大长度，如IP报文长度比MTU大，则IP数据包必须进行分片。每一片的长度都小于等于MTU减去IP首部长度。接下来每一片均被放到独立的IP报文中，并进行如下修改：总长字段被修改为此分片的长度；  更多分片（MF）标志被设置，除了最后一片；  分片偏移量字段被调整为合适的值；  首部检验和被重新计算。例如，对于一个长20字节的首部和一个MTU为1,500的以太网，分片偏移量将会是：0、(1480/8)=185、(2960/8)=370、(4440/8)=555、(5920/8)=740、等等。如果报文经过路径的MTU减小了，那么分片可能会被再次分片。比如，一个4,500字节的数据载荷被封装进了一个没有选项的IP报文（即总长为4,520字节），并在MTU为2,500字节的链路上传输，那么它会被破成如下两个分片：现在，假设下一跳的MTU为1,500字节，那么每一个分片都会被再次分成两片(由于数据片段只有在目的主机才重新被组成数据报，因此再次分片是针对每个在网络中传输的数据帧)：第3和4片是从原始第2片再次分片而来，所以除了分片后的最后一个分片外MF为都为1。当一个接收者发现IP报文的下列项目之一为真时：  DF标志为0；  分片偏移量字段不为0。它便知道这个报文已被分片，并随即将数据、标识符字段、分片偏移量和更多分片标志一起储存起来。当接受者收到了更多分片标志未被设置的分片时，它便知道原始数据载荷的总长。一旦它收齐了所有的分片，它便可以将所有片按照正确的顺序（通过分片偏移量）组装起来，并交给上层协议栈。"
                        } ,
                     
                        {
                          "title"    : "网络基础 - 互联网控制消息协议(ICMP)",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/30/network-icmp.html",
                          "date"     : "April 30, 2018",
                          "excerpt"  : "互联网控制消息协议（Internet Control Message Protocol, ICMP）是TCP/IP协议族中的一个效用协议，负责提供在TCP/IP网络上设备、服务以及路由器可用性的消息。ICMP 头ICMP是IP的一部分并依赖IP来传递消息。ICMP头相对较小并根据用途而改变。  类型（Type）ICMP消息基于RFC规范的类型或分类。  代码（Code）ICMP消息基于RFC规范的子类型。  校验和（Checksum）用来保证ICMP头和数据在抵达目的地时的完整性。  可变...",
                          "content"  : "互联网控制消息协议（Internet Control Message Protocol, ICMP）是TCP/IP协议族中的一个效用协议，负责提供在TCP/IP网络上设备、服务以及路由器可用性的消息。ICMP 头ICMP是IP的一部分并依赖IP来传递消息。ICMP头相对较小并根据用途而改变。  类型（Type）ICMP消息基于RFC规范的类型或分类。  代码（Code）ICMP消息基于RFC规范的子类型。  校验和（Checksum）用来保证ICMP头和数据在抵达目的地时的完整性。  可变域（Variable）依赖于类型和代码域的部分。ICMP类型和消息ICMP数据包的结构取决于它由Type和Code域中的值所定义的用途。你可以将ICMP的类型域作为数据包的分类，而Code域作为它的子类。举例来说，Type域的值为3时意味着“目标不可达”。但只有这个信息不足以发现问题，当如果数据包在Code域中知名值为3，也就是“端口不可达”时，你就可以知道这应该是你试图进行通信的端口的问题。所有可用的ICMP类型和代码，可参考https://www.iana.org/assignments/icmp-parameter"
                        } ,
                     
                        {
                          "title"    : "网络基础 - 域名系统(DNS)",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/30/network-dns.html",
                          "date"     : "April 30, 2018",
                          "excerpt"  : "域名系统（英文：Domain Name System，缩写：DNS）是互联网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS使用TCP和UDP端口53。DNS数据包结构  DNS ID号（DNS ID Numner）用来对应DNS查询和DNS响应。  查询/响应（Query/Response, QR）用来指明这个数据包是DNS查询还是响应。  操作代码（OpCode）用来定义消息中请求的类型。  权威应答（Authoritative Answ...",
                          "content"  : "域名系统（英文：Domain Name System，缩写：DNS）是互联网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS使用TCP和UDP端口53。DNS数据包结构  DNS ID号（DNS ID Numner）用来对应DNS查询和DNS响应。  查询/响应（Query/Response, QR）用来指明这个数据包是DNS查询还是响应。  操作代码（OpCode）用来定义消息中请求的类型。  权威应答（Authoritative Answer, AA）如果响应数据包中设定了这个值，则说明这个响应是由域内权威域名服务器发出的。  截断（Truncation, TC）用来指明这个响应由于太长，无法装入数据包而被截断。  期望递归（Recursion Desired, RD）当请求中设定了这个值，则说明DNS客户端在目标域名服务器不含有所请求信息的情况下，要求进行递归查询。  可用递归（Recursion Available, RA）当响应中设定了这个值，说明域名服务器支持递归查询。  保留（Z）在RFC1035的规定中被全设为0，但有时会被用来作为RCode域的扩展。  响应代码（Response Code）在DNS响应中用来指明错误。  问题计数（Question Count）在问题区段中的条目数。  回答计数（Answer Count）在回答区段中的条目数。  域名服务器计数（Name Server Count）在权威区段的域名资源记录数。  额外记录计数（Additional Records Count）在额外信息区段中其他资源记录数。  问题区段（Question section）大小可变，包含有被发送到DNS服务器的一条或多条的信息查询部分。  回答区段（Answer section）大小可变，含有用来回答查询的一条或多条资源记录。  权威区段（Authority section）大小可变，包含指向权威域名服务器的资源记录，用以继续解析过程。  额外信息区段（Additional Information section）包含资源记录且大小可变的区段。这些资源记录用来存储完全没有必要回答的查询相关的额外信息。DNS递归由于互联网的DNS结构是层级式的，为了能有回答客户端提交的查询，DNS服务器必须能够彼此通信。我们的内部DNS服务器知道我们本地局域网服务器的名字和IP地址的映射，但不大可能知道谷歌的IP地址。当DNS服务器需要查找一个IP地址时，它会代表发出请求的客户端向另一个DNS服务器查询。实际上，这个DNS服务器与客户端的行为相同。这个过程叫做递归查询。sequenceDiagram    participant A as DNS客户端    participant B as 本地DNS服务器    participant C as 外部DNS服务器    A-&gt;&gt;B: 递归查询    B-&gt;&gt;C: 递归查询    C-&gt;&gt;B: 查询响应    B-&gt;&gt;A: 查询响应DNS区域传送DNS区域是一个DNS服务器所授权管理的名字空间（或是一组DNS名称）。举例来说，baidu这个网站可能是由一个DNS服务器对baidu.com负责。这样，无论是baidu内部还是外部的设备，如果希望将baidu.com解析成IP地址，都需要和这个区域的权威，也就是这个DNS服务器联系。如果baidu发展壮大了，它可能会增加一个DNS服务器，专门用来处理其名字空间的email部分，如mail.baidu.com，那么这个服务器，就成为这个邮件子区域的权威。如果必要的话，还可以为子域名添加更多的DNS服务器。区域传送指处于荣誉备份的需要，在两台设备之间传送区域数据。举例来说，在拥有多个DNS服务器的组织中，管理员通常都会配置一台备用DNS服务器，用来维护一份主服务器DNS信息的拷贝，以防止DNS服务器不可欧阳。主要存在两种区域传送。  完整区域传送（AXFR）这个类型的传送将整个区域在设备间进行传送。  增量区域传送（IXFR）这个类型的传送仅传送区域信息的一部分。"
                        } ,
                     
                        {
                          "title"    : "网络基础 - 动态主机设置协议(DHCP)",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/30/network-dhcp.html",
                          "date"     : "April 30, 2018",
                          "excerpt"  : "动态主机配置协议（Dynamic Host Configuration Protocol）是一个应用层协议，能够让设备自动获取IP地址（以及其他重要网络资源，比如DNS服务器和路由网关的地址）。大多数的DHCP服务器都向客户端提供一些其他的参数，比如网络上的默认网关和DNS服务器的地址。通常被应用在大型的局域网络环境中，主要作用是集中的管理、分配IP地址，使网络环境中的主机动态的获得IP地址、Gateway地址、DNS服务器地址等信息，并能够提升地址的使用率。DHCP 头结构  操作码（O...",
                          "content"  : "动态主机配置协议（Dynamic Host Configuration Protocol）是一个应用层协议，能够让设备自动获取IP地址（以及其他重要网络资源，比如DNS服务器和路由网关的地址）。大多数的DHCP服务器都向客户端提供一些其他的参数，比如网络上的默认网关和DNS服务器的地址。通常被应用在大型的局域网络环境中，主要作用是集中的管理、分配IP地址，使网络环境中的主机动态的获得IP地址、Gateway地址、DNS服务器地址等信息，并能够提升地址的使用率。DHCP 头结构  操作码（OpCode）用来指出这个数据包是DHCP请求还是DHCP回复。  硬件类型（Hardware Type）硬件地址类型  硬件长度（Hardware Length）硬件地址长度  跳数（Hops）中继代理用来帮助寻找DHCP服务器。  事务ID（Transaction ID）用来匹配请求和响应的一个随机数。  消耗时间（Seconds Elasped）客户端第一次向DHCP服务器发出地址请求后的时间。  标记（Flags）DHCP客户端能够接受的流量类型（单播、广播以及其他）。  客户端IP地址（Client IP Address）客户端的IP地址（由“你的”IP地址域派生）  “你的”IP地址（Your IP Address）DHCP服务器提供的IP地址（最终成为客户端的IP地址域的值）  服务器IP地址（Server IP Address）DHCP服务器的IP地址  网关IP地址（Gateway IP Address）网络默认网关的IP地址。  客户端硬件地址（Client Hardware Address）客户端的MAC地址。  服务器主机名（Server Host Name）服务器的主机名（可选）。  启动文件（Boot File）DHCP所使用的启动文件（可选）。  选项（Options）用来对DHCP数据包进行扩展，以提供更多功能。DHCP 续租过程（DORA）DCHP 最主要的任务就是在续租过程中向客户端分配IP地址。过程是在一个客户端和DHCP服务器之间进行，也成为DORA过程。sequenceDiagram    participant A as DHCP客户端    participant B as DHCP服务器    A-&gt;&gt;B: 发现（Discover）    B-&gt;&gt;A: 提供（Offer）    A-&gt;&gt;B: 请求（Request）    B-&gt;&gt;A: 确认（ACK）当DCHP给一个设备分配了一个IP地址时，它同时给客户端定下了一个租约。就是说，客户端只能在有限时间内使用这个IP地址，否则就必须续约。当一个拥有IP地址的客户端在租约内重新启动，它必须进行一个精简版的DORA过程来重新认领它的IP地址。这个过程称为租约内续租。当租约内续租时，发现和提供数据包就没有必要了。考虑到其与租约过期时的DORA过程类似，可以发现在租约过续租并不需要这么做，而只是完成请求和确认两个步骤就可以了。sequenceDiagram    participant A as DHCP客户端    participant B as DHCP服务器    A-&gt;&gt;B: 请求（Request）    B-&gt;&gt;A: 确认（ACK）"
                        } ,
                     
                        {
                          "title"    : "网络基础 - 地址解析协议(ARP)",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/29/network-arp.html",
                          "date"     : "April 29, 2018",
                          "excerpt"  : "在以太网协议中规定，同一局域网中的一台主机要和另一台主机进行直接通信，必须要知道目标主机的MAC地址。而在TCP/IP协议中，网络层和传输层只关心目标主机的IP地址。这就导致在以太网中使用IP协议时，数据链路层的以太网协议接到上层IP协议提供的数据中，只包含目的主机的IP地址。于是需要一种方法，根据目的主机的IP地址，获得其MAC地址。这就是ARP协议要做的事情。所谓地址解析（address resolution）就是主机在发送帧前将目标IP地址转换成目标MAC地址的过程。另外，当发送主机...",
                          "content"  : "在以太网协议中规定，同一局域网中的一台主机要和另一台主机进行直接通信，必须要知道目标主机的MAC地址。而在TCP/IP协议中，网络层和传输层只关心目标主机的IP地址。这就导致在以太网中使用IP协议时，数据链路层的以太网协议接到上层IP协议提供的数据中，只包含目的主机的IP地址。于是需要一种方法，根据目的主机的IP地址，获得其MAC地址。这就是ARP协议要做的事情。所谓地址解析（address resolution）就是主机在发送帧前将目标IP地址转换成目标MAC地址的过程。另外，当发送主机和目的主机不在同一个局域网中时，即便知道目的主机的MAC地址，两者也不能直接通信，必须经过路由转发才可以。所以此时，发送主机通过ARP协议获得的将不是目的主机的真实MAC地址，而是一台可以通往局域网外的路由器的MAC地址。于是此后发送主机发往目的主机的所有帧，都将发往该路由器，通过它向外发送。这种情况称为委托ARP或ARP代理（ARP Proxy）。在点对点链路中不使用ARP，实际上在点对点网络中也不使用MAC地址，因为在此类网络中分别已经获取了对端的IP地址。原理在每台安装有TCP/IP协议的电脑或路由器里都有一个ARP缓存表，表里的IP地址与MAC地址是一对应的，如下表所示。            主机名称      IP地址      MAC地址              A      192.168.38.10      00-AA-00-62-D2-02              B      192.168.38.11      00-BB-00-62-C2-02              C      192.168.38.12      00-CC-00-62-C2-02              D      192.168.38.13      00-DD-00-62-C2-02              E      192.168.38.14      00-EE-00-62-C2-02              …      …      …      以主机A（192.168.38.10）向主机B（192.168.38.11）发送数据为例。  当发送数据时，主机A会在自己的ARP缓存表中寻找是否有目标IP地址。如果找到就知道目标MAC地址为（00-BB-00-62-C2-02），直接把目标MAC地址写入帧里面发送就可。  如果在ARP缓存表中没有找到相对应的IP地址，主机A就会在网络上发送一个广播（ARP request），目标MAC地址是“FF.FF.FF.FF.FF.FF”，这表示向同一网段内的所有主机发出这样的询问：“192.168.38.11的MAC地址是什么？”  网络上其他主机并不响应ARP询问，只有主机B接收到这个帧时，才向主机A做出这样的回应（ARP response）：“192.168.38.11的MAC地址是00-BB-00-62-C2-02”，此回应以单播方式。这样，主机A就知道主机B的MAC地址，它就可以向主机B发送信息。同时它还更新自己的ARP高速缓存（ARP cache），下次再向主机B发送信息时，直接从ARP缓存表里查找就可。ARP缓存表采用老化机制，在一段时间内如果表中的某一行没有使用，就会被删除，这样可以大大减少ARP缓存表的长度，加快查询速度。数据结构报文数据：  硬件类型：如以太网（0x0001）、分组无线网。  协议类型：如IP网际协议（0x0800）、IPv6（0x86DD）。  硬件地址长度：每种硬件地址的字节长度，一般为6（以太网）。  协议地址长度：每种协议地址的字节长度，一般为4（IPv4）。  操作码：1为ARP请求，2为ARP回显，3为RARP请求，4为RARP应答。  源硬件地址：n个字节，n由硬件地址长度得到，一般为发送方MAC地址。  源协议地址：m个字节，m由协议地址长度得到，一般为发送方IP地址。  目标硬件地址：n个字节，n由硬件地址长度得到，一般为目标MAC地址。  目标协议地址：m个字节，m由协议地址长度得到，一般为目标IP地址。"
                        } ,
                     
                        {
                          "title"    : "HTTP - 报文 - 首部",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/29/http-headers.html",
                          "date"     : "April 29, 2018",
                          "excerpt"  : "本文对HTTP报文中常见的首部做下说明。通用首部有些⾸部提供了与报⽂相关的最基本的信息，它们被称为通⽤⾸部。它们像和事佬⼉⼀样，不论报⽂是何类型，都为其提供⼀些有⽤信息。通用信息性首部如下：            ⾸部      描述              Connection      允许客户端和服务器指定与请求/响应连接有关的选项              Date      提供⽇期和时间标志，说明报⽂是什么时间创建的，并列出了首部可接受的日期格式              M...",
                          "content"  : "本文对HTTP报文中常见的首部做下说明。通用首部有些⾸部提供了与报⽂相关的最基本的信息，它们被称为通⽤⾸部。它们像和事佬⼉⼀样，不论报⽂是何类型，都为其提供⼀些有⽤信息。通用信息性首部如下：            ⾸部      描述              Connection      允许客户端和服务器指定与请求/响应连接有关的选项              Date      提供⽇期和时间标志，说明报⽂是什么时间创建的，并列出了首部可接受的日期格式              MIME-Version      给出了发送端使⽤的MIME版本              Trailer      如果报⽂采⽤了分块传输编码（chunked transfer encoding）⽅式，就可以⽤这个⾸部列出位于报⽂拖挂（trailer）部分的⾸部集合              Transfer-Encoding      告知接收端为了保证报⽂的可靠传输，对报⽂采⽤了什么编码⽅式              Update      给出了发送端可能想要“升级”使⽤的新版本或协议              Via      显⽰了报⽂经过的中间节点（代理、⽹关）      通用缓存性首部如下：HTTP/1.0 引⼊了第⼀个允许 HTTP 应⽤程序缓存对象本地副本的⾸部，这样就不需要总是直接从源端服务器获取了。最新的 HTTP 版本有⾮常丰富的缓存参数集。            ⾸部      描述              Cache-Control      ⽤于随报⽂传送缓存指⽰              Pragma      另⼀种随报⽂传送指⽰的⽅式，但并不专⽤于缓存      请求首部请求⾸部是只在请求报⽂中有意义的⾸部。⽤于说明是谁或什么在发送请求、请求源⾃何处，或者客户端的喜好及能⼒。服务器可以根据请求⾸部给出的客户端信息，试着为客户端提供更好的响应。请求信息性首部如下：            ⾸部      描述              Client-IP      提供了运⾏客户端的机器的IP地址              From      提供了客户端⽤户的E-mail地址              Host      给出了接收请求的服务器的主机名和端⼜号              Referer      提供了包含当前请求URI的⽂档的URL              UA-Color      提供了与客户端显⽰器的显⽰颜⾊有关的信息              UA-CPU      给出了客户端CPU的类型或制造商              UA-Disp      提供了与客户端显⽰器（屏幕）能⼒有关的信息              UA-OS      给出了运⾏在客户端机器上的操作系统名称及版本              UA-Pixels      提供了客户端显⽰器的像素信息              User-Agent      将发起请求的应⽤程序名称告知服务器        Accept首部Accept ⾸部为客户端提供了⼀种将其喜好和能⼒告知服务器的⽅式，包括它们想要什么，可以使⽤什么，以及最重要的，它们不想要什么。这样，服务器就可以根据这些额外信息，对要发送的内容做出更明智的决定。Accept ⾸部会使连接的两端都受益。客户端会得到它们想要的内容，服务器则不会浪费其时间和带宽来发送客户端⽆法使⽤的东西。常用Accept首部如下：            ⾸部      描述              Accept      告诉服务器能够发送哪些媒体类型              Accept-Charset      告诉服务器能够发送哪些字符集              Accept-Encoding      告诉服务器能够发送哪些编码⽅式              Accept-Language      告诉服务器能够发送哪些语⾔              TE      告诉服务器可以使⽤哪些扩展传输编码        条件请求首部有时客户端希望为请求加上某些限制。常用条件请求首部如下：            ⾸部      描述              Expect      允许客户端列出某请求所要求的服务器⾏为              If-Match      如果实体标记与⽂档当前的实体标记相匹配，就获取这份⽂档              If-Modified-Since      除⾮在某个指定的⽇期之后资源被修改过，否则就限制这个请求              If-None-Match      如果提供的实体标记与当前⽂档的实体标记不相符，就获取⽂档              If-Range      允许对⽂档的某个范围进⾏条件请求              If-Unmodified-Since      除⾮在某个指定⽇期之后资源没有被修改过，否则就限制这个请求              Range      如果服务器⽀持范围请求，就请求资源的指定范围        安全请求首部HTTP 本⾝就⽀持⼀种简单的机制，可以对请求进⾏质询 / 响应认证。这种机制要求客户端在获取特定的资源之前，先对⾃⾝进⾏认证，这样就可以使事务稍微安全⼀些。常用安全请求首部如下：            ⾸部      描述              Authorization      包含了客户端提供给服务器，以便对其⾃⾝进⾏认证的数据              Cookie      客户端⽤它向服务器传送⼀个令牌——它并不是真正的安全⾸部，但确实隐含了安全功能        代理请求首部随着因特⽹上代理的普遍应⽤，⼈们定义了⼏个⾸部来协助其更好地⼯作。常用代理请求首部如下：            ⾸部      描述              Max-Forward      在通往源端服务器的路径上，将请求转发给其他代理或⽹关的最⼤次数——与TRACE⽅法⼀同使⽤              Proxy-Authorization      与Authorization⾸部相同，但这个⾸部是在与代理进⾏认证时使⽤的              Proxy-Connection      与Connection⾸部相同，但这个⾸部是在与代理建⽴连接时使⽤的      响应首部响应报⽂有⾃⼰的响应⾸部集。响应⾸部为客户端提供了⼀些额外信息，⽐如谁在发送响应、响应者的功能，甚⾄与响应相关的⼀些特殊指令。常用响应信息类首部如下：            ⾸部      描　　述              Age      （从最初创建开始）响应持续时间              Public      服务器为其资源⽀持的请求⽅法列表              Retry-After      如果资源不可⽤的话，在此⽇期或时间重试              Server      服务器应⽤程序软件的名称和版本              Title      对HTML⽂档来说，就是HTML⽂档的源端给出的标题              Warning      ⽐原因短语中更详细⼀些的警告报⽂        协商首部如果资源有多种表⽰⽅法——⽐如，如果服务器上有某⽂档的法语和德语译稿，HTTP/1.1 可以为服务器和客户端提供对资源进⾏协商的能⼒。常用协商首部如下：            ⾸部      描述              Accept-Ranges      对此资源来说，服务器可接受的范围类型              Vary      服务器查看的其他⾸部的列表，可能会使响应发⽣变化；也就是说，这是⼀个⾸部列表，服务器会根据这些⾸部的内容挑选出最适合的资源版本发送给客户端        安全响应首部HTTP对应安全请求首部 的质询 / 响应认证机制的响应侧。常用安全响应首部如下：            ⾸部      描述              ProxyAuthenticate      来⾃代理的对客户端的质询列表              Set-Cookie      不是真正的安全⾸部，但隐含有安全功能；可以在客户端设置⼀个令牌，以便服务器对客户端进⾏标识              WWW-Authenticate      来⾃服务器的对客户端的质询列表      实体首部有很多⾸部可以⽤来描述 HTTP 报⽂的负荷。由于请求和响应报⽂中都可能包含实体部分，所以在这两种类型的报⽂中都可能出现这些⾸部。实体的信息性⾸部如下：            ⾸部      描述              Allow      列出了可以对此实体执⾏的请求⽅法              Location      告知客户端实体实际上位于何处；⽤于将接收端定向到资源的（可能是新的）位置（URL）上去        内容首部内容⾸部提供了与实体内容有关的特定信息，说明了其类型、尺⼨以及处理它所需的其他有⽤信息。            ⾸部      描述              Content-Base      解析主体中的相对URL时使⽤的基础URL              Content-Encoding      对主体执⾏的任意编码⽅式              Content-Language      理解主体时最适宜使⽤的⾃然语⾔              Content-Length      主体的长度或尺⼨              Content-Location      资源实际所处的位置              Content-MD5      主体的MD5校验和              Content-Range      在整个资源中此实体表⽰的字节范围              Content-Type      这个主体的对象类型        实体缓存首部通⽤的缓存⾸部说明了如何或什么时候进⾏缓存。实体的缓存⾸部提供了与被缓存实体有关的信息。常用实体缓存⾸部如下：            ⾸部      描　　述              ETag      与此实体相关的实体标记17              Expires      实体不再有效，要从原始的源端再次获取此实体的⽇期和时间              Last-Modified      这个实体最后⼀次被修改的⽇期和时间      "
                        } ,
                     
                        {
                          "title"    : "HTTP - 连接管理",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/29/http-connect.html",
                          "date"     : "April 29, 2018",
                          "excerpt"  : "TCP连接世界上⼏乎所有的 HTTP 通信都是由 TCP/IP 承载的，TCP/IP 是全球计算机及⽹络设备都在使⽤的⼀种常⽤的分组交换⽹络分层协议集。客户端应⽤程序可以打开⼀条 TCP/IP 连接，连接到可能运⾏在世界任何地⽅的服务器应⽤程序。⼀旦连接建⽴起来了，在客户端和服务器的计算机之间交换的报⽂就永远不会丢失、受损或失序。完整的连接执行流程如下图所示:TCP是分段、由IP分组传送TCP 的数据是通过名为 IP 分组（或 IP 数据报）的⼩数据块来发送的。这样的话，如图 a 所⽰，H...",
                          "content"  : "TCP连接世界上⼏乎所有的 HTTP 通信都是由 TCP/IP 承载的，TCP/IP 是全球计算机及⽹络设备都在使⽤的⼀种常⽤的分组交换⽹络分层协议集。客户端应⽤程序可以打开⼀条 TCP/IP 连接，连接到可能运⾏在世界任何地⽅的服务器应⽤程序。⼀旦连接建⽴起来了，在客户端和服务器的计算机之间交换的报⽂就永远不会丢失、受损或失序。完整的连接执行流程如下图所示:TCP是分段、由IP分组传送TCP 的数据是通过名为 IP 分组（或 IP 数据报）的⼩数据块来发送的。这样的话，如图 a 所⽰，HTTP 就是“HTTP over TCP over IP”这个“协议栈”中的最顶层了。其安全版本 HTTPS 就是在 HTTP 和 TCP 之间插⼊了⼀个（称为 TLS 或 SSL 的）密码加密层（图 b）。HTTP 要传送⼀条报⽂时，会以流的形式将报⽂数据的内容通过⼀条打开的 TCP 连接按序传输。TCP 收到数据流之后，会将数据流砍成被称作段的⼩数据块，并将段封装在 IP 分组中，通过因特⽹进⾏传输（如下图）。所有这些⼯作都是由 TCP/IP 软件来处理的，HTTP 程序员什么都看不到。保持TCP连接的连续不间断性TCP连接是通过 4 个值来识别的：  &lt; 源IP 地址、源端⼝号、⽬的IP 地址、⽬的端⼝号&gt;这 4 个值⼀起唯⼀地定义了⼀条连接。两条不同的 TCP 连接不能拥有 4 个完全相同的地址组件值（但不同连接的部分组件可以拥有相同的值）。TCP套接字编程参考 php实现webSocketTCP性能HTTP事务延迟HTTP 事务主要的连接、传输以及处理时延主要原因：      客户端⾸先需要根据 URI 确定 Web 服务器的 IP 地址和端⼜号。如果最近没有对 URI 中的主机名进⾏访问，通过 DNS 解析系统将 URI 中的主机名转换成⼀个 IP 地址可能要花费数⼗秒的时间。(⼤多数 HTTP 客户端都有⼀个⼩的 DNS 缓存，⽤来保存近期所访问站点的 IP 地址。如果已经在本地“缓存”（记录）了 IP 地址，查询就可以⽴即完成。因为⼤多数 Web 浏览器浏览的都是少数常⽤站点，所以通常都可以很快地将主机名解析出来。)        客户端会向服务器发送⼀条 TCP 连接请求，并等待服务器回送⼀个请求接受应答。每条新的 TCP 连接都会有连接建⽴时延。这个值通常最多只有⼀两秒钟，但如果有数百个 HTTP 事务的话，这个值会快速地叠加上去。        ⼀旦连接建⽴起来了，客户端就会通过新建⽴的 TCP 管道来发送HTTP 请求。数据到达时，Web 服务器会从 TCP 连接中读取请求报⽂，并对请求进⾏处理。因特⽹传输请求报⽂，以及服务器处理请求报⽂都需要时间。  TCP连接的握⼿时延建⽴⼀条新的 TCP 连接时，甚⾄是在发送任意数据之前，TCP 软件之间会交换⼀系列的 IP 分组，对连接的有关参数进⾏沟通（如下图）。如果连接只⽤来传送少量数据，这些交换过程就会严重降低 HTTP 的性能。TCP三次握手如下：  请求新的 TCP 连接时，客户端要向服务器发送⼀个⼩的 TCP 分组（通常是 40 ～ 60 个字节）。这个分组中设置了⼀个特殊的 SYN 标记，说明这是⼀个连接请求。（如上图a）。  如果服务器接受了连接，就会对⼀些连接参数进⾏计算，并向客户端回送⼀个 TCP 分组，这个分组中的 SYN 和 ACK 标记都被置位，说明连接请求已被接受（如上图b）。  最后，客户端向服务器回送⼀条确认信息，通知它连接已成功建⽴（如上图c）。现代的 TCP 栈都允许客户端在这个确认分组中发送数据。TCP慢启动TCP 数据传输的性能还取决于 TCP 连接的使⽤期（age）。TCP 连接会随着时间进⾏⾃我“调谐”，起初会限制连接的最⼤速度，如果数据成功传输，会随着时间的推移提⾼传输的速度。这种调谐被称为 TCP 慢启动（slow start），⽤于防⽌因特⽹的突然过载和拥塞。TCP 慢启动限制了⼀个 TCP 端点在任意时刻可以传输的分组数。简单来说，每成功接收⼀个分组，发送端就有了发送另外两个分组的权限。如果某个 HTTP 事务有⼤量数据要发送，是不能⼀次将所有分组都发送出去的。必须发送⼀个分组，等待确认；然后可以发送两个分组，每个分组都必须被确认，这样就可以发送四个分组了，以此类推。这种⽅式被称为“打开拥塞窗⼜”。由于存在这种拥塞控制特性，所以新连接的传输速度会⽐已经交换过⼀定量数据的、“已调谐”连接慢⼀些。由于已调谐连接要更快⼀些，所以HTTP 中有⼀些可以重⽤现存连接的⼯具。（HTTP持久连接）TIME_WAIT累积与端⼜耗尽TIME_WAIT 端⼜耗尽是很严重的性能问题，会影响到性能基准，但在现实中相对较少出现。⼤多数遇到性能基准问题的⼈最终都会碰到这个问题，⽽且性能都会变得出乎意料地差，所以这个问题值得特别关注。当某个 TCP 端点关闭 TCP 连接时，会在内存中维护⼀个⼩的控制块，⽤来记录最近所关闭连接的 IP 地址和端⼜号。这类信息只会维持⼀⼩段时间，通常是所估计的最⼤分段使⽤期的两倍（称为 2MSL，通常为 2 分钟）左右，以确保在这段时间内不会创建具有相同地址和端⼜号的新连接。实际上，这个算法可以防⽌在两分钟内创建、关闭并重新创建两个具有相同 IP 地址和端⼜号的连接。现在⾼速路由器的使⽤，使得重复分组⼏乎不可能在连接关闭的⼏分钟后，出现在服务器上。有些操作系统会将 2MSL 设置为⼀个较⼩的值，但修改此值时要特别⼩⼼。分组确实会被复制，如果来⾃之前连接的复制分组插⼊了具有相同连接值的新 TCP 流，会破坏 TCP 数据。2MSL 的连接关闭延迟通常不是什么问题，但在性能基准环境下就可能会成为⼀个问题。进⾏性能基准测试时，通常只有⼀台或⼏台⽤来产⽣流量的计算机连接到某系统中去，这样就限制了连接到服务器的客户端 IP 地址数。⽽且，服务器通常会在 HTTP 的默认 TCP 端⼜ 80 上进⾏监听。⽤TIME_WAIT 防⽌端⼜号重⽤时，这些情况也限制了可⽤的连接值组合。在只有⼀个客户端和⼀台 Web 服务器的异常情况下，构建⼀条 TCP 连接的 4 个值：  &lt;source-IP-address, source-port, destination-IP-address, destination-port&gt;其中的 3 个都是固定的——只有源端⼜号可以随意改变：  &lt;client-IP, source-port, server-IP, 80&gt;客户端每次连接到服务器上去时，都会获得⼀个新的源端⼜，以实现连接的唯⼀性。但由于可⽤源端⼜的数量有限（⽐如，60 000 个），⽽且在2MSL 秒（⽐如，120 秒）内连接是⽆法重⽤的，连接率就被限制在了 60000/120=500 次 / 秒。如果再不断进⾏优化，并且服务器的连接率不⾼于500 次 / 秒，就可确保不会遇到 TIME_WAIT 端⼜耗尽问题。要修正这个问题，可以增加客户端负载⽣成机器的数量，或者确保客户端和服务器在循环使⽤⼏个虚拟 IP 地址以增加更多的连接组合。即使没有遇到端⼜耗尽问题，也要特别⼩⼼有⼤量连接处于打开状态的情况，或为处于等待状态的连接分配了⼤量控制块的情况。在有⼤量打开连接或控制块的情况下，有些操作系统的速度会严重减缓。HTTP连接处理串行事务处理延迟如果只对连接进⾏简单的管理，TCP 的性能时延可能会叠加起来。⽐如，假设有⼀个包含了 3 个嵌⼊图⽚的 Web 页⾯。浏览器需要发起 4 个 HTTP事务来显⽰此页⾯： 1 个⽤于顶层的 HTML 页⾯，3 个⽤于嵌⼊的图⽚。如果每个事务都需要（串⾏地建⽴）⼀条新的连接，那么连接时延和慢启动时延就会叠加起来（如下图)。并行连接HTTP 允许客户端打开多条连接，并⾏地执⾏多个 HTTP事务。在这个例⼦中，并⾏加载了四幅嵌⼊式图⽚，每个事务都有⾃⼰的TCP 连接。并行连接时间如下图，⾸先装载的是封闭的 HTML 页⾯，然后并⾏处理其余的 3 个事务，每个事务都有⾃⼰的连接。图⽚的装载是并⾏的，连接的时延也是重叠的。(由于软件开销的存在，每个连接请求之间总是会有⼀些⼩的时延，但连接请求和传输时间基本上都是重叠起来的。)但并行不一定更快      客户端的⽹络带宽不足，并⾏加载多个对象，每个对象都会去竞争这有限的带宽，每个对象都会以较慢的速度按⽐例加载，这样带来的性能提升就很⼩，甚⾄没什么提升。        打开⼤量连接会消耗很多内存资源，从⽽引发⾃⾝的性能问题。  实际上，浏览器确实使⽤了并⾏连接，但它们会将并⾏连接的总数限制为⼀个较⼩的值（通常是 4 个）。服务器可以随意关闭来⾃特定客户端的超量连接。持久连接HTTP/1.1（以及 HTTP/1.0 的各种增强版本）允许 HTTP 设备在事务处理结束之后将 TCP 连接保持在打开状态，以便为未来的 HTTP 请求重⽤现存的连接。在事务处理结束之后仍然保持在打开状态的 TCP 连接被称为持久连接。⾮持久连接会在每个事务结束之后关闭。持久连接会在不同事务之间保持打开状态，直到客户端或服务器决定将其关闭为⽌。重⽤已对⽬标服务器打开的空闲持久连接，就可以避开缓慢的连接建⽴阶段。⽽且，已经打开的连接还可以避免慢启动的拥塞适应阶段，以便更快速地进⾏数据的传输。持久连接与并⾏连接配合使⽤可能是最⾼效的⽅式。现在，很多 Web 应⽤程序都会打开少量的并⾏连接，其中的每⼀个都是持久连接。  HTTP/1.0+ keep-alive连接很多 HTTP/1.0 浏览器和服务器都进⾏了扩展，以⽀持⼀种被称为 keep-alive 连接的早期实验型持久连接。串行与并行的性能比较如下图：  HTTP/1.1持久连接HTTP/1.1 逐渐停⽌了对 keep-alive 连接的⽀持，⽤⼀种名为持久连接（persistent connection）的改进型设计取代了它。持久连接的⽬的与 keepalive连接的⽬的相同，但⼯作机制更优⼀些。与 HTTP/1.0+ 的 keep-alive 连接不同，HTTP/1.1 持久连接在默认情况下是激活的。除⾮特别指明，否则 HTTP/1.1 假定所有连接都是持久的。要在事务处理结束之后将连接关闭，HTTP/1.1 应⽤程序必须向报⽂中显式地添加⼀个 Connection: close ⾸部。这是与以前的 HTTP 协议版本很重要的区别，在以前的版本中，keep-alive 连接要么是可选的，要么根本就不⽀持。HTTP/1.1 客户端假定在收到响应后，除⾮响应中包含了 Connection:close ⾸部，不然 HTTP/1.1 连接就仍维持在打开状态。但是，客户端和服务器仍然可以随时关闭空闲的连接。不发送 Connection: close 并不意味着服务器承诺永远将连接保持在打开状态。持久连接的限制和规则      发送了 Connection: close 请求⾸部之后，客户端就⽆法在那条连接上发送更多的请求了。        如果客户端不想在连接上发送其他请求了，就应该在最后⼀条请求中发送⼀个 Connection: close 请求⾸部。        只有当连接上所有的报⽂都有正确的、⾃定义报⽂长度时——也就是说，实体主体部分的长度都和相应的 Content-Length ⼀致，或者是⽤分块传输编码⽅式编码的——连接才能持久保持。        HTTP/1.1 的代理必须能够分别管理与客户端和服务器的持久连接——每个持久连接都只适⽤于⼀跳传输。（由于较⽼的代理会转发 Connection ⾸部，所以）HTTP/1.1 的代理服务器不应该与 HTTP/1.0 客户端建⽴持久连接，除⾮它们了解客户端的处理能⼒。实际上，这⼀点是很难做到的，很多⼚商都违背了这⼀原则。        尽管服务器不应该试图在传输报⽂的过程中关闭连接，⽽且在关闭连接之前⾄少应该响应⼀条请求，但不管 Connection ⾸部取了什么值，HTTP/1.1 设备都可以在任意时刻关闭连接。        HTTP/1.1 应⽤程序必须能够从异步的关闭中恢复出来。只要不存在可能会累积起来的副作⽤，客户端都应该重试这条请求。        除⾮重复发起请求会产⽣副作⽤，否则如果在客户端收到整条响应之前连接关闭了，客户端就必须要重新发起请求。        ⼀个⽤户客户端对任何服务器或代理最多只能维护两条持久连接，以防服务器过载。代理可能需要更多到服务器的连接来⽀持并发⽤户的通信，所以，如果有 N 个⽤户试图访问服务器的话，代理最多要维持2N 条到任意服务器或⽗代理的连接。  管道化连接HTTP/1.1 允许在持久连接上可选地使⽤请求管道。这是相对于 keep-alive连接的又⼀性能优化。在响应到达之前，可以将多条请求放⼊队列。当第⼀条请求通过⽹络流向地球另⼀端的服务器时，第⼆条和第三条请求也可以开始发送了。在⾼时延⽹络条件下，这样做可以降低⽹络的环回时间，提⾼性能。与串行、持久对比如下图:限制：      如果 HTTP 客户端⽆法确认连接是持久的，就不应该使⽤管道。        必须按照与请求相同的顺序回送 HTTP 响应。HTTP 报⽂中没有序列号标签，因此如果收到的响应失序了，就没办法将其与请求匹配起来了。        HTTP 客户端必须做好连接会在任意时刻关闭的准备，还要准备好重发所有未完成的管道化请求。如果客户端打开了⼀条持久连接，并⽴即发出了 10 条请求，服务器可能在只处理了，⽐⽅说，5 条请求之后关闭连接。剩下的 5 条请求会失败，客户端必须能够应对这些过早关闭连接的情况，重新发出这些请求。        HTTP 客户端不应该⽤管道化的⽅式发送会产⽣副作⽤的请求（⽐如POST）。总之，出错的时候，管道化⽅式会阻碍客户端了解服务器执⾏的是⼀系列管道化请求中的哪⼀些。由于⽆法安全地重试 POST 这样的⾮幂等请求，所以出错时，就存在某些⽅法永远不会被执⾏的风险。  关闭连接TCP 连接是双向的。TCP 连接的每⼀端都有⼀个输⼊队列和⼀个输出队列，⽤于数据的读或写。放⼊⼀端输出队列中的数据最终会出现在另⼀端的输⼊队列中。如下图：  完全关闭与半关闭应⽤程序可以关闭 TCP 输⼊和输出信道中的任意⼀个，或者将两者都关闭了。套接字调⽤ close() 会将 TCP 连接的输⼊和输出信道都关闭了。这被称作“完全关闭”，如图 4-20a 所⽰。还可以⽤套接字调⽤shutdown() 单独关闭输⼊或输出信道。这被称为“半关闭”，如下图所示：  TCP关闭及重置错误简单的 HTTP 应⽤程序可以只使⽤完全关闭。但当应⽤程序开始与很多其他类型的 HTTP 客户端、服务器和代理进⾏对话且开始使⽤管道化持久连接时，使⽤半关闭来防⽌对等实体收到⾮预期的写⼊错误就变得很重要了。总之，关闭连接的输出信道总是很安全的。连接另⼀端的对等实体会在从其缓冲区中读出所有数据之后收到⼀条通知，说明流结束了，这样它就知道你将连接关闭了。关闭连接的输⼊信道⽐较危险，除⾮你知道另⼀端不打算再发送其他数据了。如果另⼀端向你已关闭的输⼊信道发送数据，操作系统就会向另⼀端的机器回送⼀条 TCP“连接被对端重置”的报⽂，如下图所⽰。⼤部分操作系统都会将这种情况作为很严重的错误来处理，删除对端还未读取的所有缓存数据。对管道化连接来说，这是⾮常糟糕的事情。  正常关闭HTTP 规范建议，当客户端或服务器突然要关闭⼀条连接时，应该“正常地关闭传输连接”，但它并没有说明应该如何去做。总之，实现正常关闭的应⽤程序⾸先应该关闭它们的输出信道，然后等待连接另⼀端的对等实体关闭它的输出信道。当两端都告诉对⽅它们不会再发送任何数据（⽐如关闭输出信道）之后，连接就会被完全关闭，⽽不会有重置的危险。但不幸的是，⽆法确保对等实体会实现半关闭，或对其进⾏检查。因此，想要正常关闭连接的应⽤程序应该先半关闭其输出信道，然后周期性地检查其输⼊信道的状态（查找数据，或流的末尾）。如果在⼀定的时间区间内对端没有关闭输⼊信道，应⽤程序可以强制关闭连接，以节省资源。"
                        } ,
                     
                        {
                          "title"    : "HTTP - 报文 - 状态码",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/27/http-message-status.html",
                          "date"     : "April 27, 2018",
                          "excerpt"  : "本文对HTTP报文中常见的状态码做下说明。所有状态码参见HTTP状态码100~199 信息性状态码HTTP/1.1 向协议中引⼊了信息性状态码。这些状态码相对较新，关于其复杂性和感知价值存在⼀些争议。已定义的信息性状态码如下：            状态码      原因短语      含义              100      Continue      说明收到了请求的初始部分，请客户端继续。发送了这个状态码之后，服务器在收到请求之后必须进⾏响应。              10...",
                          "content"  : "本文对HTTP报文中常见的状态码做下说明。所有状态码参见HTTP状态码100~199 信息性状态码HTTP/1.1 向协议中引⼊了信息性状态码。这些状态码相对较新，关于其复杂性和感知价值存在⼀些争议。已定义的信息性状态码如下：            状态码      原因短语      含义              100      Continue      说明收到了请求的初始部分，请客户端继续。发送了这个状态码之后，服务器在收到请求之后必须进⾏响应。              101      Switching Protocols      说明服务器正在根据客户端的指定，将协议切换成Update⾸部所列的协议。      由于目前应用场景有限，这里不做过多说明。200~299 成功状态码客户端发起请求时，这些请求通常都是成功的。服务器有⼀组⽤来表⽰成功的状态码，分别对应于不同类型的请求。            状态码      原因短语      含义              200      OK      请求没问题，实体的主体部分包含了所请求的资源              201      Created      ⽤于创建服务器对象的请求（⽐如，PUT）。响应的实体主体部分中应该包含各种引⽤了已创建的资源的URL，Location⾸部包含的则是最具体的引⽤。服务器必须在发送这个状态码之前创建好对象              202      Accepted      请求已被接受，但服务器还未对其执⾏任何动作。不能保证服器会完成这个请求；这只是意味着接受请求时，它看起来是有的。服务器应该在实体的主体部分包含对请求状态的描述，或许还应该有对请求完成时间的估计（或者包含⼀个指针，指向可以获取此信息的位置）              203      Non-Authoritative Information      实体⾸部包含的信息不是来⾃于源端服务器，⽽是来⾃资源的⼀份副本。如果中间节点上有⼀份资源副本，但⽆法或者没有对它所发送的与资源有关的元信息（⾸部）进⾏验证，就会出现这种情况。这种响应码并不是⾮⽤不可的；如果实体⾸部来⾃源端服务器，响应为200状态的应⽤程序就可以将其作为⼀种可选项使⽤              204      No Content      响应报⽂中包含若⼲⾸部和⼀个状态⾏，但没有实体的主体部分。主要⽤于在浏览器不转为显⽰新⽂档的情况下，对其进⾏更新（⽐如刷新⼀个表单页⾯）              205      Reset Content      另⼀个主要⽤于浏览器的代码。负责告知浏览器清除当前页⾯中的所有HTML 表单元素              206      Partial Content      成功执⾏了⼀个部分或Range（范围）请求。稍后我们会看到，客户端可以通过⼀些特殊的⾸部来获取部分或某个范围内的⽂档——这个状态码就说明范围请求成功了。206响应中必须包含Content-Range、Date以及ETag或Content-Location⾸部。      300~399 重定向状态码重定向状态码要么告知客户端使⽤替代位置来访问他们所感兴趣的资源，要么就提供⼀个替代的响应⽽不是资源的内容。如果资源已被移动，可发送⼀个重定向状态码和⼀个可选的 Location ⾸部来告知客户端资源已被移⾛，以及现在可以在哪⾥找到它，这样，浏览器就可以在不打扰使⽤者的情况下，透明地转⼊新的位置了。可以通过某些重定向状态码对资源的应⽤程序本地副本与源端服务器上资源进⾏验证。⽐如，HTTP 应⽤程序可以查看其资源的本地副本是否仍然是最新的，或者在源端服务器上资源是否被修改过。总之，在对那些包含了重定向状态码的⾮ HEAD 请求进⾏响应时，最好要包含⼀个实体，并在实体中包含描述信息和指向（多个）重定向 URL 的链接。            状态码      原因短语      含义              300      Multiple Choices      客户端请求⼀个实际指向多个资源的URL时会返回这个状态码，⽐如服务器上有某个HTML⽂档的英语和法语版本。返回这个代码时会带有⼀个选项列表；这样⽤户就可以选择他希望使⽤的那⼀项了。有多个版本可⽤时，客户端需要沟通解决，服务器可以在Location⾸部包含⾸选URL              301      Moved Permanently      在请求的URL已被移除时使⽤。响应的Location⾸部中应该包含资源现在所处的URL              302      Found      与301状态码类似；但是，客户端应该使⽤Location⾸部给出的URL来临时定位资源。将来的请求仍应使⽤⽼的URL              303      See Other      告知客户端应该⽤另⼀个URL来获取资源。新的URL位于响应报⽂的 Location ⾸部。其主要⽬的是允许POST请求的响应将客户端定向到某个资源上去              304      Not Modified      客户端可以通过所包含的请求⾸部，使其请求变成有条件的。如果客户端发起了⼀个条件GET请求，⽽最近资源未被修改的话， 就可以⽤这个状态码来说明资源未被修改。带有这个状态码的响应不应该包含实体的主体部分              305      Use Proxy      ⽤来说明必须通过⼀个代理来访问资源；代理的位置由Location⾸部给出。很重要的⼀点是，客户端是相对某个特定资源来解析这条响应的，不能假定所有请求，甚⾄所有对持有所请求资源的服务器的请求都通过这个代理进⾏。如果客户端错误地让代理介⼊了某条请求，可能会引发破坏性的⾏为，⽽且会造成安全漏洞              306      （未使⽤）      当前未使⽤              307      Temporary Redirect      与301状态码类似；但客户端应该使⽤Location⾸部给出的URL来临时定位资源。将来的请求应该使⽤⽼的URL      302、303、307区别当 HTTP/1.0 客户端发起⼀个 POST 请求，并在响应中收到 302 重定向状态码时，它会接受 Location ⾸部的重定向 URL，并向那个 URL 发起⼀个GET 请求（⽽不会像原始请求中那样发起 POST 请求）。  HTTP/1.0 服务器希望 HTTP/1.0 客户端这么做——如果 HTTP/1.0 服务器收到来⾃ HTTP/1.0 客户端的 POST 请求之后发送了 302 状态码，服务器就期望客户端能够接受重定向 URL，并向重定向的 URL 发送⼀个 GET 请求。  问题出在 HTTP/1.1。HTTP/1.1 规范使⽤ 303 状态码来实现同样的⾏为（服务器发送 303 状态码来重定向客户端的 POST 请求，在它后⾯跟上⼀个 GET 请求）。  为了避开这个问题，HTTP/1.1 规范指出，对于 HTTP/1.1 客户端，⽤ 307状态码取代 302 状态码来进⾏临时重定向。这样服务器就可以将 302 状态码保留起来，为 HTTP/1.0 客户端使⽤了。400～499 客户端错误状态码            状态码      原因短语      含义              400      Bad Request      ⽤于告知客户端它发送了⼀个错误的请求              401      Unauthorized      与适当的⾸部⼀同返回，在这些⾸部中请求客户端在获取对资源的访问权之前，对⾃⼰进⾏认证。              402      Payment Required      现在这个状态码还未使⽤，但已经被保留，以作未来之⽤              403      Forbidden      ⽤于说明请求被服务器拒绝了。如果服务器想说明为什么拒绝请求，可以包含实体的主体部分来对原因进⾏描述。但这个状态码通常是在服务器不想说明拒绝原因的时候使⽤的              404      Not Found      ⽤于说明服务器⽆法找到所请求的URL。通常会包含⼀个实体，以便客户端应⽤程序显⽰给⽤户看              405      Method Not Allowed      发起的请求中带有所请求的URL不⽀持的⽅法时，使⽤此状态码。应该在响应中包含Allow⾸部，以告知客户端对所请求的资源可以使⽤哪些⽅法。              406      Not Acceptable      客户端可以指定参数来说明它们愿意接收什么类型的实体。服务器没有与客户端可接受的URL相匹配的资源时，使⽤此代码。通常，服务器会包含⼀些⾸部，以便客户端弄清楚为什么请求⽆法满⾜。              407      Proxy Authentication Required      与401状态码类似，但⽤于要求对资源进⾏认证的代理服务器              408      Request Timeout      如果客户端完成请求所花的时间太长，服务器可以回送此状态码，并关闭连接。超时时长随服务器的不同有所不同，但通常对所有的合法请求来说，都是够长的              409      Conflict      ⽤于说明请求可能在资源上引发的⼀些冲突。服务器担⼼请求会引发冲突时，可以发送此状态码。响应中应该包含描述冲突的主体              410      Gone      与404类似，只是服务器曾经拥有过此资源。主要⽤于Web站点的维护，这样服务器的管理者就可以在资源被移除的情况下通知客户端了              411      Length Required      服务器要求在请求报⽂中包含Content-Length⾸部时使⽤。              412      Precondition Failed      客户端发起了条件请求，且其中⼀个条件失败了的时候使⽤。客户端包含了Expect⾸部时发起的就是条件请求。更多有关Expect⾸部的内容请参见附录C中Expect部分              413      Request Entity Too Large      客户端发送的实体主体部分⽐服务器能够或者希望处理的要⼤时，使⽤此状态码              414      Request URI Too Long      客户端所发请求中的请求URL⽐服务器能够或者希望处理的要长时，使⽤此状态码              415      Unsupported Media Type      服务器⽆法理解或⽆法⽀持客户端所发实体的内容类型时，使⽤此状态码              416      Requested Range Not Satisfiable      请求报⽂所请求的是指定资源的某个范围，⽽此范围⽆效或⽆法满⾜时，使⽤此状态码              417      Expectation Failed      请求的Expect请求⾸部包含了⼀个期望，但服务器⽆法满⾜此期望时，使⽤此状态码。如果代理或其他中间应⽤程序有确切证据说明源端服务器会为某请求产⽣⼀个失败的期望，就可以发送这个响应状态码      500～599 服务器错误状态码            状态码      原因短语      含义              500      Internal Server Error      服务器遇到⼀个妨碍它为请求提供服务的错误时，使⽤此状态码              501      Not Implemented      客户端发起的请求超出服务器的能⼒范围（⽐如，使⽤了服务器不⽀持的请求⽅法）时，使⽤此状态码作为代理或⽹关使⽤的服务器从请求响应链的下⼀条链路上              502      Bad Gateway      收到了⼀条伪响应（⽐如，它⽆法连接到其⽗⽹关）时，使⽤此状态码              503      Service Unavailable      ⽤来说明服务器现在⽆法为请求提供服务，但将来可以。如果服务器知道什么时候资源会变为可⽤的，可以在响应中包含⼀个Retry-After⾸部。更多有关Retry-After⾸部的              504      Gateway Timeout      与状态码408类似，只是这⾥的响应来⾃⼀个⽹关或代理，它们在等待另⼀服务器对其请求进⾏响应时超时了              505      HTTP Version Not Supported      服务器收到的请求使⽤了它⽆法或不愿⽀持的协议版本时，使⽤此状态码。有些服务器应⽤程序会选择不⽀持协议      "
                        } ,
                     
                        {
                          "title"    : "HTTP - 报文 - 方法",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/27/http-message-method.html",
                          "date"     : "April 27, 2018",
                          "excerpt"  : "本文对HTTP报文中常见的方法做下说明。GET是最常⽤的⽅法。通常⽤于请求服务器发送某个资源。HTTP/1.1 要求服务器实现此⽅法。HEADHEAD ⽅法与 GET ⽅法的⾏为很类似，但服务器在响应中只返回⾸部。不会返回实体的主体部分。这就允许客户端在未获取实际资源的情况下，对资源的⾸部进⾏检查。使⽤ HEAD，可以：  在不获取资源的情况下了解资源的情况（⽐如，判断其类型）；  通过查看响应中的状态码，看看某个对象是否存在；  通过查看⾸部，测试资源是否被修改了。服务器开发者必须确保返...",
                          "content"  : "本文对HTTP报文中常见的方法做下说明。GET是最常⽤的⽅法。通常⽤于请求服务器发送某个资源。HTTP/1.1 要求服务器实现此⽅法。HEADHEAD ⽅法与 GET ⽅法的⾏为很类似，但服务器在响应中只返回⾸部。不会返回实体的主体部分。这就允许客户端在未获取实际资源的情况下，对资源的⾸部进⾏检查。使⽤ HEAD，可以：  在不获取资源的情况下了解资源的情况（⽐如，判断其类型）；  通过查看响应中的状态码，看看某个对象是否存在；  通过查看⾸部，测试资源是否被修改了。服务器开发者必须确保返回的⾸部与GET请求所返回的⾸部完全相同。遵循 HTTP/1.1 规范，就必须实现 HEAD ⽅法。PUT与 GET 从服务器读取⽂档相反，PUT ⽅法会向服务器写⼊⽂档，是让服务器⽤请求的主体部分来创建⼀个由所请求的 URL 命名的新⽂档。POST⽤来向服务器输⼊数据的，而PUT ⽤于向服务器上的资源（例如⽂件）中存储数据。TRACE请求会在⽬的服务器端发起⼀个“环回”诊断。⾏程最后⼀站的服务器会弹回⼀条 TRACE 响应，并在响应主体中携带它收到的原始请求报⽂。这样客户端就可以查看在所有中间 HTTP 应⽤程序组成的请求 / 响应链上，原始报⽂是否，以及如何被毁坏或修改过。TRACE ⽅法主要⽤于诊断；也就是说，⽤于验证请求是否如愿穿过了请求 / 响应链。它也是⼀种很好的⼯具，可以⽤来查看代理和其他应⽤程序对⽤户请求所产⽣效果。尽管 TRACE 可以很⽅便地⽤于诊断，但它确实也有缺点，它假定中间应⽤程序对各种不同类型请求（不同的⽅法——GET、HEAD、POST等）的处理是相同的。很多 HTTP 应⽤程序会根据⽅法的不同做出不同的事情——⽐如，代理可能会将 POST 请求直接发送给服务器，⽽将 GET 请求发送给另⼀个 HTTP 应⽤程序（⽐如 Web 缓存）。TRACE 并不提供区分这些⽅法的机制。通常，中间应⽤程序会⾃⾏决定对 TRACE 请求的处理⽅式。TRACE 请求中不能带有实体的主体部分。TRACE 响应的实体主体部分包含了响应服务器收到的请求的精确副本。OPTIONSOPTIONS ⽅法请求 Web 服务器告知其⽀持的各种功能。可以询问服务器通常⽀持哪些⽅法，或者对某些特殊资源⽀持哪些⽅法。这为客户端应⽤程序提供了⼀种⼿段，使其不⽤实际访问那些资源就能判定访问各种资源的最优⽅式。DELETE所做的事情就是请服务器删除请求 URL 所指定的资源。但是，客户端应⽤程序⽆法保证删除操作⼀定会被执⾏。因为HTTP 规范允许服务器在不通知客户端的情况下撤销请求。扩展方法由于HTTP设计得易于扩展，所以除了这些⽅法之外，其他服务器可能还会实现⼀些⾃⼰的请求⽅法。这些附加的⽅法是对 HTTP 规范的扩展，因此被称为扩展⽅法。常用扩展方法如下：            ⽅法      描述              LOCK      允许⽤户“锁定”资源——⽐如，可以在编辑某个资源的时候将其锁定，以防别⼈同时对其进⾏修改              MKCOL      允许⽤户创建资源              COPY      便于在服务器上复制资源              MOVE      在服务器上移动资源      "
                        } ,
                     
                        {
                          "title"    : "HTTP - 报文",
                          "category" : "",
                          "tags"     : " http",
                          "url"      : "/2018/04/23/http-message.html",
                          "date"     : "April 23, 2018",
                          "excerpt"  : "分为两类：请求报文和响应报文。请求报文格式：//起始行&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;//首部&lt;headers&gt;//实体主体&lt;entity-body&gt;响应报文格式：//起始行&lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt;//首部&lt;headers&gt;//实体主体&lt;entity-body&gt;起始行  方法（method）请求的...",
                          "content"  : "分为两类：请求报文和响应报文。请求报文格式：//起始行&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;//首部&lt;headers&gt;//实体主体&lt;entity-body&gt;响应报文格式：//起始行&lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt;//首部&lt;headers&gt;//实体主体&lt;entity-body&gt;起始行  方法（method）请求的起始⾏以⽅法作为开始，⽅法⽤来告知服务器要做些什么。常用方法如下：            ⽅法      描述      是否包含主体              GET      从服务器获取⼀份⽂档      否              HEAD      只从服务器获取⽂档的⾸部      否              POST      向服务器发送需要处理的数据      是              PUT      将请求的主体部分存储在服务器上      是              TRACE      对可能经过代理服务器传送到服务器上去的报⽂进⾏追踪      否              OPTIONS      决定可以在服务器上执⾏哪些⽅法      否              DELETE      从服务器上删除⼀份⽂档      否      具体内容请参考 HTTP - 报文 - 方法  状态码（status）⽅法是⽤来告诉服务器做什么事情的，状态码则⽤来告诉客户端，发⽣了什么事情。状态码位于响应的起始⾏中。状态码分类：            整体范围      已定义范围      分类              100～199      100～101      信息提⽰              200～299      200～206      成功              300～399      300～305      重定向              400～499      400～415      客户端错误              500～599      500～505      服务器错误      具体内容请参考 HTTP - 报文 - 状态码  版本号（version）版本号会以 HTTP/x.y 的形式出现在请求和响应报⽂的起始⾏中。为HTTP 应⽤程序提供了⼀种将⾃⼰所遵循的协议版本告知对⽅的⽅式。注意，版本号不会被当作⼩数来处理。版本中的每个数字（⽐如HTTP/1.0 中的 1 和 0）都会被当作⼀个单独的数字来处理。因此，在⽐较 HTTP 版本时，每个数字都必须单独进⾏⽐较，以便确定哪个版本更⾼。⽐如，HTTP/2.22 就⽐ HTTP/2.3 的版本要⾼，因为 22 ⽐ 3⼤。首部HTTP ⾸部字段向请求和响应报⽂中添加了⼀些附加信息。本质上来说，它们只是⼀些名 / 值对的列表。首部分类如下：            分类      说明              通用首部      既可以出现在请求报⽂中，也可以出现在响应报⽂中。              请求⾸部      提供更多有关请求的信息。              响应⾸部      提供更多有关响应的信息。              实体⾸部      描述主体的长度和内容，或者资源⾃⾝。              扩展⾸部      规范中没有定义的新⾸部。      每个 HTTP ⾸部都有⼀种简单的语法：名字后⾯跟着冒号（ ：），然后跟上可选的空格，再跟上字段值，最后是⼀个 CRLF。具体说明请查看 HTTP - 报文 - 首部实体的主体部分HTTP 报⽂的第三部分是可选的实体主体部分。实体的主体是 HTTP 报⽂的负荷。就是 HTTP 要传输的内容。HTTP 报⽂可以承载很多类型的数字数据：图⽚、视频、HTML ⽂档、软件应⽤程序、信⽤卡事务、电⼦邮件等。"
                        } ,
                     
                        {
                          "title"    : "以太坊发行代币(二)",
                          "category" : "",
                          "tags"     : " 区块链, 以太坊",
                          "url"      : "/2018/04/10/ethereum-crypto-currency-2.html",
                          "date"     : "April 10, 2018",
                          "excerpt"  : "在上一节中，已经讲了如何去发行一个简单的代币，如果没看过的同学，请先去阅读以太坊发行代币(一)这一节，我们将对之前的代币做一次升级。如果你想把你的代币卖给一个交易所，只是发送到一个其他合约的以太坊地址是不够的，因为它不会意识到这个新代币或者谁发送给它的，因为这个合约没有发布一些事件或者接口。所以对于合约，你应该首先批准它们可以从你账号转出代币，然后让它们知道它们应该怎么去做。由于里面的一些函数是必须去做一些交易操作，这里很有必要把它们弄成集成为一个内部函数（只有这个合约本身能够调用）。 /...",
                          "content"  : "在上一节中，已经讲了如何去发行一个简单的代币，如果没看过的同学，请先去阅读以太坊发行代币(一)这一节，我们将对之前的代币做一次升级。如果你想把你的代币卖给一个交易所，只是发送到一个其他合约的以太坊地址是不够的，因为它不会意识到这个新代币或者谁发送给它的，因为这个合约没有发布一些事件或者接口。所以对于合约，你应该首先批准它们可以从你账号转出代币，然后让它们知道它们应该怎么去做。由于里面的一些函数是必须去做一些交易操作，这里很有必要把它们弄成集成为一个内部函数（只有这个合约本身能够调用）。 /* Internal transfer, can only be called by this contract */function _transfer(address _from, address _to, uint _value) internal {    require (_to != 0x0);                               // Prevent transfer to 0x0 address. Use burn() instead    require (balanceOf[_from] &gt;= _value);                // Check if the sender has enough    require (balanceOf[_to] + _value &gt;= balanceOf[_to]); // Check for overflows    require(!frozenAccount[_from]);                     // Check if sender is frozen    require(!frozenAccount[_to]);                       // Check if recipient is frozen    balanceOf[_from] -= _value;                         // Subtract from the sender    balanceOf[_to] += _value;                           // Add the same to the recipient    Transfer(_from, _to, _value);}现在你的其他涉及到交易操作的函数可以做它们自己的校验，然后用正确的参数去调用transfer这个函数。  注意这个函数没有做任何的权限校验就可以去转移代币，这是因为这个函数是内部函数，只有这个合约本身能够调用。  所以如果你添加了任何调用到它的函数，需要在调用前确保调用者有权限去转移代币。中心管理所有的dapp默认是去中心化的，这不意味着他们不能拥有某些中心管理，比如你想有能力能够造更多的代币，又或者你想禁止某人使用你的代币。你可以把任何你想加的功能加到你的合约里面去，但你只能在最开始的时候加，这样那些代币拥有者可以知道你的游戏规则，然后决定要不要拥有你的代币。这里我们将学习到一个合约特别有用的属性：继承  继承允许一个合约获得父合约的熟属性，而不需要重新定义它们。这样可以使我们的代码更加的简洁和重复使用。  添加下面这段代码到你的代码第一行，在contract MyToken {前添加contract owned {    address public owner;    function owned() {        owner = msg.sender;    }    modifier onlyOwner {        require(msg.sender == owner);        _;    }    function transferOwnership(address newOwner) onlyOwner {        owner = newOwner;    }}这里创建了一个非常基本的合约，只是定义了关于这个合约的一些公共函数。下一步只要添加is owner到你的合约。contract MyToken is owned {    /* the rest of the contract as usual */这样所有MyToken的函数可以使用owner这个变量和modifer onlyOnwer。这个合约也可以获得一个可以修改合约拥有者的函数。即使合约一开始设置了合约拥有者，你也可以在构造函数添加这段代码：function MyToken(    uint256 initialSupply,    string tokenName,    uint8 decimalUnits,    string tokenSymbol,    address centralMinter    ) {    if(centralMinter != 0 ) owner = centralMinter;}中心代币发行支持你能够去控制流通代币的数量。  一种情况是当你的货币实际上代表了一种区块链资产（像金币券或者政府货币），然后你想要你的虚拟库存能够真实的反应其中一种。又或者你想要控制代币的价格，适当的增加或减少流通数量。首先，我们需要增加一个变量来存储总发行量，然后在我们的构造函数去指定它。contract MyToken {    uint256 public totalSupply;    function MyToken(...) {        totalSupply = initialSupply;        ...    }    ...}现在添加一个新函数来允许合约拥有者去创建新的代币。function mintToken(address target, uint256 mintedAmount) onlyOwner {    balanceOf[target] += mintedAmount;    totalSupply += mintedAmount;    Transfer(0, owner, mintedAmount);    Transfer(owner, target, mintedAmount);}注意到函数名最后加了onlyOwner，意味着这个函数只能被设置为合约拥有者的账号调用，这样你就可以创造更多的代币。冻结资产根据你的使用场景，你可能需要会遇到一些管理障碍，比如谁可以拥有你的代币，谁不可以。这样的话你需要增加一个参数来允许合约拥有者去冻结或者解冻资产。在这个合约的任何地方添加这个变量和函数。不过建议你把映射跟其他映射放到一起，事件跟其他事件放到一起。mapping (address =&gt; bool) public frozenAccount;event FrozenFunds(address target, bool frozen);function freezeAccount(address target, bool freeze) onlyOwner {    frozenAccount[target] = freeze;    FrozenFunds(target, freeze);}对于这段代码所有账号默认都是解冻的，不过合约拥有者可以通过调用freezeAccount设置它们的一个冻结状态。  不幸的是，冻结没有任何的实际效果，因为我们还没有在转移代币的函数中做任何操作。现在修改它：function transfer(address _to, uint256 _value) {        require(!frozenAccount[msg.sender]);现在任何冻结的账号可以保留他们的代币，但是不是转移这些代币。任何账号默认都是解冻的直到你去冻结它，你也可以通过白名单的方式来管理。  只要把freezeAccount重命名为approvedAccount，然后修改最后一行代码为：require(approvedAccount[msg.sender]);自动买卖到目前为止，你已经可以信任你的代币并应用到实际场景中。但如果你想通过市场价格自动买卖来通过以太币（或其他代币）赎回。首先，需要设置买卖的价格。uint256 public sellPrice;uint256 public buyPrice;function setPrices(uint256 newSellPrice, uint256 newBuyPrice) onlyOwner {    sellPrice = newSellPrice;    buyPrice = newBuyPrice;}这是一个不经常变动的可接受价格，因为每次价格变动都需要你执行一个交易并且话费一点以太币。如果你需要一个不变的带小数位的架构，建议你参考standard data feeds下一步创建买卖函数：function buy() payable returns (uint amount){    amount = msg.value / buyPrice;                    // calculates the amount    require(balanceOf[this] &gt;= amount);               // checks if it has enough to sell    balanceOf[msg.sender] += amount;                  // adds the amount to buyer's balance    balanceOf[this] -= amount;                        // subtracts amount from seller's balance    Transfer(this, msg.sender, amount);               // execute an event reflecting the change    return amount;                                    // ends function and returns}function sell(uint amount) returns (uint revenue){    require(balanceOf[msg.sender] &gt;= amount);         // checks if the sender has enough to sell    balanceOf[this] += amount;                        // adds the amount to owner's balance    balanceOf[msg.sender] -= amount;                  // subtracts the amount from seller's balance    revenue = amount * sellPrice;    msg.sender.transfer(revenue);                     // sends ether to the seller: it's important to do this last to prevent recursion attacks    Transfer(msg.sender, this, amount);               // executes an event reflecting on the change    return revenue;                                   // ends function and returns}这些操作并不会增加新代币而是改变合约拥有者的余额。注意设置的价格不是以太币为单位，而是以wei为单位。一个以太币相当于1000000000000000000wei，所以当在以太坊设置你代币的价格时，需要在后面增加18个0。当创建合约时，为了能够回购市场上所有代币，需要支付足够多的以太币。否则你的合约就破产了，你的用户没办法去卖掉他们的代币。一个更有趣的合约可以允许一个交易所的任何人都能出价，或者可以从外部直接获取价格。自动充值每次你在以太坊做交易，你都需要支付小费给矿工，让他去计算你合约的结果。这一切可以在将来会被改变，但目前只能支付以太币，因此你所有的代币用户都需要持有以太币。如果用户的以太币数量不足以支付小费会被冻结，知道合约拥有者来支付它。但在某些场景下，你可能不想你的用户来考虑以太坊，区块链或者如何拥有以太币，所以一个有效的方法是如果检测到用户余额不足，你能够自动帮用户充值余额。首先，你需要创建一个变量来存储账户的阈值和一个函数来设置他。如果你不知道设置多少合适，可以设置5 finney（0.005个以太币）uint public minBalanceForAccounts;function setMinBalance(uint minimumBalanceInFinney) onlyOwner {        minBalanceForAccounts = minimumBalanceInFinney * 1 finney;}然后，添加下面代码到trensfer函数，让卖家退还一部分代币来充值以太币：/* Send coins */function transfer(address _to, uint256 _value) {    ...    if(msg.sender.balance &lt; minBalanceForAccounts)        sell((minBalanceForAccounts - msg.sender.balance) / sellPrice);}你也可以把支付小费的操作从卖家转移到买家：/* Send coins */function transfer(address _to, uint256 _value) {    ...    if(_to.balance&lt;minBalanceForAccounts)        _to.send(sell((minBalanceForAccounts - _to.balance) / sellPrice));}这样可以保证所有人都有足够的以太币来支付小费。工作量证明这里有一些方法通过数学公式来增加你的代币供应。一个最简单的办法就是绑定以太坊的挖矿，意思就是一旦任何人找到以太坊的区块，它也相应获得你的代币回报。你可以通过一些特殊接口来获得找到区块的账号。function giveBlockReward() {    balanceOf[block.coinbase] += 1;}也可以增加一个数学公式，让任何人知道如果解答这个公式来获得回报。下面这个例子你必须解答出当前挑战，并正确设置下一个挑战。uint public currentChallenge = 1; // Can you figure out the cubic root of this number?function rewardMathGeniuses(uint answerToCurrentReward, uint nextChallenge) {    require(answerToCurrentReward**3 == currentChallenge); // If answer is wrong do not continue    balanceOf[msg.sender] += 1;         // Reward the player    currentChallenge = nextChallenge;   // Set the next challenge}当然，计算上面这个结果通过手动是很困难的，但使用计算器就很简单，所以这游戏容易被计算机给破解。也因为最后一名赢家可以选择下一个挑战的难度，他们可以选择他们知道的，所以对其他玩家来说是很不公平的。一个更公平的系统需要设计一个对计算机来说很难的挑战，但也不是完全不可能挑战成功。一个非常好的方案是需要挑战者从很多数字中找到一个低于困难值的hash。这个方案是Adam Back在1997年首次提出，称为Hashcash,然后中本聪在2008年将它应用于比特币的工作量证明。当然你也可以创建自己的工作量证明。bytes32 public currentChallenge;                         // The coin starts with a challengeuint public timeOfLastProof;                             // Variable to keep track of when rewards were givenuint public difficulty = 10**32;                         // Difficulty starts reasonably lowfunction proofOfWork(uint nonce){    bytes8 n = bytes8(sha3(nonce, currentChallenge));    // Generate a random hash based on input    require(n &gt;= bytes8(difficulty));                   // Check if it's under the difficulty    uint timeSinceLastProof = (now - timeOfLastProof);  // Calculate time since last reward was given    require(timeSinceLastProof &gt;=  5 seconds);         // Rewards cannot be given too quickly    balanceOf[msg.sender] += timeSinceLastProof / 60 seconds;  // The reward to the winner grows by the minute    difficulty = difficulty * 10 minutes / timeSinceLastProof + 1;  // Adjusts the difficulty    timeOfLastProof = now;                              // Reset the counter    currentChallenge = sha3(nonce, currentChallenge, block.blockhash(block.number - 1));  // Save a hash that will be used as the next proof}构造函数同样也要修改，增加下面这行代码：timeOfLastProof = now;一旦你运行合约，选择这个工作量证明函数，添加你的幸运数字，然后运行。如果这个确认窗口显示一个红色警告“Data can’t be execute”，需要返回上一步设置另一个数字直到你找到一个满足交易能够执行下去的数字。一旦你找到了这个数字，你将每分钟获得一个代币奖励，分钟数取决于距离上次挑战的时间。然后这个难度将被调整，保证平均每隔10分钟才能被计算出来。完整代码pragma solidity ^0.4.16;contract owned {    address public owner;    function owned() public {        owner = msg.sender;    }    modifier onlyOwner {        require(msg.sender == owner);        _;    }    function transferOwnership(address newOwner) onlyOwner public {        owner = newOwner;    }}interface tokenRecipient { function receiveApproval(address _from, uint256 _value, address _token, bytes _extraData) public; }contract TokenERC20 {    // Public variables of the token    string public name;    string public symbol;    uint8 public decimals = 18;    // 18 decimals is the strongly suggested default, avoid changing it    uint256 public totalSupply;    // This creates an array with all balances    mapping (address =&gt; uint256) public balanceOf;    mapping (address =&gt; mapping (address =&gt; uint256)) public allowance;    // This generates a public event on the blockchain that will notify clients    event Transfer(address indexed from, address indexed to, uint256 value);    // This notifies clients about the amount burnt    event Burn(address indexed from, uint256 value);    /**     * Constrctor function     *     * Initializes contract with initial supply tokens to the creator of the contract     */    function TokenERC20(        uint256 initialSupply,        string tokenName,        string tokenSymbol    ) public {        totalSupply = initialSupply * 10 ** uint256(decimals);  // Update total supply with the decimal amount        balanceOf[msg.sender] = totalSupply;                // Give the creator all initial tokens        name = tokenName;                                   // Set the name for display purposes        symbol = tokenSymbol;                               // Set the symbol for display purposes    }    /**     * Internal transfer, only can be called by this contract     */    function _transfer(address _from, address _to, uint _value) internal {        // Prevent transfer to 0x0 address. Use burn() instead        require(_to != 0x0);        // Check if the sender has enough        require(balanceOf[_from] &gt;= _value);        // Check for overflows        require(balanceOf[_to] + _value &gt; balanceOf[_to]);        // Save this for an assertion in the future        uint previousBalances = balanceOf[_from] + balanceOf[_to];        // Subtract from the sender        balanceOf[_from] -= _value;        // Add the same to the recipient        balanceOf[_to] += _value;        Transfer(_from, _to, _value);        // Asserts are used to use static analysis to find bugs in your code. They should never fail        assert(balanceOf[_from] + balanceOf[_to] == previousBalances);    }    /**     * Transfer tokens     *     * Send `_value` tokens to `_to` from your account     *     * @param _to The address of the recipient     * @param _value the amount to send     */    function transfer(address _to, uint256 _value) public {        _transfer(msg.sender, _to, _value);    }    /**     * Transfer tokens from other address     *     * Send `_value` tokens to `_to` in behalf of `_from`     *     * @param _from The address of the sender     * @param _to The address of the recipient     * @param _value the amount to send     */    function transferFrom(address _from, address _to, uint256 _value) public returns (bool success) {        require(_value &lt;= allowance[_from][msg.sender]);     // Check allowance        allowance[_from][msg.sender] -= _value;        _transfer(_from, _to, _value);        return true;    }    /**     * Set allowance for other address     *     * Allows `_spender` to spend no more than `_value` tokens in your behalf     *     * @param _spender The address authorized to spend     * @param _value the max amount they can spend     */    function approve(address _spender, uint256 _value) public        returns (bool success) {        allowance[msg.sender][_spender] = _value;        return true;    }    /**     * Set allowance for other address and notify     *     * Allows `_spender` to spend no more than `_value` tokens in your behalf, and then ping the contract about it     *     * @param _spender The address authorized to spend     * @param _value the max amount they can spend     * @param _extraData some extra information to send to the approved contract     */    function approveAndCall(address _spender, uint256 _value, bytes _extraData)        public        returns (bool success) {        tokenRecipient spender = tokenRecipient(_spender);        if (approve(_spender, _value)) {            spender.receiveApproval(msg.sender, _value, this, _extraData);            return true;        }    }    /**     * Destroy tokens     *     * Remove `_value` tokens from the system irreversibly     *     * @param _value the amount of money to burn     */    function burn(uint256 _value) public returns (bool success) {        require(balanceOf[msg.sender] &gt;= _value);   // Check if the sender has enough        balanceOf[msg.sender] -= _value;            // Subtract from the sender        totalSupply -= _value;                      // Updates totalSupply        Burn(msg.sender, _value);        return true;    }    /**     * Destroy tokens from other account     *     * Remove `_value` tokens from the system irreversibly on behalf of `_from`.     *     * @param _from the address of the sender     * @param _value the amount of money to burn     */    function burnFrom(address _from, uint256 _value) public returns (bool success) {        require(balanceOf[_from] &gt;= _value);                // Check if the targeted balance is enough        require(_value &lt;= allowance[_from][msg.sender]);    // Check allowance        balanceOf[_from] -= _value;                         // Subtract from the targeted balance        allowance[_from][msg.sender] -= _value;             // Subtract from the sender's allowance        totalSupply -= _value;                              // Update totalSupply        Burn(_from, _value);        return true;    }}/******************************************//*       ADVANCED TOKEN STARTS HERE       *//******************************************/contract MyAdvancedToken is owned, TokenERC20 {    uint256 public sellPrice;    uint256 public buyPrice;    mapping (address =&gt; bool) public frozenAccount;    /* This generates a public event on the blockchain that will notify clients */    event FrozenFunds(address target, bool frozen);    /* Initializes contract with initial supply tokens to the creator of the contract */    function MyAdvancedToken(        uint256 initialSupply,        string tokenName,        string tokenSymbol    ) TokenERC20(initialSupply, tokenName, tokenSymbol) public {}    /* Internal transfer, only can be called by this contract */    function _transfer(address _from, address _to, uint _value) internal {        require (_to != 0x0);                               // Prevent transfer to 0x0 address. Use burn() instead        require (balanceOf[_from] &gt;= _value);               // Check if the sender has enough        require (balanceOf[_to] + _value &gt;= balanceOf[_to]); // Check for overflows        require(!frozenAccount[_from]);                     // Check if sender is frozen        require(!frozenAccount[_to]);                       // Check if recipient is frozen        balanceOf[_from] -= _value;                         // Subtract from the sender        balanceOf[_to] += _value;                           // Add the same to the recipient        Transfer(_from, _to, _value);    }    /// @notice Create `mintedAmount` tokens and send it to `target`    /// @param target Address to receive the tokens    /// @param mintedAmount the amount of tokens it will receive    function mintToken(address target, uint256 mintedAmount) onlyOwner public {        balanceOf[target] += mintedAmount;        totalSupply += mintedAmount;        Transfer(0, this, mintedAmount);        Transfer(this, target, mintedAmount);    }    /// @notice `freeze? Prevent | Allow` `target` from sending &amp; receiving tokens    /// @param target Address to be frozen    /// @param freeze either to freeze it or not    function freezeAccount(address target, bool freeze) onlyOwner public {        frozenAccount[target] = freeze;        FrozenFunds(target, freeze);    }    /// @notice Allow users to buy tokens for `newBuyPrice` eth and sell tokens for `newSellPrice` eth    /// @param newSellPrice Price the users can sell to the contract    /// @param newBuyPrice Price users can buy from the contract    function setPrices(uint256 newSellPrice, uint256 newBuyPrice) onlyOwner public {        sellPrice = newSellPrice;        buyPrice = newBuyPrice;    }    /// @notice Buy tokens from contract by sending ether    function buy() payable public {        uint amount = msg.value / buyPrice;               // calculates the amount        _transfer(this, msg.sender, amount);              // makes the transfers    }    /// @notice Sell `amount` tokens to contract    /// @param amount amount of tokens to be sold    function sell(uint256 amount) public {        require(this.balance &gt;= amount * sellPrice);      // checks if the contract has enough ether to buy        _transfer(msg.sender, this, amount);              // makes the transfers        msg.sender.transfer(amount * sellPrice);          // sends ether to the seller. It's important to do this last to avoid recursion attacks    }}"
                        } ,
                     
                        {
                          "title"    : "以太坊发行代币(一)",
                          "category" : "",
                          "tags"     : " 区块链, 以太坊",
                          "url"      : "/2018/04/07/ethereum-crypto-currency-1.html",
                          "date"     : "April 7, 2018",
                          "excerpt"  : "本文使用到的工具geth、Mist，并通过私有链来做测试。如果你不知道还不了解，请先阅读这篇文章《搭建以太坊私有网络》先从最基本的开始，打开Mist，进入到 Contract 标签页，然后点击 Deploy New Contract在Solidity Contract Source code输入框，输入以下代码：contract MyToken {    /* This creates an array with all balances */    mapping (address =&...",
                          "content"  : "本文使用到的工具geth、Mist，并通过私有链来做测试。如果你不知道还不了解，请先阅读这篇文章《搭建以太坊私有网络》先从最基本的开始，打开Mist，进入到 Contract 标签页，然后点击 Deploy New Contract在Solidity Contract Source code输入框，输入以下代码：contract MyToken {    /* This creates an array with all balances */    mapping (address =&gt; uint256) public balanceOf;}mapping是一种关联数组，这里我们把地址和余额关联起来。  address是基本的16进制以太坊格式。  余额是一个256位的非负数整数。public意味着这个变量可以被区块链中的任何人开放，这里意味着余额是公开的。如果你这时候马上发布你的合约，它可以工作但是一点用都没有：因为里面为0没有余额，且不能挖矿来获得代币。  所以，我们可以先在合约安装时初始化一定的代币数量给创建合约的人。在最后一个大括号前添加以下代码：function MyToken() {    balanceOf[msg.sender] = 21000000;}也许你已经注意到添加代码的函数名MyToken与我们的合约名MyToken是一样的。这点非常重要，类似于我们的构造函数，它只会运行一次，且是在合约上传到网络的时候运行。  这个函数设置了msg.sender（部署了这个合约的地址）的余额21000000个。除了直接在代码中设置余额，我们还可以用更好的方法，通过传参来设置。像这样：function MyToken(uint256 initialSupply) public {    balanceOf[msg.sender] = initialSupply;}修改上面的代码后，我们在Mist的右侧选择MyToken然后就可以看到我们定义的Constructor parameters。现在你已经拥有了一个能初始化余额功能的合约，但不能交易，所有余额只会一直留在同一个账号中，所以我们接下来实现交易功能。  在最后一个大括号前添加以下代码：/* Send coins */function transfer(address _to, uint256 _value) {    /* Add and subtract new balances */    balanceOf[msg.sender] -= _value;    balanceOf[_to] += _value;}这是个非常简单的函数：它有一个接收者_to和一个数量值_value，一旦有人执行它，它会减掉他们的代币数量_value，然后添加这些代币数量到接收者_to的余额中。  这里有一个很明显的问题：由于我们没有对发送数量做限制，一个人可以发送超过他拥有的代币数量。  接下来我们将做一个简单的校验，如果发送者没有足够的余额，合约的执行将被终止。也将校验泛滥的情况，如果一个人拥有特别大的余额，将会对他做归零处理。  你可以通过return或者throw来终止合约执行。throw将会失去执行合约所支付的gas，而retun更让人头疼,他对合约所做的任何改动都将保留，而throw将会回滚所有的合约操作。由于钱包会察觉到合约将抛的异常，对用户做出警告，所以可以有效的防止因throw所浪费的gas。function transfer(address _to, uint256 _value) {    /* Check if sender has balance and for overflows */    require(balanceOf[msg.sender] &gt;= _value &amp;&amp; balanceOf[_to] + _value &gt;= balanceOf[_to]);    /* Add and subtract new balances */    balanceOf[msg.sender] -= _value;    balanceOf[_to] += _value;}我们先直接添加以下变量，在后面用来处理代币注册。string public name;string public symbol;uint8 public decimals;接下来在合约启动时，允许设置这些变量。/* Initializes contract with initial supply tokens to the creator of the contract */function MyToken(uint256 initialSupply, string tokenName, string tokenSymbol, uint8 decimalUnits) {    balanceOf[msg.sender] = initialSupply;              // Give the creator all initial tokens    name = tokenName;                                   // Set the name for display purposes    symbol = tokenSymbol;                               // Set the symbol for display purposes    decimals = decimalUnits;                            // Amount of decimals for display purposes}最后我们需要一些事件。它们是一些空函数，可以帮助客户端来发生在合约的活动。  在合约的开头声明这个事件：event Transfer(address indexed from, address indexed to, uint256 value);然后你需要在涉及到交易的函数中添加以下两行代码：/* Notify anyone listening that this transfer took place */Transfer(msg.sender, _to, _value);现在可以你的代币已经准备好了！部署现在把上面的代码复制到SOLIDITY CONTRACT SOURCE CODE。如果代码在编译没有报错，你可以在右边看到SELECT CONTRACT TO DEPLOY的下拉列表。选择MyToken合约，然后你可以在右边看到所有你需要自定义的参数。但为了这次教程，建议你设置变量为：  Initial supply : 10000  Token name : 任意你想到的名字  Token symbol : %  Decimal units : 2滚动到页面最下面，你可以看到创建合约所需要的估计费用，然后你选择一个你将要支付的费用。  你额外支付的那部分费用会退还给你，所以你可以使用默认设置。  点击deploy，输入你账号密码，点击SEND TRANSACTION,然后等待几秒让你的交易被记录。返回首页，你将看到你的交易正在被等待确认。这里我们可以利用私有链的优势，通过挖矿来实现确认。一旦确认完成，你就可以在账号主页看到你所创建的代币。如果你发送代币给你朋友，它们不会在他们的钱包看到。这是因为钱包只会追踪那些它所知道的代币，你必须手动去添加它们。  现在进入到Contract标签页,你可以看到你新创建的合约链接，点击它会去到它的页面。点击copy address，然后复制这个地址到一个文本编辑器中。为了添加钱包对代币的追踪，去到合约页，然后点击 Watch Token。这时将会出现一个弹出框，然后你需要将你上一步复制的合约地址粘贴进去。代币名称，代币符号，和小数位会自动填充进去。做完这些操作，钱包会自动显示你拥有的代币，然后你也可以发送给任何人。"
                        } ,
                     
                        {
                          "title"    : "加密散列-sha256",
                          "category" : "",
                          "tags"     : " 区块链, 密码学",
                          "url"      : "/2018/04/05/sha256.html",
                          "date"     : "April 5, 2018",
                          "excerpt"  : "SHA256是安全散列算法SHA（Secure Hash Algorithm）系列算法之一，其摘要长度为256bits，即32个字节，故称SHA256（1个字节=8位）。算法步骤原始消息分为N个512bit的消息块。每个消息块分成16个32bit，标记为M(i)0、M(i)1、M(i)2、…、M(i)15然后对这N个消息块依次进行处理。1.补位  由于必须分成n个512bit块，所以必须进行补位。  最后还需要预留64bit记录消息块的长度，所以消息块的长度不能大于2^64。补位使其长度...",
                          "content"  : "SHA256是安全散列算法SHA（Secure Hash Algorithm）系列算法之一，其摘要长度为256bits，即32个字节，故称SHA256（1个字节=8位）。算法步骤原始消息分为N个512bit的消息块。每个消息块分成16个32bit，标记为M(i)0、M(i)1、M(i)2、…、M(i)15然后对这N个消息块依次进行处理。1.补位  由于必须分成n个512bit块，所以必须进行补位。  最后还需要预留64bit记录消息块的长度，所以消息块的长度不能大于2^64。补位使其长度 先补一个1，然后再补0，直到长度满足对512取模后余数是448。总而言之，补位是至少补一位，最多补512位。以信息“abc”为例显示补位的过程。  原始信息：01100001 01100010 01100011  补位第一步：0110000101100010 01100011 1  首先补一个“1”  补位第二步：0110000101100010 01100011 10…..0  然后补423个“0”  我们可以把最后补位完成后的数据用16进制写成下面的样子  61626380 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 000000002.补长度  所谓的补长度是将原始数据的长度补到已经进行了补位操作的消息后面。通常用一个64位的数据来表示原始消息的长度。如果消息长度不大于2^64，那么第一个字就是0。在进行了补长度的操作以后，整个消息就变成下面这样了（16进制格式）61626380 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000018如果原始的消息长度超过了512，我们需要将它补成512的倍数。然后我们把整个消息分成一个一个512位的数据块，分别处理每一个数据块，从而得到消息摘要。3.常量定义这些常量是对自然数中前64个质数的立方根的小数部分取前32bit而来。k[0..63] :=  0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,  0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,  0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,  0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,  0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,  0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,  0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,  0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f24.哈希初值这些初值是对自然数中前8个质数3、5、7、11等的平方根的小数部分取前32bit而来。H(0)0 = 6a09e667  H(0)1 = bb67ae85  H(0)2 = 3c6ef372  H(0)3 = a54ff53a  H(0)4 = 510e527f  H(0)5 = 9b05688c  H(0)6 = 1f83d9ab  H(0)7 = 5be0cd19实现伪代码预处理append the bit '1' to the messageappend k bits '0', where k is the minimum number &gt;= 0 such that the resulting message    length (in bits) is congruent to 448(mod 512)append length of message (before pre-processing), in bits, as 64-bit big-endian integer处理# 分割512块for each chunk    # 每块分割成16个32bit    break chunk into sixteen 32-bit big-endian words w[0..15]    # 用16个32bit，扩展其他48个32bit    for i from 16 to 63        s0 := (w[i-15] rightrotate 7) xor (w[i-15] rightrotate 18) xor(w[i-15] rightshift 3)        s1 := (w[i-2] rightrotate 17) xor (w[i-2] rightrotate 19) xor(w[i-2] rightshift 10)        w[i] := w[i-16] + s0 + w[i-7] + s1    # 哈希初始值    a := h0    b := h1    c := h2    d := h3    e := h4    f := h5    g := h6    h := h7    # 主循环    for i from 0 to 63        s0 := (a rightrotate 2) xor (a rightrotate 13) xor(a rightrotate 22)        maj := (a and b) xor (a and c) xor(b and c)        t2 := s0 + maj        s1 := (e rightrotate 6) xor (e rightrotate 11) xor(e rightrotate 25)        ch := (e and f) xor ((not e) and g)        t1 := h + s1 + ch + k[i] + w[i]        h := g        g := f        f := e        e := d + t1        d := c        c := b        b := a        a := t1 + t2    # 修改哈希值    h0 := h0 + a    h1 := h1 + b    h2 := h2 + c    h3 := h3 + d    h4 := h4 + e    h5 := h5 + f    h6 := h6 + g    h7 := h7 + h# 输出结果digest = hash = h0 append h1 append h2 append h3 append h4 append h5 append h6 append h7输出值256bit的二进制值或者64个16进制的ascii码。"
                        } ,
                     
                        {
                          "title"    : "加密散列-sha1",
                          "category" : "",
                          "tags"     : " 区块链, 密码学",
                          "url"      : "/2018/04/05/sha1.html",
                          "date"     : "April 5, 2018",
                          "excerpt"  : "SHA-1（英语：Secure Hash Algorithm 1，中文名：安全散列算法1）是一种密码散列函数，美国国家安全局设计，并由美国国家标准技术研究所（NIST）发布为联邦数据处理标准（FIPS）[2]。SHA-1可以生成一个被称为消息摘要的160位（20字节）散列值，散列值通常的呈现形式为40个十六进制数。算法步骤原始消息分为N个512bit的消息块。每个消息块分成16个32bit。1.补位  由于必须分成n个512bit块，所以必须进行补位。  最后还需要预留64bit记录消息块...",
                          "content"  : "SHA-1（英语：Secure Hash Algorithm 1，中文名：安全散列算法1）是一种密码散列函数，美国国家安全局设计，并由美国国家标准技术研究所（NIST）发布为联邦数据处理标准（FIPS）[2]。SHA-1可以生成一个被称为消息摘要的160位（20字节）散列值，散列值通常的呈现形式为40个十六进制数。算法步骤原始消息分为N个512bit的消息块。每个消息块分成16个32bit。1.补位  由于必须分成n个512bit块，所以必须进行补位。  最后还需要预留64bit记录消息块的长度，所以消息块的长度不能大于2^64。补位使其长度 先补一个1，然后再补0，直到长度满足对512取模后余数是448。总而言之，补位是至少补一位，最多补512位。以信息“abc”为例显示补位的过程。  原始信息：01100001 01100010 01100011  补位第一步：0110000101100010 01100011 1  首先补一个“1”  补位第二步：0110000101100010 01100011 10…..0  然后补423个“0”  我们可以把最后补位完成后的数据用16进制写成下面的样子  61626380 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 000000002.补长度  所谓的补长度是将原始数据的长度补到已经进行了补位操作的消息后面。通常用一个64位的数据来表示原始消息的长度。如果消息长度不大于2^64，那么第一个字就是0。在进行了补长度的操作以后，整个消息就变成下面这样了（16进制格式）61626380 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000018如果原始的消息长度超过了512，我们需要将它补成512的倍数。然后我们把整个消息分成一个一个512位的数据块，分别处理每一个数据块，从而得到消息摘要。3.哈希初值h0 := 0x67452301h1 := 0xEFCDAB89h2 := 0x98BADCFEh3 := 0x10325476h4 := 0xC3D2E1F0实现伪代码预处理append \"1\" bit to messageappend \"0\" bits until message length in bits ≡ 448 (mod 512)append bit length of message as 64-bit little-endian integer to message处理# 分割512块for each 512-bit chunk of message    # 每块分割成16个32bit    break chunk into sixteen 32-bit little-endian words w[i], 0 ≤ i ≤ 15    # 用16个32bit，扩展其他64个32bit    for i from 16 to 79        w[i] := (w[i-3] xor w[i-8] xor w[i-14] xor w[i-16]) leftrotate 1    # 哈希初始值    a := h0    b := h1    c := h2    d := h3    e := h4    # 主循环    for i from 0 to 79        if 0 ≤ i ≤ 19 then            f := (b and c) or ((not b) and d)            k := 0x5A827999        else if 20 ≤ i ≤ 39            f := b xor c xor d            k := 0x6ED9EBA1        else if 40 ≤ i ≤ 59            f := (b and c) or (b and d) or(c and d)            k := 0x8F1BBCDC        else if 60 ≤ i ≤ 79            f := b xor c xor d            k := 0xCA62C1D6         temp := (a leftrotate 5) + f + e + k + w[i]        e := d        d := c        c := b leftrotate 30        b := a        a := temp    # 修改哈希值    h0 := h0 + a    h1 := h1 + b    h2 := h2 + c    h3 := h3 + d    h4 := h4 + e# 输出结果digest = hash = h0 append h1 append h2 append h3 append h4输出值160bit的二进制值或者40个16进制的ascii码。"
                        } ,
                     
                        {
                          "title"    : "加密散列-PIPEMD160",
                          "category" : "",
                          "tags"     : " 区块链, 密码学",
                          "url"      : "/2018/04/05/ripemd160.html",
                          "date"     : "April 5, 2018",
                          "excerpt"  : "RIPEMD (RACE原始完整性校验讯息摘要)是一种加密哈希函数，由 鲁汶大学 Hans Dobbertin,Antoon Bosselaers 和 Bart Prenee组成的COSIC 研究小组发布于1996年。 RIPEMD是以MD4为基础原则所设计的 ，而且其表现与更有名的SHA-1类似.RIPEMD-160是以原始版RIPEMD所改进的160位元版本，而且是RIPEMD系列中最常见的版本。 RIPEMD-160是设计给学术社群所使用的，刚好相对于 国家安全局 所设计 SHA-1...",
                          "content"  : "RIPEMD (RACE原始完整性校验讯息摘要)是一种加密哈希函数，由 鲁汶大学 Hans Dobbertin,Antoon Bosselaers 和 Bart Prenee组成的COSIC 研究小组发布于1996年。 RIPEMD是以MD4为基础原则所设计的 ，而且其表现与更有名的SHA-1类似.RIPEMD-160是以原始版RIPEMD所改进的160位元版本，而且是RIPEMD系列中最常见的版本。 RIPEMD-160是设计给学术社群所使用的，刚好相对于 国家安全局 所设计 SHA-1 和 SHA-2 算法。 另一方面，RIPEMD-160比SHA-1较少使用，所以可能造成RIPEMD-160比SHA还不常被审查。另外，RIPEMD-160并没有任何专利所限制。同时也存在着128,256-320位元的这种算法，称为RIPEMD-128,RIPEMD-256和RIPEMD-320。 128位版本的用意仅是取代原始版RIPEMD，因为原版也同样是128位元，并且被发现有潜在的安全问题。 而256和320位版本只有减少碰撞发生的机率，但没有提升安全等级(以 preimage举例)。不过，RIPEMD的设计者们没有真正设计256和320位元这2种标准，他们只是在128位元和160位元的基础上，修改了初始参数和s-box来达到输出为256和320位元。所以，256位的强度和128相当，而320位的强度和160位相当。且RIPEMD建立在md的基础之上，所以其添加数据的方式和md5完全一样。伪代码原始消息分为N个512bit的消息块。每个消息块分成16个32bit。1.补位  由于必须分成n个512bit块，所以必须进行补位。  最后还需要预留64bit记录消息块的长度，所以消息块的长度不能大于2^64补位使其长度 先补一个1，然后再补0，直到长度满足对512取模后余数是448。总而言之，补位是至少补一位，最多补512位。以信息“abc”为例显示补位的过程。  原始信息：01100001 01100010 01100011  补位第一步：0110000101100010 01100011 1  首先补一个“1”  补位第二步：0110000101100010 01100011 10…..0  然后补423个“0”  我们可以把最后补位完成后的数据用16进制写成下面的样子  61626380 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 000000002.补长度  所谓的补长度是将原始数据的长度补到已经进行了补位操作的消息后面。通常用一个64位的数据来表示原始消息的长度。如果消息长度不大于2^64，那么第一个字就是0。在进行了补长度的操作以后，整个消息就变成下面这样了（16进制格式）61626380 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000018如果原始的消息长度超过了512，我们需要将它补成512的倍数。然后我们把整个消息分成一个一个512位的数据块，分别处理每一个数据块，从而得到消息摘要。2.函数定义f(j, x, y, z) = x XOR y XOR z (0 &lt;= j &lt;= 15)   f(j, x, y, z) = (x AND y) OR (NOT(x) AND z) (16 &lt;= j &lt;= 31)   f(j, x, y, z) = (x OR NOT(y)) XOR z (32 &lt;= j &lt;= 47)   f(j, x, y, z) = (x AND z) OR (y AND NOT(z)) (48 &lt;= j &lt;= 63)   f(j, x, y, z) = x XOR (y OR NOT(z)) (64 &lt;= j &lt;= 79)3.常量定义added constants (hexadecimal)K(j) = 0x00000000 (0 &lt;= j &lt;= 15)   K(j) = 0x5A827999 (16 &lt;= j &lt;= 31) int(230 x sqrt(2))   K(j) = 0x6ED9EBA1 (32 &lt;= j &lt;= 47) int(230 x sqrt(3))   K(j) = 0x8F1BBCDC (48 &lt;= j &lt;= 63) int(230 x sqrt(5))   K(j) = 0xA953FD4E (64 &lt;= j &lt;= 79) int(230 x sqrt(7))   K’(j) = 0x50A28BE6 (0 &lt;= j &lt;= 15) int(230 x cbrt(2))   K’(j) = 0x5C4DD124 (16 &lt;= j &lt;= 31) int(230 x cbrt(3))   K’(j) = 0x6D703EF3 (32 &lt;= j &lt;= 47) int(230 x cbrt(5))   K’(j) = 0x7A6D76E9 (48 &lt;= j &lt;= 63) int(230 x cbrt(7))   K’(j) = 0x00000000 (64 &lt;= j &lt;= 79)selection of message wordr(j) = j (0 &lt;= j &lt;= 15)   r(16..31) = 7, 4, 13, 1, 10, 6, 15, 3, 12, 0, 9, 5, 2, 14, 11, 8   r(32..47) = 3, 10, 14, 4, 9, 15, 8, 1, 2, 7, 0, 6, 13, 11, 5, 12   r(48..63) = 1, 9, 11, 10, 0, 8, 12, 4, 13, 3, 7, 15, 14, 5, 6, 2   r(64..79) = 4, 0, 5, 9, 7, 12, 2, 10, 14, 1, 3, 8, 11, 6, 15, 13   r’(0..15) = 5, 14, 7, 0, 9, 2, 11, 4, 13, 6, 15, 8, 1, 10, 3, 12   r’(16..31)= 6, 11, 3, 7, 0, 13, 5, 10, 14, 15, 8, 12, 4, 9, 1, 2   r’(32..47)= 15, 5, 1, 3, 7, 14, 6, 9, 11, 8, 12, 2, 10, 0, 4, 13   r’(48..63)= 8, 6, 4, 1, 3, 11, 15, 0, 5, 12, 2, 13, 9, 7, 10, 14   r’(64..79)= 12, 15, 10, 4, 1, 5, 8, 7, 6, 2, 13, 14, 0, 3, 9, 11amount for rotate left (rol)s(0..15)  = 11, 14, 15, 12, 5, 8, 7, 9, 11, 13, 14, 15, 6, 7, 9, 8   s(16..31) = 7, 6, 8, 13, 11, 9, 7, 15, 7, 12, 15, 9, 11, 7, 13, 12   s(32..47) = 11, 13, 6, 7, 14, 9, 13, 15, 14, 8, 13, 6, 5, 12, 7, 5   s(48..63) = 11, 12, 14, 15, 14, 15, 9, 8, 9, 14, 5, 6, 8, 6, 5, 12   s(64..79) = 9, 15, 5, 11, 6, 8, 13, 12, 5, 12, 13, 14, 11, 8, 5, 6   s’(0..15) = 8, 9, 9, 11, 13, 15, 15, 5, 7, 7, 8, 11, 14, 14, 12, 6   s’(16..31)= 9, 13, 15, 7, 12, 8, 9, 11, 7, 7, 12, 7, 6, 15, 13, 11   s’(32..47)= 9, 7, 15, 11, 8, 6, 6, 14, 12, 13, 5, 14, 13, 13, 7, 5   s’(48..63)= 15, 5, 8, 11, 14, 14, 6, 14, 6, 9, 12, 9, 12, 5, 15, 8   s’(64..79)= 8, 5, 12, 9, 12, 5, 14, 6, 8, 13, 6, 5, 15, 13, 11, 114.哈希初值这些初值是对自然数中前8个质数3、5、7、11等的平方根的小数部分取前32bit而来。h0 = 0x67452301   h1 = 0xEFCDAB89   h2 = 0x98BADCFE   h3 = 0x10325476   h4 = 0xC3D2E1F0实现伪代码#It is assumed that the message after padding consists of t 16-word blocks#that will be denoted with X[i][j], with 0 &lt;= i &lt;= t-1 and 0 &lt;= j &lt;= 15. #The symbol [+] denotes addition modulo 2**32 and rol_s denotes cyclic left#shift (rotate) over s positions.for i := 0 to t-1 {    A := h0; B := h1; C := h2; D = h3; E = h4;    A' := h0; B' := h1; C' := h2; D' = h3; E' = h4;    for j := 0 to 79 {        T := rol_s(j)(A [+] f(j, B, C, D) [+] X[i][r(j)] [+] K(j)) [+] E;        A := E; E := D; D := rol_10(C); C := B; B := T;        T := rol_s'(j)(A' [+] f(79-j, B', C', D') [+] X[i][r'(j)] [+] K'(j)) [+] E';        A' := E'; E' := D'; D' := rol_10(C'); C' := B'; B' := T;    }    T := h1 [+] C [+] D'; h1 := h2 [+] D [+] E'; h2 := h3 [+] E [+] A';    h3 := h4 [+] A [+] B'; h4 := h0 [+] B [+] C'; h0 := T;}# 输出结果digest = hash = h0 append h1 append h2 append h3 append h4输出值160bit的二进制值或者40个16进制的ascii码。"
                        } ,
                     
                        {
                          "title"    : "Merkle树",
                          "category" : "",
                          "tags"     : " 区块链, 密码学",
                          "url"      : "/2018/04/05/merkle-tree.html",
                          "date"     : "April 5, 2018",
                          "excerpt"  : "Merkle树是一种哈希二叉树，它是一种用作快速归纳和校验大规模数据完整性的数据结构。  比特币校验区块交易数据就是使用这种算法。Merkle树是自底向上构建的。如图所示Merkle树一般用来进行完整性验证处理。在处理完整性验证的应用场景中，Merkle树会大大减少数据的传输量及计算的复杂度。成如果想要证明一个确切的数据块是Merkle树中的一员。通常，只需要树根及这个区块和通向树根沿途的中间哈希值，就可以暂时忽略树的其他部分，这些就已经足以让我们验证到树根。  一个节点只需要计算log~...",
                          "content"  : "Merkle树是一种哈希二叉树，它是一种用作快速归纳和校验大规模数据完整性的数据结构。  比特币校验区块交易数据就是使用这种算法。Merkle树是自底向上构建的。如图所示Merkle树一般用来进行完整性验证处理。在处理完整性验证的应用场景中，Merkle树会大大减少数据的传输量及计算的复杂度。成如果想要证明一个确切的数据块是Merkle树中的一员。通常，只需要树根及这个区块和通向树根沿途的中间哈希值，就可以暂时忽略树的其他部分，这些就已经足以让我们验证到树根。  一个节点只需要计算log~2~(N)个32字节的哈希值，形成一条从特定交易到树根的认证路径或者Merkle路径即可。如图所示，我们只要知道蓝色节点的hash值，就能验证  是否在树中。"
                        } ,
                     
                        {
                          "title"    : "加密散列-md5",
                          "category" : "",
                          "tags"     : " 区块链, 密码学",
                          "url"      : "/2018/04/05/md5.html",
                          "date"     : "April 5, 2018",
                          "excerpt"  : "MD5消息摘要算法（英语：MD5 Message-Digest Algorithm），一种被广泛使用的密码散列函数，可以产生出一个128位（16字节）的散列值（hash value），用于确保信息传输完整一致。算法步骤原始消息分为N个512bit的消息块。每个消息块分成16个32bit。1.补位  由于必须分成n个512bit块，所以必须进行补位。  最后还需要预留64bit记录消息块的长度，所以消息块的长度不能大于2^64。补位使其长度 先补一个1，然后再补0，直到长度满足对512取模后...",
                          "content"  : "MD5消息摘要算法（英语：MD5 Message-Digest Algorithm），一种被广泛使用的密码散列函数，可以产生出一个128位（16字节）的散列值（hash value），用于确保信息传输完整一致。算法步骤原始消息分为N个512bit的消息块。每个消息块分成16个32bit。1.补位  由于必须分成n个512bit块，所以必须进行补位。  最后还需要预留64bit记录消息块的长度，所以消息块的长度不能大于2^64。补位使其长度 先补一个1，然后再补0，直到长度满足对512取模后余数是448。总而言之，补位是至少补一位，最多补512位。以信息“abc”为例显示补位的过程。  原始信息：01100001 01100010 01100011  补位第一步：0110000101100010 01100011 1  首先补一个“1”  补位第二步：0110000101100010 01100011 10…..0  然后补423个“0”  我们可以把最后补位完成后的数据用16进制写成下面的样子  61626380 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 000000002.补长度  所谓的补长度是将原始数据的长度补到已经进行了补位操作的消息后面。通常用一个64位的数据来表示原始消息的长度。如果消息长度不大于2^64，那么第一个字就是0。在进行了补长度的操作以后，整个消息就变成下面这样了（16进制格式）61626380 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000000  00000000 0000000000000000 00000018如果原始的消息长度超过了512，我们需要将它补成512的倍数。然后我们把整个消息分成一个一个512位的数据块，分别处理每一个数据块，从而得到消息摘要。3.常量定义r[ 0..15]：= {7, 12, 17, 22,  7, 12, 17, 22,  7, 12, 17, 22,  7, 12, 17, 22}  r[16..31]：= {5,  9, 14, 20,  5,  9, 14, 20,  5,  9, 14, 20,  5,  9, 14, 20}  r[32..47]：= {4, 11, 16, 23,  4, 11, 16, 23,  4, 11, 16, 23,  4, 11, 16, 23}  r[48..63]：= {6, 10, 15, 21,  6, 10, 15, 21,  6, 10, 15, 21,  6, 10, 15, 21}4.哈希初值h0 := 0x67452301h1 := 0xEFCDAB89h2 := 0x98BADCFEh3 := 0x10325476实现伪代码预处理append \"1\" bit to messageappend \"0\" bits until message length in bits ≡ 448 (mod 512)append bit length of message as 64-bit little-endian integer to message处理# 分割512块for each 512-bit chunk of message    # 每块分割成16个32bit    break chunk into sixteen 32-bit little-endian words w[i], 0 ≤ i ≤ 15    # 哈希初始值    var int a := h0    var int b := h1    var int c := h2    var int d := h3    # 主循环    for i from 0 to 63        if 0 ≤ i ≤ 15 then            f := (b and c) or ((not b) and d)            g := i        else if 16 ≤ i ≤ 31            f := (d and b) or ((not d) and c)            g := (5×i + 1) mod 16        else if 32 ≤ i ≤ 47            f := b xor c xor d            g := (3×i + 5) mod 16        else if 48 ≤ i ≤ 63            f := c xor (b or (not d))            g := (7×i) mod 16         temp := d        d := c        c := b        b := leftrotate((a + f + k[i] + w[g]),r[i]) + b        a := temp    Next i    # 修改哈希值    h0 := h0 + a    h1 := h1 + b    h2 := h2 + c    h3 := h3 + dEnd ForEach# 输出结果var int digest := h0 append h1 append h2 append h3 //(expressed as little-endian)输出值128bit的二进制值或者32个16进制的ascii码。"
                        } ,
                     
                        {
                          "title"    : "搭建以太坊私有网络",
                          "category" : "",
                          "tags"     : " 区块链, 以太坊",
                          "url"      : "/2018/04/01/ether-private-network.html",
                          "date"     : "April 1, 2018",
                          "excerpt"  : "Geth可以通过命令行方式实现以太坊的各种功能,如账户的新建编辑删除，开启挖矿，ether币的转移，智能合约的部署和执行等等。安装brew tap ethereum/ethereumbrew install ethereum安装完成后检查，输入geth version创建私有网络1.创建一个目录，如geth-private-test2.进入该目录下，创建文件genesis.json，并写入以下内容{  \"config\": {        \"chainId\": 10,       ...",
                          "content"  : "Geth可以通过命令行方式实现以太坊的各种功能,如账户的新建编辑删除，开启挖矿，ether币的转移，智能合约的部署和执行等等。安装brew tap ethereum/ethereumbrew install ethereum安装完成后检查，输入geth version创建私有网络1.创建一个目录，如geth-private-test2.进入该目录下，创建文件genesis.json，并写入以下内容{  \"config\": {        \"chainId\": 10,        \"homesteadBlock\": 0,        \"eip155Block\": 0,        \"eip158Block\": 0  },  \"coinbase\"   : \"0x0000000000000000000000000000000000000000\",  \"difficulty\" : \"0x20000\",  \"extraData\"  : \"\",  \"gasLimit\"   : \"0x2fefd8\",  \"nonce\"      : \"0x0000000000000042\",  \"mixhash\"    : \"0x0000000000000000000000000000000000000000000000000000000000000000\",  \"parentHash\" : \"0x0000000000000000000000000000000000000000000000000000000000000000\",  \"timestamp\"  : \"0x00\",  \"alloc\"      : { }}3.初始化，并指定数据目录，例如这里的chaingeth init ./genesis.json --datadir ./chain4.进入后台，并指定日志输出文件，例如这里的eth_output.logsgeth --datadir ./chain --nodiscover console 2&gt;&gt; eth_output.logs后续操作可以通过 tail -f eth_output.logs 查看日志输出5.创建用户查看当前用户列表eth.accounts可以看到是空的[]创建新用户personal.newAccount(密码)完成再查看用户列表，即可看到用户。例如我这里创建了两个用户。挖矿开始挖矿miner.start()执行一段时间后，可以看到用户余额已经增加了。结束挖矿miner.stop()MistMist是以太坊钱包，可作为我们geth的可视化操作界面。安装可直接到官网选择适合自己版本下载安装。启动并连接我们的已经创建好的私有网络/Applications/Mist.app/Contents/MacOS/Mist --rpc ~/geth-private-test/chain/geth.ipc启动后如下图所示点击 LAUNCH APPLICATION 进入，如图所示如果页面显示的账号跟我们geth显示的账号一致，且显示的网络是Private，说明已经连接成功了。   后续geth的操作都会同步到Mist。"
                        } ,
                     
                        {
                          "title"    : "密码学",
                          "category" : "",
                          "tags"     : " 区块链, 密码学",
                          "url"      : "/2018/04/01/cryptography.html",
                          "date"     : "April 1, 2018",
                          "excerpt"  : "对称加密加密  解密   优点  加解密效率高（速度快，空间占用小），加密强度高。缺点  安全性弱，密钥由多方管理，密钥容易泄露。常见加密算法  DES、3DES、Blowfish、RC2、AES以及国密的SM4。非对称加密加密  解密   优点  安全性高，公私钥分离。缺点  加解密效率低。常见加密算法  RSA、椭圆曲线算法同态加密是一种特殊的加密方法，允许对密文进行处理得到仍然是加密的结果，即对密文直接进行处理，跟对明文进行处理再加密，得到的结果相同。从代数的角度讲，即同态性。如果定...",
                          "content"  : "对称加密加密  解密   优点  加解密效率高（速度快，空间占用小），加密强度高。缺点  安全性弱，密钥由多方管理，密钥容易泄露。常见加密算法  DES、3DES、Blowfish、RC2、AES以及国密的SM4。非对称加密加密  解密   优点  安全性高，公私钥分离。缺点  加解密效率低。常见加密算法  RSA、椭圆曲线算法同态加密是一种特殊的加密方法，允许对密文进行处理得到仍然是加密的结果，即对密文直接进行处理，跟对明文进行处理再加密，得到的结果相同。从代数的角度讲，即同态性。如果定义一个运算符 ，对加密算法 E 和 解密算法 D，满足 则意味着对于该运算满足同态性。同态性在代数上包括：加法同态、乘法同态、减法同态和除法同态。同时满足加法同态和乘法同态，则意味着是 代数同态，即 全同态。同时满足四种同态性，则被称为 算数同态。函数加密与同态加密相关的一个问题是函数加密。同态加密保护的是数据本身，而函数加密顾名思义保护的是处理函数本身，即让第三方看不到处理过程的前提下，对数据进行处理。该问题已被证明是不存在对多个通用函数的任意多 key 的方案，目前仅能做到对某个特定函数的一个 key 的方案。Hash算法公式  公式说明  m：任意长度消息（实际上有长度限制的，但因为长度可以非常大，这里可以认为是任意长度消息） H：哈希函数  h：固定长度的哈希值一个优秀的 hash 算法，将能实现：  正向快速：给定明文和 hash 算法，在有限时间和有限资源内能计算出 hash 值。  逆向困难：给定（若干） hash 值，在有限时间内很难（基本不可能）逆推出明文。  输入敏感：原始输入信息修改一点信息，产生的 hash 值看起来应该都有很大不同。  冲突避免：很难找到两段内容不同的明文，使得它们的 hash 值一致（发生冲突），又称抗碰撞性。抗碰撞性  哈希函数的抗碰撞性是指寻找两个能够产生碰撞的消息在计算上是不可行的。但找到两个碰撞的消息在计算上不可行，并不意味着不存在两个碰撞的消息。哈希函数是把大空间上的消息压缩到小空间上，碰撞肯定存在。只是计算上是不可行的。主流hash算法  MD5(安全性不足应用于商业场景)  SHA-1(安全性不足应用于商业场景)  SHA-2PIPEMD其他流行加密算法Merkle树数字摘要对数字内容进行 Hash 运算，获取唯一的摘要值来指代原始数字内容。数字摘要是解决确保内容没被篡改过的问题（利用 Hash 函数的抗碰撞性特点）。数字摘要是 Hash 算法最重要的一个用途。在网络上下载软件或文件时，往往同时会提供一个数字摘要值，用户下载下来原始文件可以自行进行计算，并同提供的摘要值进行比对，以确保内容没有被修改过。数字签名乙方收到甲方传过来的一串信息，怎么能够确定确实是甲方而不是有人伪造呢？我们把非对称加密反过来做就可以了，因为只有甲方自己才持有一份秘密的私钥，他拿这个私钥对数据进行加密得到密文 C = EA私(M)，乙方持有甲方的公钥，解密明文P = DA公(C)，如果能够解密成功就证明信息确实是甲方所发。不过通常不需要对发送信息的整个内容都加密，那样太慢。只需要计算一个信息的唯一信息摘要并对信息摘要加密解密即可，下面就会讲到数据摘要算法（俗称HASH算法），这也是数字签名的算法名称，很多时候是一个摘要算法+非对称算法，例如SHA1RSA, SHA256RSA等。数字证书数字证书用来证明某个公钥是谁的，并且内容是正确的。对于非对称加密算法和数字签名来说，很重要的一点就是公钥的分发。一旦公钥被人替换（典型的如中间人攻击），则整个安全体系将被破坏掉。怎么确保一个公钥确实是某个人的原始公钥？这就需要数字证书机制。顾名思义，数字证书就是像一个证书一样，证明信息和合法性。由证书认证机构（Certification Authority，CA）来签发，权威的 CA 包括 verisign 等。数字证书内容可能包括版本、序列号、签名算法类型、签发者信息、有效期、被签发人、签发的公开密钥、CA 数字签名、其它信息等等，一般使用最广泛的标准为 ITU 和 ISO 联合制定的 X.509 规范。其中，最重要的包括 签发的公开密钥、CA 数字签名 两个信息。因此，只要通过这个证书就能证明某个公钥是合法的，因为带有 CA 的数字签名。更进一步地，怎么证明 CA 的签名合法不合法呢？类似的，CA 的数字签名合法不合法也是通过 CA 的证书来证明的。主流操作系统和浏览器里面会提前预置一些 CA 的证书（承认这些是合法的证书），然后所有基于他们认证的签名都会自然被认为合法。PKI体系在非对称加密中，公钥则可以通过证书机制来进行保护，如何管理和分发证书则可以通过 PKI（Public Key Infrastructure）来保障。顾名思义，PKI 体系在现代密码学应用领域处于十分基础的地位，解决了十分核心的证书管理问题。PKI 并不代表某个特定的密码学技术和流程，PKI 是建立在公私钥基础上实现安全可靠传递消息和身份确认的一个通用框架。实现了 PKI 的平台可以安全可靠地管理网络中用户的密钥和证书，包括多个实现和变种，知名的有 RSA 公司的 PKCS（Public Key Cryptography Standards）标准和 X.509 规范等。一般情况下，PKI 至少包括如下组件：CA（Certification Authority）：负责证书的颁发和作废，接收来自 RA 的请求，是最核心的部分；RA（Registration Authority）：对用户身份进行验证，校验数据合法性，负责登记，审核过了就发给 CA；证书数据库：存放证书，一般采用 LDAP 目录服务，标准格式采用 X.500 系列。CA 是最核心的组件，主要完成对证书的管理。常见的流程为，用户通过 RA 登记申请证书，CA 完成证书的制造，颁发给用户。用户需要撤销证书则向 CA 发出申请。之前章节内容介绍过，密钥有两种类型：用于签名和用于加解密，对应称为 签名密钥对 和 加密密钥对。用户证书可以有两种方式。一般可以由 CA 来生成证书和私钥；也可以自己生成公钥和私钥，然后由 CA 来对公钥进行签发。后者情况下，当用户私钥丢失后，CA 无法完成恢复。"
                        } ,
                     
                        {
                          "title"    : "共识算法",
                          "category" : "",
                          "tags"     : " 区块链, 算法",
                          "url"      : "/2018/03/23/agreement.html",
                          "date"     : "March 23, 2018",
                          "excerpt"  : "查看原图  drow.io源文件下载",
                          "content"  : "查看原图  drow.io源文件下载"
                        } ,
                     
                        {
                          "title"    : "比特币挖矿",
                          "category" : "",
                          "tags"     : " 区块链, 比特币",
                          "url"      : "/2018/03/18/bitcoin-mining.html",
                          "date"     : "March 18, 2018",
                          "excerpt"  : "查看原图  drow.io源文件下载",
                          "content"  : "查看原图  drow.io源文件下载"
                        } ,
                     
                        {
                          "title"    : "比特币51攻击",
                          "category" : "",
                          "tags"     : " 区块链, 比特币",
                          "url"      : "/2018/03/18/bitcoin-51attach.html",
                          "date"     : "March 18, 2018",
                          "excerpt"  : "查看原图  drow.io源文件下载",
                          "content"  : "查看原图  drow.io源文件下载"
                        } ,
                     
                        {
                          "title"    : "RSA算法",
                          "category" : "",
                          "tags"     : " 加密, 算法",
                          "url"      : "/2018/03/17/rsa.html",
                          "date"     : "March 17, 2018",
                          "excerpt"  : "查看原图  drow.io源文件下载",
                          "content"  : "查看原图  drow.io源文件下载"
                        } ,
                     
                        {
                          "title"    : "拜占庭算法",
                          "category" : "",
                          "tags"     : " 共识, 算法",
                          "url"      : "/2018/03/09/Byzantine-failures.html",
                          "date"     : "March 9, 2018",
                          "excerpt"  : "查看原图  drow.io源文件下载",
                          "content"  : "查看原图  drow.io源文件下载"
                        } ,
                     
                        {
                          "title"    : "比特币网络",
                          "category" : "",
                          "tags"     : " 区块链, 比特币",
                          "url"      : "/2018/03/03/bitcoin-network.html",
                          "date"     : "March 3, 2018",
                          "excerpt"  : "查看原图  drow.io源文件下载",
                          "content"  : "查看原图  drow.io源文件下载"
                        } ,
                     
                        {
                          "title"    : "比特币区块链",
                          "category" : "",
                          "tags"     : " 区块链, 比特币",
                          "url"      : "/2018/03/03/bitcoin-chain.html",
                          "date"     : "March 3, 2018",
                          "excerpt"  : "查看原图  drow.io源文件下载",
                          "content"  : "查看原图  drow.io源文件下载"
                        } ,
                     
                        {
                          "title"    : "比特币交易",
                          "category" : "",
                          "tags"     : " 区块链, 比特币",
                          "url"      : "/2018/02/25/bitcoin-exchange.html",
                          "date"     : "February 25, 2018",
                          "excerpt"  : "查看原图  drow.io源文件下载",
                          "content"  : "查看原图  drow.io源文件下载"
                        } ,
                     
                        {
                          "title"    : "比特币钱包",
                          "category" : "",
                          "tags"     : " 区块链, 比特币",
                          "url"      : "/2018/02/21/bitcoin-wallet.html",
                          "date"     : "February 21, 2018",
                          "excerpt"  : "查看原图  drow.io源文件下载",
                          "content"  : "查看原图  drow.io源文件下载"
                        } ,
                     
                        {
                          "title"    : "比特币地址&amp;密钥",
                          "category" : "",
                          "tags"     : " 区块链, 比特币",
                          "url"      : "/2018/02/21/bitcoin-address.html",
                          "date"     : "February 21, 2018",
                          "excerpt"  : "查看原图  drow.io源文件下载",
                          "content"  : "查看原图  drow.io源文件下载"
                        } ,
                     
                        {
                          "title"    : "shadowsock部署",
                          "category" : "",
                          "tags"     : " shadowsock",
                          "url"      : "/2017/12/11/shadowsock.html",
                          "date"     : "December 11, 2017",
                          "excerpt"  : "部署我是选了网上大多数人推荐的vultr，性价比高，而且还有很骚的操作，后面讲。  1.选服务器，直接选最便宜的，因为我只是拿来当ss用。  2.安装ss参考文章以root用户进入该服务器终端，执行一下命令wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.shchmo...",
                          "content"  : "部署我是选了网上大多数人推荐的vultr，性价比高，而且还有很骚的操作，后面讲。  1.选服务器，直接选最便宜的，因为我只是拿来当ss用。  2.安装ss参考文章以root用户进入该服务器终端，执行一下命令wget --no-check-certificate -O shadowsocks-all.sh https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.shchmod +x shadowsocks-all.sh./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log过程中会提示你输入ss的脚本语言、密码、端口、以及加密方式3.安装加速器参考文章执行wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh &amp;&amp; chmod +x bbr.sh &amp;&amp; ./bbr.sh验证uname -r4.骚操作vultr它是以小时来计费的，即使你是月付的，它也会折算成小时。 那它是怎么算使用的，你部署了服务器，就算使用。  所以我们可以把部署好ss的服务器备份，然后在你不使用的时候摧毁掉，想用的时候再恢复。第一步：点击Add Snapshot，创建一个备份，名称随便填第二步：摧毁第三步：恢复使用安装shadowsocks客户端macbrew install shadowsocks-libevubuntusudo apt install shadowsocks使用shadowsocks客户端1.创建新连接  2.设置ip、端口、加密方式  这样就可以使用我们搭建的ss服务了，其他应用如果要走ss，只需连上我们的shadowsocks即可。 默认shadowsocks的端口为1080我以dropbox为例  只要在首选项&gt;网络&gt;设置代理即可  命令行使用安装proxychains-ngmacbrew install proxychains-ngubuntu# 安装git clone https://github.com/rofl0r/proxychains-ng.git./configure --prefix=/usr --sysconfdir=/etcmakesudo make installsudo make install-config# 配置 socks4 127.0.0.1 9050改为socks5 127.0.0.1 1080vi /usr/local/etc/proxychains.conf# 验证ip是否为ss服务器的ipproxychains4 curl ip.gs之后如果需要只用ss，只要在命令前加上proxychains4即可。"
                        } ,
                     
                        {
                          "title"    : "php实现记住登录",
                          "category" : "",
                          "tags"     : " php, 登录",
                          "url"      : "/2017/06/25/php-remember-login.html",
                          "date"     : "June 25, 2017",
                          "excerpt"  : "流程1.用户通过点击“记住密码”，提交登陆表单传递给服务器。  2.服务器生成唯一标识token，保存到数据库  3.写cookie，设置失效时间（这样token就保存到了客户端）  4.如果用户登陆失效，服务器取客户端token进行校验  5.token与服务器保存的token一致，且没有失效，则判定用户登录成功  6.token与服务器保存的token不一致或超过失效时间，则判定用户需要重新登录方案一用用户id来作为token，如remember_user=1337，这样等于把用户id...",
                          "content"  : "流程1.用户通过点击“记住密码”，提交登陆表单传递给服务器。  2.服务器生成唯一标识token，保存到数据库  3.写cookie，设置失效时间（这样token就保存到了客户端）  4.如果用户登陆失效，服务器取客户端token进行校验  5.token与服务器保存的token一致，且没有失效，则判定用户登录成功  6.token与服务器保存的token不一致或超过失效时间，则判定用户需要重新登录方案一用用户id来作为token，如remember_user=1337，这样等于把用户id暴露了出来。 这样一来，可以不断尝试不同的用户id来登录其他人的账号，甚至可以登录管理员账号，相当危险！！方案二使用一个随机字符串作为token。function generateInsecureToken($length = 20){    $buf = '';    for ($i = 0; $i &lt; $length; ++$i) {        $buf .= chr(mt_rand(0, 255));    }    return bin2hex($buf);}mt_rant其实并不安全，如果你要生成随机数，可以使用以下几个方案1.RandomLib12.random_bytes($length) (PHP 7, or available in PHP 5 via random_compat2)  3.Raw bytes read from /dev/urandom  4.mcrypt_create_iv($length, MCRYPT_DEV_URANDOM)  5.openssl_random_pseudo_bytes($length)可以这么写function generateToken($length = 20){    return bin2hex(random_bytes($length));}这个方案会有时序攻击的风险。 如果你的token＝WBWgm2oMFxsiGRGQNJ6n8gtN3gOuQ2wjN8ZRjZtU0Mn 如果你是通过数据库来校验SELECT * FROM auth_tokens WHERE token = 'WBWgm2oMFxsiGRGQNJ6n8gtN3gOuQ2wjN8ZRjZtU0Mn';或者通过从数据库取出token，在程序中做简单校验$getToken = $_GET[‘token’];if ($getToken == $token) {    //success} else {    //fail}这时有人按以下步骤修改他的cookie1.第一次把第一个字节从W改为X  2.第二次把最后一个字节从n改为o 第二次的校验时间要比第一次的校验时间要短，这样用户可以不断修改尝试来确认更改的字符是否正确，就是一次时序攻击。参考It’s All About Time. 这个时间差异仅在纳秒级有意义。 这不是一个简单或容易的攻击，但是我们写一个存在风险的程序是完全没有意义的。方案三在token中不留下任何有用的信息（甚至服务器时间）给攻击者。 使用selector:validator来取代单一的token，通过selector在数据库中去取出validator,这样可以防止不可避免的时序风险。从数据库取出token，程序中使用hash_equals()来做校验，因为hash_equals()能够防止时序攻击。生成tokenif ($login-&gt;success &amp;&amp; $login-&gt;rememberMe) { // However you implement it    $selector = base64_encode(random_bytes(9));    $authenticator = random_bytes(33);    setcookie(        'remember',         $selector.':'.base64_encode($authenticator),         time() + 864000,         '/',         'yourdomain.com',         true, // TLS-only         true  // http-only    );    $database-&gt;exec(        \"INSERT INTO auth_tokens (selector, token, userid, expires) VALUES (?, ?, ?, ?)\",         [            $selector,            hash('sha256', $authenticator),            $login-&gt;userId,            date('Y-m-d\TH:i:s', time() + 864000)        ]    );}验证if (empty($_SESSION['userid']) &amp;&amp; !empty($_COOKIE['remember'])) {    list($selector, $authenticator) = explode(':', $_COOKIE['remember']);    $row = $database-&gt;selectRow(        \"SELECT * FROM auth_tokens WHERE selector = ?\",        [            $selector        ]    );    if (hash_equals($row['token'], hash('sha256', base64_decode($authenticator)))) {        $_SESSION['userid'] = $row['userid'];        // Then regenerate login token as above    }}实际例子这里没有把uc记住登陆接口用异步请求去处理，主要因为我们系统并不都在同个主域名下，所以如果要实现全系统统一记住登陆处理，只能跳转到uc，在uc设置cookie。1.记住登录 sequenceDiagram    participant 系统A    participant UC    系统A--&gt;&gt;UC: 请求异步登录接口校验    UC-&gt;&gt;系统A: 返回登录校验结果    Note left of 系统A: 失败则结束流程    系统A--&gt;&gt;UC: 跳转到记住登录接口    Note right of UC: 1.生成token 2.写入数据库 3.设置cookie    UC-&gt;&gt;系统A: 跳转回系统A首页    Note left of 系统A: 完成2.校验登录 sequenceDiagram    participant 系统A    participant UC    系统A--&gt;&gt;UC: 跳转到校验记住登录接口    Note right of UC: 校验cookie及有效期    Note right of UC: 校验失败    UC-&gt;&gt;系统A: 跳转回系统A登录页    Note left of 系统A: 完成    Note right of UC: 校验成功 1.生成新token 2.写入数据库 3.设置cookie    UC-&gt;&gt;系统A: 跳转回系统A首页    Note left of 系统A: 完成3.移除记住登录 sequenceDiagram    participant 系统A    participant UC    系统A--&gt;&gt;UC: 跳转到移除记住登录接口    Note right of UC: 1.删除cookie 2.删除数据库token    UC-&gt;&gt;系统A: 跳转回系统A首页    Note left of 系统A: 完成资源            https://github.com/ircmaxell/RandomLib &#8617;              https://github.com/paragonie/random_compat &#8617;      "
                        } ,
                     
                        {
                          "title"    : "php实现webSocket",
                          "category" : "",
                          "tags"     : " php, webSocket",
                          "url"      : "/2017/06/11/php-websocket.html",
                          "date"     : "June 11, 2017",
                          "excerpt"  : "socketSocket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。执行流程服务器端  1.初始化  2.绑定端口(bind)  3.进入监听(listen)  4.阻塞(accept),等待用户连接  5.接收，发送客户端数据客户端  1.初始化  2.连接服务器(connect)  3...",
                          "content"  : "socketSocket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。执行流程服务器端  1.初始化  2.绑定端口(bind)  3.进入监听(listen)  4.阻塞(accept),等待用户连接  5.接收，发送客户端数据客户端  1.初始化  2.连接服务器(connect)  3.发送，读取数据实现服务器端&lt;?php//确保在连接客户端时不会超时set_time_limit(0);$ip = '127.0.0.1';$port = 1935;/* +------------------------------- *    @socket通信整个过程 +------------------------------- *    @socket_create *    @socket_bind *    @socket_listen *    @socket_accept *    @socket_read *    @socket_write *    @socket_close +-------------------------------- *//*----------------    以下操作都是手册上的    -------------------*/if(($sock = socket_create(AF_INET,SOCK_STREAM,SOL_TCP)) &lt; 0) {    echo \"socket_create() 失败的原因是:\".socket_strerror($sock).\"\n\";}if(($ret = socket_bind($sock,$ip,$port)) &lt; 0) {    echo \"socket_bind() 失败的原因是:\".socket_strerror($ret).\"\n\";}if(($ret = socket_listen($sock,4)) &lt; 0) {    echo \"socket_listen() 失败的原因是:\".socket_strerror($ret).\"\n\";}$count = 0;do {    if (($msgsock = socket_accept($sock)) &lt; 0) {        echo \"socket_accept() failed: reason: \" . socket_strerror($msgsock) . \"\n\";        break;    } else {                //发到客户端        $msg =\"测试成功！\n\";        socket_write($msgsock, $msg, strlen($msg));                echo \"测试成功了啊\n\";        $buf = socket_read($msgsock,8192);                        $talkback = \"收到的信息:$buf\n\";        echo $talkback;                if(++$count &gt;= 5){            break;        };                }    //echo $buf;    socket_close($msgsock);} while (true);socket_close($sock);?&gt;客户端&lt;?phperror_reporting(E_ALL);set_time_limit(0);echo \"&lt;h2&gt;TCP/IP Connection&lt;/h2&gt;\n\";$port = 1935;$ip = \"127.0.0.1\";/* +------------------------------- *    @socket连接整个过程 +------------------------------- *    @socket_create *    @socket_connect *    @socket_write *    @socket_read *    @socket_close +-------------------------------- */$socket = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);if ($socket &lt; 0) {    echo \"socket_create() failed: reason: \" . socket_strerror($socket) . \"\n\";}else {    echo \"OK.\n\";}echo \"试图连接 '$ip' 端口 '$port'...\n\";$result = socket_connect($socket, $ip, $port);if ($result &lt; 0) {    echo \"socket_connect() failed.\nReason: ($result) \" . socket_strerror($result) . \"\n\";}else {    echo \"连接OK\n\";}$in = \"Ho\r\n\";$in .= \"first blood\r\n\";$out = '';if(!socket_write($socket, $in, strlen($in))) {    echo \"socket_write() failed: reason: \" . socket_strerror($socket) . \"\n\";}else {    echo \"发送到服务器信息成功！\n\";    echo \"发送的内容为:&lt;font color='red'&gt;$in&lt;/font&gt; &lt;br&gt;\";}while($out = socket_read($socket, 8192)) {    echo \"接收服务器回传信息成功！\n\";    echo \"接受的内容为:\",$out;}echo \"关闭SOCKET...\n\";socket_close($socket);echo \"关闭OK\n\";?&gt;webSocket执行流程  1.初始化  2.绑定端口  3.监听  4.等待用户连接  5.客户端发送握手  6.服务器响应握手  7.握手完毕后,可以相互传输数据  8.连接结束,发送关闭控制帧并断开TCP握手流程socket-select说明function socket_select (array &amp;$read, array &amp;$write, array &amp;$except, $tv_sec, $tv_usec = null)获取read数组中活动的socket，并且把不活跃的从read数组中删除,具体的看文档. 这是一个同步方法，必须得到响应之后才会继续下一步,常用在同步非阻塞IO。  1.新连接到来时,被监听的端口是活跃的,如果是新数据到来或者客户端关闭链接时,活跃的是对应的客户端socket而不是服务器上被监听的端口  2.如果客户端发来数据没有被读走,则socket_select将会始终显示客户端是活跃状态并将其保存在readfds数组中  3.如果客户端先关闭了,则必须手动关闭服务器上相对应的客户端socket,否则socket_select也始终显示该客户端活跃(这个道理跟”有新连接到来然后没有用socket_access把它读出来,导致监听的端口一直活跃”是一样的)实现server.php&lt;?php/** * Simple server class which manage WebSocket protocols * @author Sann-Remy Chea &lt;http://srchea.com&gt; * @license This program is free software: you can redistribute it and/or modify * 	it under the terms of the GNU General Public License as published by * 	the Free Software Foundation, either version 3 of the License, or * 	(at your option) any later version. * 	This program is distributed in the hope that it will be useful, * 	but WITHOUT ANY WARRANTY; without even the implied warranty of * 	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the * 	GNU General Public License for more details. * 	You should have received a copy of the GNU General Public License * 	along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;. * @version 1.0.0 */namespace PushWebSocket;class Server {	/**	 * The address of the server	 * @var String	 */	private $address;	/**	 * The port for the master socket	 * @var int	 */	private $port;	/**	 * The master socket	 * @var Resource	 */	private $master;	/**	 * The array of sockets (1 socket = 1 client)	 * @var Array of resource	 */	private $sockets;	/**	 * The array of connected clients	 * @var Array of clients	 */	private $clients;	/**	 * If true, the server will print messages to the terminal	 * @var Boolean	 */	private $verboseMode;	/**	 * Server constructor	 * @param $address The address IP or hostname of the server (default: 127.0.0.1).	 * @param $port The port for the master socket (default: 5001)	 */	public function __construct($address = '127.0.0.1', $port = 5001, $verboseMode = false) {		$this-&gt;console(\"Server starting...\");		$this-&gt;address = $address;		$this-&gt;port = $port;		$this-&gt;verboseMode = $verboseMode;		// socket creation		$socket = socket_create(AF_INET, SOCK_STREAM, SOL_TCP);		socket_set_option($socket, SOL_SOCKET, SO_REUSEADDR, 1);		if(!is_resource($socket)) {			$this-&gt;console(\"socket_create() failed: \".socket_strerror(socket_last_error()), true);		}		if(!socket_bind($socket, $this-&gt;address, $this-&gt;port)) {			$this-&gt;console(\"socket_bind() failed: \".socket_strerror(socket_last_error()), true);		}		if(!socket_listen($socket, 20)) {			$this-&gt;console(\"socket_listen() failed: \".socket_strerror(socket_last_error()), true);		}		$this-&gt;master = $socket;		$this-&gt;sockets = array($socket);		$this-&gt;console(\"Server started on {$this-&gt;address}:{$this-&gt;port}\");	}	/**	 * Create a client object with its associated socket	 * @param $socket	 */	private function connect($socket) {		$this-&gt;console(\"Creating client...\");		$client = new \PushWebSocket\Client(uniqid(), $socket);		$this-&gt;clients[] = $client;		$this-&gt;sockets[] = $socket;		$this-&gt;console(\"Client #{$client-&gt;getId()} is successfully created!\");	}	/**	 * Do the handshaking between client and server	 * @param $client	 * @param $headers	 */	private function handshake($client, $headers) {		$this-&gt;console(\"Getting client WebSocket version...\");		if(preg_match(\"/Sec-WebSocket-Version: (.*)\r\n/\", $headers, $match)) {			$version = $match[1];		}		else {			$this-&gt;console(\"The client doesn't support WebSocket\");			return false;		}		$this-&gt;console(\"Client WebSocket version is {$version}, (required: 13)\");		if($version == 13) {			// Extract header variables			$this-&gt;console(\"Getting headers...\");			if(preg_match(\"/GET (.*) HTTP/\", $headers, $match))				$root = $match[1];			if(preg_match(\"/Host: (.*)\r\n/\", $headers, $match))				$host = $match[1];			if(preg_match(\"/Origin: (.*)\r\n/\", $headers, $match))				$origin = $match[1];			if(preg_match(\"/Sec-WebSocket-Key: (.*)\r\n/\", $headers, $match))				$key = $match[1];			$this-&gt;console(\"Client headers are:\");			$this-&gt;console(\"\t- Root: \".$root);			$this-&gt;console(\"\t- Host: \".$host);			$this-&gt;console(\"\t- Origin: \".$origin);			$this-&gt;console(\"\t- Sec-WebSocket-Key: \".$key);			$this-&gt;console(\"Generating Sec-WebSocket-Accept key...\");			$acceptKey = $key.'258EAFA5-E914-47DA-95CA-C5AB0DC85B11';			$acceptKey = base64_encode(sha1($acceptKey, true));			$upgrade = \"HTTP/1.1 101 Switching Protocols\r\n\".					   \"Upgrade: websocket\r\n\".					   \"Connection: Upgrade\r\n\".					   \"Sec-WebSocket-Accept: $acceptKey\".					   \"\r\n\r\n\";			$this-&gt;console(\"Sending this response to the client #{$client-&gt;getId()}:\r\n\".$upgrade);			socket_write($client-&gt;getSocket(), $upgrade);			$client-&gt;setHandshake(true);			$this-&gt;console(\"Handshake is successfully done!\");			return true;		}		else {			$this-&gt;console(\"WebSocket version 13 required (the client supports version {$version})\");			return false;		}	}	/**	 * Disconnect a client and close the connection	 * @param $socket	 */	private function disconnect($client) {		$this-&gt;console(\"Disconnecting client #{$client-&gt;getId()}\");		$client-&gt;setIsConnected(false);		$i = array_search($client, $this-&gt;clients);		$j = array_search($client-&gt;getSocket(), $this-&gt;sockets);		if($j &gt;= 0) {			if($client-&gt;getSocket()) {				array_splice($this-&gt;sockets, $j, 1);				socket_shutdown($client-&gt;getSocket(), 2);				socket_close($client-&gt;getSocket());				$this-&gt;console(\"Socket closed\");			}		}		if($i &gt;= 0) {			array_splice($this-&gt;clients, $i, 1);		}		$this-&gt;console(\"Client #{$client-&gt;getId()} disconnected\");	}	/**	 * Get the client associated with the socket	 * @param $socket	 * @return A client object if found, if not false	 */	private function getClientBySocket($socket) {		foreach($this-&gt;clients as $client)			if($client-&gt;getSocket() == $socket) {				$this-&gt;console(\"Client found\");				return $client;			}		return false;	}	/**	 * Do an action	 * @param $client	 * @param $action	 */	private function action($client, $action) {		$action = $this-&gt;unmask($action);		$this-&gt;console(\"Performing action: \".$action);		if($action == \"exit\" || $action == \"quit\") {			$this-&gt;console(\"Killing a child process\");			posix_kill($client-&gt;getPid(), SIGTERM);			$this-&gt;console(\"Process {$client-&gt;getPid()} is killed!\");		}	}	/**	 * Run the server	 */	public function run() {		$this-&gt;console(\"Start running...\");		$this-&gt;console(\"Open in a browser: websocket_client.html (http)\");		$i = 1;		while(true) {			$changed_sockets = $this-&gt;sockets;			if($changed_sockets) {				@socket_select($changed_sockets, $write = NULL, $except = NULL, 1);				foreach($changed_sockets as $socket) {                    //如果是主机，则有新客户端请求连接					if($socket == $this-&gt;master) {						if(($acceptedSocket = socket_accept($this-&gt;master)) &lt; 0) {							$this-&gt;console(\"Socket error: \".socket_strerror(socket_last_error($acceptedSocket)));						}						else {							$this-&gt;console($i);							$this-&gt;connect($acceptedSocket);						}					}                    //有客户端的新数据到来或者关闭链接					else {						$this-&gt;console($i);						$this-&gt;console(\"Finding the socket that associated to the client...\");						$client = $this-&gt;getClientBySocket($socket);						if($client) {							$this-&gt;console(\"Receiving data from the client\");							$data = null;							while($bytes = @socket_recv($socket, $r_data, 2048, MSG_DONTWAIT)) {								$data .= $r_data;							}							if(!$client-&gt;getHandshake()) {								$this-&gt;console(\"Doing the handshake\");								if($this-&gt;handshake($client, $data)) {									$this-&gt;startProcess($client);								}								else {									$this-&gt;disconnect($client);								}							}							elseif($bytes === 0) {								$this-&gt;disconnect($client);							}							else {								// When received data from client								$this-&gt;action($client, $data);							}						}					}				}			}			$i ++;		}	}	/**	 * Start a child process for pushing data	 * @param unknown_type $client	 */	private function startProcess($client) {		$this-&gt;console(\"Start a client process\");		$pid = pcntl_fork();		if($pid == -1) {			die('could not fork');		}		elseif($pid) { // process			$client-&gt;setPid($pid);		}		else {			// we are the child			while(true) {				// check if the client is connected				if(!$client-&gt;isConnected()){					break;				}				// push something to the client				$seconds = rand(2, 5);				$this-&gt;send($client, \"I am waiting {$seconds} seconds\");				sleep($seconds);			}		}	}	/**	 * Send a text to client	 * @param $client	 * @param $text	 */	private function send($client, $text) {		$this-&gt;console(\"Send '\".$text.\"' to client #{$client-&gt;getId()}\");		$text = $this-&gt;encode($text);		if(socket_write($client-&gt;getSocket(), $text, strlen($text)) === false) {			$this-&gt;console(\"Unable to write to client #{$client-&gt;getId()}'s socket\");			$this-&gt;disconnect($client);		}	}	/**	 * Encode a text for sending to clients via ws://	 * @param $text	 * @param $messageType	 */	function encode($message, $messageType='text') {		switch ($messageType) {			case 'continuous':				$b1 = 0;				break;			case 'text':				$b1 = 1;				break;			case 'binary':				$b1 = 2;				break;			case 'close':				$b1 = 8;				break;			case 'ping':				$b1 = 9;				break;			case 'pong':				$b1 = 10;				break;		}			$b1 += 128;		$length = strlen($message);		$lengthField = \"\";		if($length &lt; 126) {			$b2 = $length;		} elseif($length &lt;= 65536) {			$b2 = 126;			$hexLength = dechex($length);			//$this-&gt;stdout(\"Hex Length: $hexLength\");			if(strlen($hexLength)%2 == 1) {				$hexLength = '0' . $hexLength;			}			$n = strlen($hexLength) - 2;			for($i = $n; $i &gt;= 0; $i=$i-2) {				$lengthField = chr(hexdec(substr($hexLength, $i, 2))) . $lengthField;			}			while(strlen($lengthField) &lt; 2) {				$lengthField = chr(0) . $lengthField;			}		} else {			$b2 = 127;			$hexLength = dechex($length);			if(strlen($hexLength) % 2 == 1) {				$hexLength = '0' . $hexLength;			}			$n = strlen($hexLength) - 2;			for($i = $n; $i &gt;= 0; $i = $i - 2) {				$lengthField = chr(hexdec(substr($hexLength, $i, 2))) . $lengthField;			}			while(strlen($lengthField) &lt; 8) {				$lengthField = chr(0) . $lengthField;			}		}		return chr($b1) . chr($b2) . $lengthField . $message;	}	/**	 * Unmask a received payload	 * @param $buffer	 */	private function unmask($payload) {		$length = ord($payload[1]) &amp; 127;		if($length == 126) {			$masks = substr($payload, 4, 4);			$data = substr($payload, 8);		}		elseif($length == 127) {			$masks = substr($payload, 10, 4);			$data = substr($payload, 14);		}		else {			$masks = substr($payload, 2, 4);			$data = substr($payload, 6);		}		$text = '';		for($i = 0; $i &lt; strlen($data); ++$i) {			$text .= $data[$i] ^ $masks[$i%4];		}		return $text;	}	/**	 * Print a text to the terminal	 * @param $text the text to display	 * @param $exit if true, the process will exit	 */	private function console($text, $exit = false) {		$text = date('[Y-m-d H:i:s] ').$text.\"\r\n\";		if($exit) {			die($text);		}		if($this-&gt;verboseMode) {			echo $text;		}	}}?&gt;client.php/** * Define a Client object * @author Sann-Remy Chea &lt;http://srchea.com&gt; * @license This program is free software: you can redistribute it and/or modify * it under the terms of the GNU General Public License as published by * the Free Software Foundation, either version 3 of the License, or * (at your option) any later version. * This program is distributed in the hope that it will be useful, * but WITHOUT ANY WARRANTY; without even the implied warranty of * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the * GNU General Public License for more details. * You should have received a copy of the GNU General Public License * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;. * @version 1.0.0 */namespace PushWebSocket;class Client {	private $id;	private $socket;	private $handshake;	private $pid;	private $isConnected;	public function __construct($id, $socket) {		$this-&gt;id = $id;		$this-&gt;socket = $socket;		$this-&gt;handshake = false;		$this-&gt;pid = null;		$this-&gt;isConnected = true;	}	public function getId() {		return $this-&gt;id;	}	public function getSocket() {		return $this-&gt;socket;	}	public function getHandshake() {		return $this-&gt;handshake;	}	public function getPid() {		return $this-&gt;pid;	}	public function isConnected() {		return $this-&gt;isConnected;	}	public function setId($id) {		$this-&gt;id = $id;	}	public function setSocket($socket) {		$this-&gt;socket = $socket;	}	public function setHandshake($handshake) {		$this-&gt;handshake = $handshake;	}	public function setPid($pid) {		$this-&gt;pid = $pid;	}	public function setIsConnected($isConnected) {		$this-&gt;isConnected = $isConnected;	}}run.php/** * A daemon of PHP Push WebSocket * @author Sann-Remy Chea &lt;http://srchea.com&gt; * @license This program is free software: you can redistribute it and/or modify * it under the terms of the GNU General Public License as published by * the Free Software Foundation, either version 3 of the License, or * (at your option) any later version. * This program is distributed in the hope that it will be useful, * but WITHOUT ANY WARRANTY; without even the implied warranty of * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the * GNU General Public License for more details. * You should have received a copy of the GNU General Public License * along with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;. * @version 1.0.0 */date_default_timezone_set('PRC');error_reporting(E_ALL);require_once './server.php'; // Autoload files using Composer autoloadrequire_once './client.php'; // Autoload files using Composer autoloadset_time_limit(0);// variables$address = '0.0.0.0';$port = 8080;$verboseMode = true;$server = new \PushWebSocket\Server($address, $port, $verboseMode);$server-&gt;run();client.html&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Test - PHP Push WebSocket&lt;/title&gt;&lt;meta charset=\"utf-8\" /&gt;&lt;script type=\"text/javascript\"&gt;var ws, url = 'ws://192.168.99.100:8080';window.onbeforeunload = function() {	ws.send('quit');};window.onload = function() {	try {		ws = new WebSocket(url);		write('Connecting... (readyState '+ws.readyState+')');		ws.onopen = function(msg) {			write('Connection successfully opened (readyState ' + this.readyState+')');		};		ws.onmessage = function(msg) {			write('Server says: '+msg.data);		};		ws.onclose = function(msg) {			if(this.readyState == 2)				write('Closing... The connection is going throught the closing handshake (readyState '+this.readyState+')');			else if(this.readyState == 3)				write('Connection closed... The connection has been closed or could not be opened (readyState '+this.readyState+')');			else				write('Connection closed... (unhandled readyState '+this.readyState+')');		};		ws.onerror = function(event) {			terminal.innerHTML = '&lt;li style=\"color: red;\"&gt;'+event.data+'&lt;/li&gt;'+terminal.innerHTML;		};	}	catch(exception) {		write(exception);	}};function write(text) {	var date = new Date();	var dateText = '['+date.getFullYear()+'-'+(date.getMonth()+1 &gt; 9 ? date.getMonth()+1 : '0'+date.getMonth()+1)+'-'+(date.getDate() &gt; 9 ? date.getDate() : '0'+date.getDate())+' '+(date.getHours() &gt; 9 ? date.getHours() : '0'+date.getHours())+':'+(date.getMinutes() &gt; 9 ? date.getMinutes() : '0'+date.getMinutes())+':'+(date.getSeconds() &gt; 9 ? date.getSeconds() : '0'+date.getSeconds())+']';	var terminal = document.getElementById('terminal');	terminal.innerHTML = '&lt;li&gt;'+dateText+' '+text+'&lt;/li&gt;'+terminal.innerHTML;}&lt;/script&gt;&lt;/head&gt;&lt;body&gt;	&lt;a href=\"client.html\" target=\"_blank\"&gt;Add another client&lt;/a&gt;	&lt;ul id=\"terminal\"&gt;&lt;/ul&gt;&lt;/body&gt;&lt;/html&gt;使用swoole&lt;?php$server = new swoole_websocket_server(\"0.0.0.0\", 8080);$server-&gt;on('open', function (swoole_websocket_server $server, $request) {    file_put_contents( __DIR__ .'/log.txt' , $request-&gt;fd);});$server-&gt;on('message', function (swoole_websocket_server $server, $frame) {    global $client;    $data = $frame-&gt;data;    $m = file_get_contents( __DIR__ .'/log.txt');    for ($i=1 ; $i&lt;= $m ; $i++) {        echo PHP_EOL . '  i is  ' . $i .  '  data  is '.$data  . '  m = ' . $m;        $server-&gt;push($i, $data );    }});$server-&gt;on('close', function ($ser, $fd) {    echo \"client {$fd} closed\n\";});$server-&gt;start();参考文章深入浅出讲解：php的socket通信  细说websocket - php篇  php socket_select() 说明"
                        } ,
                     
                        {
                          "title"    : "php实现守护进程",
                          "category" : "",
                          "tags"     : " php, 守护进程",
                          "url"      : "/2017/02/05/php-daemon.html",
                          "date"     : "February 5, 2017",
                          "excerpt"  : "守护进程应该能达到的要求 不依赖于当前会话，且无法打开控制终端。编写过程  1.假设当前进程为p  2.创建子进程c1，然后退出父进程p(进程组组长无法创建会话，这样c1就不是进程组组长)。  3.在c1进程中创建会话，此时进程c1为会话组长，并且可以打开控制终端。  4.在c1进程中创建子进程c2,退出父进程c1。  5.在c2进程中进行逻辑处理。实现&lt;?php// 创建子进程$pid = pcntl_fork();// 如果是父进程，退出if ($pid) {    exit($...",
                          "content"  : "守护进程应该能达到的要求 不依赖于当前会话，且无法打开控制终端。编写过程  1.假设当前进程为p  2.创建子进程c1，然后退出父进程p(进程组组长无法创建会话，这样c1就不是进程组组长)。  3.在c1进程中创建会话，此时进程c1为会话组长，并且可以打开控制终端。  4.在c1进程中创建子进程c2,退出父进程c1。  5.在c2进程中进行逻辑处理。实现&lt;?php// 创建子进程$pid = pcntl_fork();// 如果是父进程，退出if ($pid) {    exit($pid);}// 创建会话posix_setsid();// 创建子进程$pid = pcntl_fork();// 如果是父进程，退出if ($pid) {    exit($pid);}while(true) {    //逻辑处理    sleep(1);    echo '执行中';}参考文章  Linux信号列表详解  Linux-进程、进程组、作业、会话、控制终端详解  进程 、进程组、会话、控制终端之间的关系  php写守护进程（Daemon）  每天进步一点点——Linux中的文件描述符与打开文件之间的关系  Linux 系统文件描述符继承带来的危害  关于PHP的STDIN/STDOUT/STDERR  PHP高级编程之守护进程，实现优雅重启"
                        } ,
                     
                        {
                          "title"    : "mac使用rsync+fswatch实现目录文件实时同步",
                          "category" : "",
                          "tags"     : " 文件同步",
                          "url"      : "/2017/02/02/mac-rsync-fswatch.html",
                          "date"     : "February 2, 2017",
                          "excerpt"  : "安装rsyncbrew install rsync创建用户创建用户配置文件\etc\rsyncd.secrets  添加用户名:密码  这里我们设置用户名为root，密码123456，即root:123456配置创建配置文件 \etc\rsyncd.confuid = root                   #守护进程的用户权限gid = rootport = 873                   #rsync使用的端口，默认873address = 192.168.0.101...",
                          "content"  : "安装rsyncbrew install rsync创建用户创建用户配置文件\etc\rsyncd.secrets  添加用户名:密码  这里我们设置用户名为root，密码123456，即root:123456配置创建配置文件 \etc\rsyncd.confuid = root                   #守护进程的用户权限gid = rootport = 873                   #rsync使用的端口，默认873address = 192.168.0.101      # 本机的ip地址use chroot = yesuid = root                   #守护进程的用户权限gid = rootport = 873                   #rsync使用的端口，默认873address = 192.168.0.101      # 本机的ip地址use chroot = yesread only = no               # no客户端可上传文件,yes只读write only = no              # no客户端可下载文件,yes不能下载#list = yes                  # 是否提供资源列表hosts allow=192.168.0.101    # 本模块允许通过的IP地址hosts deny=*                 # 禁止主机IPmax connections = 5          # 客户端最大连接数目motd file = /etc/rsyncd.motdpid file = /var/run/rsyncd.pid   # 进程号存放位置log file = /var/log/rsyncd.log   # 日志位置lock file = /var/run/rsync.lock  # 锁文件存放位置transfer logging = yeslog format = %t %a %m %f %bsyslog facility = local3timeout = 300[phproot1]                            # 要同步的模块名path = /Users/Username/Document/Kitematic/nginx/htdocs/php1 # 要同步的目录list=yesignore errorsauth users = root                  # 登陆系统使用的用户名，没有默认为匿名。secrets file = /etc/rsyncd.secrets # 密码文件存放的位置comment = linuxsir tmp             # 这个名名称无所谓，最后模块名一直[phproot2]                            # 要同步的模块名path = /Users/Username/Document/Kitematic/nginx/htdocs/php2 # 要同步的目录list=yesignore errorsauth users = root                  # 登陆系统使用的用户名，没有默认为匿名。secrets file = /etc/rsyncd.secrets # 密码文件存放的位置comment = linuxsir tmp             # 这个名名称无所谓，最后模块名一直[phproot3]                            # 要同步的模块名path = /Users/Username/Document/Kitematic/nginx/htdocs/php3 # 要同步的目录list=yesignore errorsauth users = root                  # 登陆系统使用的用户名，没有默认为匿名。secrets file = /etc/rsyncd.secrets # 密码文件存放的位置comment = linuxsir tmp             # 这个名名称无所谓，最后模块名一直这里我们设置了3个同步模块，对应三个需要同步的目录启动sudo rsync --daemon --config=/etc/rsyncd.conf同步这里我们以同步/Users/Username/Document/Kitematic/nginx/htdocs/php1到/Users/Username/Document/Kitematic/nginx/htdocs/php2为例本地同步rsync -ave /Users/Username/Document/Kitematic/nginx/htdocs/php1/ /Users/Username/Document/Kitematic/nginx/htdocs/php2/远程同步rsync -ave ssh /Users/Username/Document/Kitematic/nginx/htdocs/php1/ username@192.168.0.101:phproot1/安装fswatchbrew install fswatch实时同步创建shell文件 rsync.sh#!/bin/zshfswatch /Users/zhongjunbin/Document/Kitematic/nginx/htdocs/php1/ | while read filedo    rsync -ave ssh /Users/Username/Document/Kitematic/nginx/htdocs/php1/ Username@192.168.0.101:phproot2/    rsync -ave ssh /Users/Username/Document/Kitematic/nginx/htdocs/php1/ Username@192.168.0.101:phproot3/    echo \"${file} was rsynced\" &gt;&gt; /usr/local/var/log/rsync.log 2&gt;&amp;1donefswatch /Users/zhongjunbin/Document/Kitematic/nginx/htdocs/php2/ | while read filedo    rsync -ave ssh /Users/Username/Document/Kitematic/nginx/htdocs/php1/ Username@192.168.0.101:phproot1/    rsync -ave ssh /Users/Username/Document/Kitematic/nginx/htdocs/php1/ Username@192.168.0.101:phproot3/    echo \"${file} was rsynced\" &gt;&gt; /usr/local/var/log/rsync.log 2&gt;&amp;1donefswatch /Users/zhongjunbin/Document/Kitematic/nginx/htdocs/php3/ | while read filedo    rsync -ave ssh /Users/Username/Document/Kitematic/nginx/htdocs/php1/ Username@192.168.0.101:phproot1/    rsync -ave ssh /Users/Username/Document/Kitematic/nginx/htdocs/php1/ Username@192.168.0.101:phproot2/    echo \"${file} was rsynced\" &gt;&gt; /usr/local/var/log/rsync.log 2&gt;&amp;1done后台运行shellsudo sh rsync.sh &amp;完成"
                        } ,
                     
                        {
                          "title"    : "数据库的事务处理",
                          "category" : "",
                          "tags"     : " 数据库, 分布式",
                          "url"      : "/2016/11/24/transaction-deal.html",
                          "date"     : "November 24, 2016",
                          "excerpt"  : "事务四个核心要素1.原子性  一组操作，要么都成功，要么都失败，不存在中间状态。  2.一致性  事务在提交或回滚时，对其他人来说，数据的状态是统一的，不存在其他状态。  最理想的状态是，数据提交后，所有的更改能立刻生效，但由于cpu运算，磁盘写入，内存写入需要时间，所以不可能达到立刻生效。  所以一般说的是逻辑上同时生效。  比如修改a，b两行数据，要保证一致性，对a，b加锁，修改数据，对a，b解锁。  3.隔离性  读未提交：什么锁也没有，别人可以读到中间状态（即为提交）数据。  读已...",
                          "content"  : "事务四个核心要素1.原子性  一组操作，要么都成功，要么都失败，不存在中间状态。  2.一致性  事务在提交或回滚时，对其他人来说，数据的状态是统一的，不存在其他状态。  最理想的状态是，数据提交后，所有的更改能立刻生效，但由于cpu运算，磁盘写入，内存写入需要时间，所以不可能达到立刻生效。  所以一般说的是逻辑上同时生效。  比如修改a，b两行数据，要保证一致性，对a，b加锁，修改数据，对a，b解锁。  3.隔离性  读未提交：什么锁也没有，别人可以读到中间状态（即为提交）数据。  读已提交：（读写锁）即不可重复读。在一个事务中，两次读取同样一条记录，数据可能会改变。  可重复读：（读写锁）在事务中读取的数据，在提交前不会被改变。 序列化：事务被处理为顺序执行。  4.持久性  事务执行完，数据就不会丢。单机事务从性能上看，读写锁在并行上并不理想，因为读的时候不能写，写的时候不能读。 于是MVCC出现了  MVCC是使用copy-on-write来解决这个问题  一个人开启一个事务，此时会申请一个事务id，此id是自增的且不会合并到全局id。在事务中，每执行一条sql都会令这个id递增，但只会读取到&lt;=自己事务id的数据， 这样就实现了数据读取不受事务外影响，即可重复读。而其他人只会读取&lt;=全局事务id的数据。在事务提交时，把该事务id更新到全局id。Q1: MVCC有解决版本冲突的问题吗？  Q2: 不同数据库的MVCC实现多机事务在单机事务中我们可以用锁来解决问题。可以用一个例子来说明这个问题，bob要给smith100块钱。  最简单的协议是,两段提交协议  Prepare(bob-100) at 机器a -&gt; Prepare(smith+100) at 机器b -&gt; commit(bob) -&gt; commit(smith)这样会引发一个性能问题，如果b机器一直无反馈，导致a机器一直处于等待状态，锁无法释放。如何改进呢？  其实smith并不需要很强的一致可见性，只要在合理时间内给smith加钱就行了。 在a机器做如下操作：  1.开启本地事务  2.读取bob账户  3.判断是否有充足余额  4.更新bob账户，bob－100  5.将需要给smith＋100写log，并且生成唯一的transactionID  6.事务关闭  7.异步发送通知消费者  在b机器做如下操作 查看去重表是否有相应transactionID，如果没有则  1.开启本地事务  2.smith＋100  3.将transactionID写入去重表  4.事务关闭  5.通知a机器已操作成功  如果有则通知a机器已操作成功Q1: 为何要使用去重表呢？ 因为b有可能会操作失败，或无反馈给a。此时a应继续发送通知，直到b反馈成功。 如果不用去重表，会导致b已操作成功，而a仍继续发送通知，让b去给smith＋100。  Q2: 如果bob是个消费大户，短时间内进行了大量购买，可能会让bob所在机器成为热点，可能会让事务在某个单节点大量堆积，导致挂掉。  可把写log操作放到另外一台机器，这样可以通过水平加log机器来防止热点产生。  Q3: 如果有几十个系统同时关注smith＋100这个操作呢？ 可以增加一个队列，使用推，拉，或推拉结合的方式将smith＋100这个操作加以分发，减少主机压力。"
                        } ,
                     
                        {
                          "title"    : "数据库的一致性与高可用",
                          "category" : "",
                          "tags"     : " 分布式",
                          "url"      : "/2016/11/24/consistency-highavailability.html",
                          "date"     : "November 24, 2016",
                          "excerpt"  : "在给定多台计算机，他们相互之间由网络相互连通，能够做到  1.数据每次成功写入，数据不会丢失，并且按照写入的顺序排列  2.给定安全级别，保证服务可用性，并尽可能减少机器消耗。2PC所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）。准备阶段事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。...",
                          "content"  : "在给定多台计算机，他们相互之间由网络相互连通，能够做到  1.数据每次成功写入，数据不会丢失，并且按照写入的顺序排列  2.给定安全级别，保证服务可用性，并尽可能减少机器消耗。2PC所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）。准备阶段事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态。可以进一步将准备阶段分为以下三个步骤：  1）协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。  2）参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作）  3）各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。提交阶段如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)接下来分两种情况分别讨论提交阶段的过程。当协调者节点从所有参与者节点获得的相应消息都为”同意”时:1）协调者节点向所有参与者节点发出”正式提交(commit)”的请求。  2）参与者节点正式完成操作，并释放在整个事务期间内占用的资源。  3）参与者节点向协调者节点发送”完成”消息。  4）协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。如果任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：1）协调者节点向所有参与者节点发出”回滚操作(rollback)”的请求。  2）参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。  3）参与者节点向协调者节点发送”回滚完成”消息。  4）协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务。不管最后结果如何，第二阶段都会结束当前事务。  二阶段提交看起来确实能够提供原子性的操作，但是不幸的事，二阶段提交还是有几个缺点的：  1.同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。  2.单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）  3.数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。  4.二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。  由于二阶段提交存在着诸如同步阻塞、单点问题、脑裂等缺陷，所以，研究者们在二阶段提交的基础上做了改进，提出了三阶段提交。3PC三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。与两阶段提交不同的是，三阶段提交有两个改动点。  1.引入超时机制。同时在协调者和参与者中都引入超时机制。  2.在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。  也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。CanCommit阶段3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。  1.事务询问 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。  2.响应反馈 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈NoPreCommit阶段协调者根据参与者的反应情况来决定是否可以记性事务的PreCommit操作。根据响应情况，有以下两种可能。  假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行。  1.发送预提交请求 协调者向参与者发送PreCommit请求，并进入Prepared阶段。  2.事务预提交 参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。  3.响应反馈 如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。  1.发送中断请求 协调者向所有参与者发送abort请求。  2.中断事务 参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。doCommit阶段该阶段进行真正的事务提交，也可以分为以下两种情况。执行提交  1.发送提交请求 协调接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。  2.事务提交 参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。  3.响应反馈 事务提交完之后，向协调者发送Ack响应。  4.完成事务 协调者接收到所有参与者的ack响应之后，完成事务。中断事务  协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。  1.发送中断请求 协调者向所有参与者发送abort请求  2.事务回滚 参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。3.反馈结果 参与者完成事务回滚之后，向协调者发送ACK消息  4.中断事务 协调者接收到参与者反馈的ACK消息之后，执行事务的中断。在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。 ）2PC与3PC的区别相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。了解了2PC和3PC之后，我们可以发现，无论是二阶段提交还是三阶段提交都无法彻底解决分布式的一致性问题。Google Chubby的作者Mike Burrows说过， there is only one consensus protocol, and that’s Paxos” – all other approaches are just broken versions of Paxos. 意即世上只有一种一致性算法，那就是Paxos，所有其他一致性算法都是Paxos算法的不完整版。Paxos其实就是“少数服从多数”我们假定有A,B,C,D,E五台机器。kv系统需要put一个数据[key=Whisper -&gt; val=3306]到我们这5台机器上，要保证只要反馈为真，任意两台机器挂掉都不会丢失数据，并且可以保证高可用。怎么做：  首先,客户端随机选择一个节点，进行写入提交，这里我们随机选择了C这个节点，这时候C节点就是这次提议的发起人【也叫proposer，在老的2pc协议里也叫做coodinator】，当C收到这个提议的时候，C首先要做的事情是根据当前节点的最新全局global id，做一次自增操作，我们假定，在当时全局id,Global ID是0,所以，这个议案就被对应了一个编号，1—&gt;[key=Whisper -&gt; val=3306]。这里有两个我们经常犯的错误，下面做一个解说：  1.global id问题，在老的论文里，Lamport没有描述这个自增id是怎么生成的，所以大家的第一个疑问一般是问id怎么生成，从我目前能够看到的所有实现里面，基本上就是选择哪一台机器，就是以那台机器当前所保持的全局id(snapshot，可能不是全局来看的最高值，但没关系，只要是自己这台机器的最高值就行了)，然后做一下自增就行了。我们后面会看到协议如何保证非全局最高值的globalID提议会被拒绝以至于不能够形成决议。  2.global id —&gt;[key=Whisper -&gt; val=3306] . 这也是个会让人困惑的问题，在原文中，他被表示为一个key-value的形式，比如proposal[0-&gt;value] 。这会让人自然的联想到与数据库的kv相对应，key是0，value是value。然后就会困惑，这个数据是怎么和数据库对应起来的呢？这是我当时的困惑，现在也把他列在这里。其实很简单，这里的global id对应value.global id只是对paxos协议有意义，对于数据库，其实只需要关心value里面的数据即可，也即将global id —&gt;[key=Whisper -&gt; val=3306]里面的value: [key=Whisper-&gt; val=3306] 作为数据库构建映射时所需要的redoLog就行了，global id的作用只是告诉你这些数据的顺序是按照global id来排列的，其他无意义。我们回到文中，我们已经将这个新的议案标记了从C这台机器看起来最大的global id : 1—&gt;[key=Whisper -&gt; val=3306]。然后，他会尝试将这个信息发送给其余的A,B,D,E这几台机器。 我们来看这些机器的操作流程。 在这个过程中，Paxos将A,B,D,E叫做accepter【老的协议里没有区分，管这些都叫做参与者，cohorts】，他们的行为模式如下： 如果A,B,D,E这几台机器的globalID 小于C给出的决议的GID(1—&gt;[key=Whisper -&gt; val=3306])，那么就告诉C，这个决议被批准了。而如果A,B,D,E这几台机器的GlobalID 大于或等于C给出决议的GID.那么就告知C 这个决议不能够被批准。 我们假定A,B两台机器当时的Max(GID)是0 ，而D,E的Max(GID)是1.那么，A,B两台机器会反馈给C说协议被接受，这时候我们算算，C的议案有几票了？A+B+!C!，一定要算自己哦:) 。所以，这个议案有三票，5台机器的半数是3.超过法定人数，于是决议就被同意了。我们保持这个上下文，来看看D,E这边的情况。首先，要思考的问题是，为什么D,E的Max(GID)是1呢？ 其实很简单，D可能在C发起决议的同时，也发起了一个决议，我们假定这个决议是由D发起的，决议是 1—&gt;[key=taobao -&gt;val=1234]。既然D,E的Max(GID)是1，那么意味着E已经告知D,它同意了他的决议，但D马上会发现，A,B,C里面的任意一个都返回了D不同意。他的议案只拿到两票，没有通过，它虽然有点不爽，但也是没办法的事情啊。。这时候C的决议已经被多数派接受，所以他需要告知所有人，我的议案1—&gt;[key=Whisper -&gt; val=3306]已经被接受，你们去学习吧。zab协议(Paxos改进)zab协议把整个过程分为两个部分，第一个部分叫选总统，第二个部分叫进行决议。 选总统的过程比较特殊，这种模式，相对的给人感觉思路来源于lamport的面包房算法，这个我们后面讲。，选择的主要依据是：  1.如果有gid最大的机器，那么他是主机。  2.如果好几台主机的gid相同，那么按照序号选择最小的那个。所以，在开始的时候，给A,B,C,D,E进行编号，0,1,2,3,4。 第一轮的时候，因为大家的Max(gid)都是0，所以自然而然按照第二个规则，选择A作为主机。 然后，所有人都知道A是主机以后，无论谁收到的请求，都直接转发给A,由A机器去做后续的分发，这个分发的过程，我们叫进行决议。  进行决议的规则就简单很多了，对其他机器进行3pc 提交，但与3pc不同的是，因为是群发议案给所有其他机器，所以一个机器无反馈对大局是没有影响的，只有当在一段时间以后，超过半数没有反馈，才是有问题的时候，这时候要做的事情是，重新选择总统。 具体过程是，A会将决议precommit给B,C,D,E。然后等待，当B,C,D,E里面的任意两个返回收到后，就可以进行doCommit().否则进行doAbort(). 为什么要任意两个？原因其实也是一样的，为了防止脑裂，原则上只能大于半数，不能少于半数，因为一旦决议成立的投票数少于半数，那么就存在另立中央的可能，两个总统可不是闹着玩的。  定两个，就能够保证，任意“两台”机器挂掉，数据不丢:)，能够做到quorum。参考文章淘宝沈询"
                        } ,
                     
                        {
                          "title"    : "php线程安全",
                          "category" : "",
                          "tags"     : " php",
                          "url"      : "/2016/11/18/php-about-thred-safe.html",
                          "date"     : "November 18, 2016",
                          "excerpt"  : "线程不安全线程不安全就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据。  比如一个 ArrayList 类，在添加一个元素的时候，它可能会有两步来完成：1. 在 Items[Size] 的位置存放此元素；2. 增大 Size 的值。  在单线程运行的情况下，如果 Size = 0，添加一个元素后，此元素在位置 0，而且 Size=1；  而如果是在多线程情况下，比如有两个线程，线程 A 先将元素1存放在位置 0。但是此时 CPU 调度线程A暂停，线程 B 得到...",
                          "content"  : "线程不安全线程不安全就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据。  比如一个 ArrayList 类，在添加一个元素的时候，它可能会有两步来完成：1. 在 Items[Size] 的位置存放此元素；2. 增大 Size 的值。  在单线程运行的情况下，如果 Size = 0，添加一个元素后，此元素在位置 0，而且 Size=1；  而如果是在多线程情况下，比如有两个线程，线程 A 先将元素1存放在位置 0。但是此时 CPU 调度线程A暂停，线程 B 得到运行的机会。线程B向此 ArrayList 添加元素2，因为此时 Size 仍然等于 0 （注意，我们假设的是添加一个元素是要两个步骤，而线程A仅仅完成了步骤1），所以线程B也将元素存放在位置0。然后线程A和线程B都继续运行，都增加 Size 的值，结果Size等于2。处理http并发目前有两种响应请求方式  1.创建线程（线程不安全）  2.创建进程，每个进程都是单线程（线程安全）php自身是不响应http请求的，需要通过配置apache或nginx服务器来请求转发。apache支持两种并发模式  1.Worker MPM ,使用创建线程来处理并发，这种情况php需要选择线程安全版本  2.Prefork MPM 使用创建进程来处理并发其他像nginx,lighttpd使用FastCGI，都是通过进程来处理请求，所以不存在线程安全问题。php异步处理fsockopen,stream_socket等都是通过socket来创建进程实现异步处理，不存在线程安全。 curl是通过异步发起http请求来处理的，所以也不存在线程安全。php实现多线程可通过安装pthreads扩展库来实现，有线程安全问题，需要使用线程安全版本。"
                        } ,
                     
                        {
                          "title"    : "线程与cpu核",
                          "category" : "",
                          "tags"     : " 操作系统",
                          "url"      : "/2016/11/14/system-thread-cpu.html",
                          "date"     : "November 14, 2016",
                          "excerpt"  : "进程，线程，核之间的关联  1.一个应用普遍只占一个进程，一个进程可以衍生出多个线程，而核只与线程有关。  2.一个线程只能在一个核上面跑。单核CPU，程序可以创建多个线程，但他们并不是真正意义上的并行执行，因为他们只会占用一个核，所以只是切换速度较快，没察觉到。每个线程会分配差不多20ms的时间片，执行完时间片，会切换到其他线程，该线程会处于等待执行状态，等其他线程执行完，再继续执行20ms。如果遇到有某些操作比较耗时，又要及时反馈给用户，还是很有必要多线程的。多核CPU，应该多用多线程...",
                          "content"  : "进程，线程，核之间的关联  1.一个应用普遍只占一个进程，一个进程可以衍生出多个线程，而核只与线程有关。  2.一个线程只能在一个核上面跑。单核CPU，程序可以创建多个线程，但他们并不是真正意义上的并行执行，因为他们只会占用一个核，所以只是切换速度较快，没察觉到。每个线程会分配差不多20ms的时间片，执行完时间片，会切换到其他线程，该线程会处于等待执行状态，等其他线程执行完，再继续执行20ms。如果遇到有某些操作比较耗时，又要及时反馈给用户，还是很有必要多线程的。多核CPU，应该多用多线程，系统会把线程平均分配到每个核上面，一个核上面的线程处理参考上面的单核CPU。"
                        } ,
                     
                        {
                          "title"    : "监督学习与梯度下降",
                          "category" : "",
                          "tags"     : " 机器学习",
                          "url"      : "/2016/11/14/machinelearning-supervised.html",
                          "date"     : "November 14, 2016",
                          "excerpt"  : "假设一个问题有n个特征，线性函数为  其中   差值计算，其中m为训练数据  所以我们要求出当最小值时的特征参数值。主要有两种方式来求出  1.梯度下降  2.正则方程组梯度下降把计算结果与真实结果的差值比做山顶，通过找寻山的最大坡度下降，达到最快到达山脚，从而实现最小差值。对每个求导，得出最快下降梯度，然后沿着这梯度下降。学习速度或下降速度。python实例import numpy as npimport matplotlib.pyplot as pltx_train = np.arra...",
                          "content"  : "假设一个问题有n个特征，线性函数为  其中   差值计算，其中m为训练数据  所以我们要求出当最小值时的特征参数值。主要有两种方式来求出  1.梯度下降  2.正则方程组梯度下降把计算结果与真实结果的差值比做山顶，通过找寻山的最大坡度下降，达到最快到达山脚，从而实现最小差值。对每个求导，得出最快下降梯度，然后沿着这梯度下降。学习速度或下降速度。python实例import numpy as npimport matplotlib.pyplot as pltx_train = np.array([[1, 2], [2, 1], [2, 3], [3, 5], [1, 3], [4, 2], [7, 3], [4, 5], [11, 3], [8, 7]])y_train = np.array([7, 8, 10, 14, 8, 13, 20, 16, 28, 26])x_test  = np.array([[1, 4], [2, 2], [2, 5], [5, 3], [1, 5], [4, 1]])def h(x, theta0_guess, theta1_guess, theta2_guess):return theta0_guess + theta1_guess * x[0] + theta2_guess * x[1]def learn(learn_rate = 0.001,  variance = 0.00001):theta0_guess = 0theta1_guess = 0theta2_guess = 0diff = 10000dataSetCount = len(x_train)while (diff &gt; variance) :    sum0 = sum1 = sum2 = 0    for i in range(dataSetCount):        sum0 += (y_train[i] - h(x_train[i], theta0_guess, theta1_guess, theta2_guess))    for i in range(dataSetCount):        sum1 += (y_train[i] - h(x_train[i], theta0_guess, theta1_guess, theta2_guess)) * x_train[i][0]    for i in range(dataSetCount):        sum2 += (y_train[i] - h(x_train[i], theta0_guess, theta1_guess, theta2_guess)) * x_train[i][1]    theta0_guess += learn_rate * sum0    theta1_guess += learn_rate * sum1    theta2_guess += learn_rate * sum2    diff = 0    for i in range(dataSetCount):        diff += 1/2 * ((h(x_train[i], theta0_guess, theta1_guess, theta2_guess) - y_train[i]) ** 2)    plt.plot([h(x, theta0_guess, theta1_guess, theta2_guess) for x in x_train])return theta0_guess, theta1_guess, theta2_guessprint(learn())plt.show()输出结果如下：上述方法可实现收敛，但在针对大量数据的处理上性能差。批量梯度下降 每训练完一条数据，便更新值，这样可以只取其中一部分训练数据来训练，提高性能，但可能无法达到收敛。  正则方程组把训练数据集看成一个矩阵    且    得出    由性质  可得    使    推断出  python实例import numpy as npimport matplotlib.pyplot as pltx_train = np.matrix([[1, 1, 2], [1, 2, 1], [1, 2, 3], [1, 3, 5], [1, 1, 3], [1, 4, 2], [1, 7, 3], [1, 4, 5], [1, 11, 3], [1, 8, 7]])y_train = np.matrix([[7], [8], [10], [14], [8], [13], [20], [16], [28], [26]])def h(x, theta0_guess, theta1_guess, theta2_guess):    return theta0_guess + theta1_guess * x[1] + theta2_guess * x[2]def learn():    x_train_t = x_train.T    theta = (1 / (x_train_t * x_train)) * x_train_t * y_train    theta = np.asarray(theta).reshape(-1)    plot = []    for x in x_train:        x = np.asarray(x)[0]        plot.append(h(x, theta[0], theta[1], theta[2]))    plt.plot(plot)    plt.show()learn()"
                        } ,
                     
                        {
                          "title"    : "时间复杂度计算",
                          "category" : "",
                          "tags"     : " 算法",
                          "url"      : "/2016/11/13/time-complexity.html",
                          "date"     : "November 13, 2016",
                          "excerpt"  : "用大写O()来体现算法时间复杂度，称之为大O记法。推导大O阶1.用常数1取代运行时间中的所有加法常数。  2.在修改后的运行次数函数中，只保留最高阶项。  3.如果最高阶项存在且不是1，则去除与这个项相乘的常数。  4.得出大O阶。算法分析1.计算所有情况的平均值，称为平均时间复杂度2.计算最坏情况下的时间复杂度，称为最坏时间复杂度计算实例常数阶 O(1)int sum = 0, n = 100; /*执行一次*/sum = (1 + n) * n / 2; /*执行一次*/sum = (...",
                          "content"  : "用大写O()来体现算法时间复杂度，称之为大O记法。推导大O阶1.用常数1取代运行时间中的所有加法常数。  2.在修改后的运行次数函数中，只保留最高阶项。  3.如果最高阶项存在且不是1，则去除与这个项相乘的常数。  4.得出大O阶。算法分析1.计算所有情况的平均值，称为平均时间复杂度2.计算最坏情况下的时间复杂度，称为最坏时间复杂度计算实例常数阶 O(1)int sum = 0, n = 100; /*执行一次*/sum = (1 + n) * n / 2; /*执行一次*/sum = (1 + n) * n / 2; /*执行一次*/sum = (1 + n) * n / 2; /*执行一次*/sum = (1 + n) * n / 2; /*执行一次*/sum = (1 + n) * n / 2; /*执行一次*/sum = (1 + n) * n / 2; /*执行一次*/sum = (1 + n) * n / 2; /*执行一次*/printf(\"%d\", sum);线性阶 O(n)int sum = 0, n = 100, i;for(i = 0; i &lt; n; i++){    sum = (1 + n) * n / 2; /*执行一次*/}printf(\"%d\", sum);对数阶 O(logn)int count = 1;while(count &lt; n){    count = count * 2;}平方阶 O(n²)int i,j,sum = 0;for( i = 0; i &lt; n; i++){    for( j = iSS; j &lt; n; j++)    {        sum ++;    }}"
                        } ,
                     
                        {
                          "title"    : "排序",
                          "category" : "",
                          "tags"     : " 算法",
                          "url"      : "/2016/11/13/sort.html",
                          "date"     : "November 13, 2016",
                          "excerpt"  : "冒泡算法do  swapped = false  for i = 1 to indexOfLastUnsortedElement    if leftElement &gt; rightElement      swap(leftElement, rightElement)      swapped = truewhile swapped选择排序repeat (numOfElements - 1) times  set the first unsorted element as the m...",
                          "content"  : "冒泡算法do  swapped = false  for i = 1 to indexOfLastUnsortedElement    if leftElement &gt; rightElement      swap(leftElement, rightElement)      swapped = truewhile swapped选择排序repeat (numOfElements - 1) times  set the first unsorted element as the minimum  for each of the unsorted elements    if element &lt; currentMinimum      set element as new minimum  swap minimum with first unsorted position插入排序mark first element as sortedfor each unsorted element  'extract' the element  for i = lastSortedIndex to 0    if currentSortedElement &gt; extractedElement      move sorted element to the right by 1    else: insert extracted element归并排序split each element into partitions of size 1recursively merge adjancent partitions  for i = leftPartStartIndex to rightPartLastIndex inclusive    if leftPartHeadValue &lt;= rightPartHeadValue      copy leftPartHeadValue    else: copy rightPartHeadValuecopy elements back to original array统计排序create key (counting) arrayfor each element in list  increase the respective counter by 1for each counter, starting from smallest key  while counter is non-zero    restore element to list    decrease counter by 1基数排序create 10 buckets (queues) for each digit (0 to 9)for each digit placing  for each element in list    move element into respective bucket  for each bucket, starting from smallest digit    while bucket is non-empty      restore element to list"
                        } ,
                     
                        {
                          "title"    : "php实现session跨域",
                          "category" : "",
                          "tags"     : " php, session",
                          "url"      : "/2016/11/13/php-session.html",
                          "date"     : "November 13, 2016",
                          "excerpt"  : "session跨域在*.a.com上保存session，在客户端浏览器中会生成一个sessionID，作用范围仅仅是在a.com这个域名下，这个sessionID就是对应该服务器存储session文件的文件名，在用户打开浏览器访问a.com，浏览器会发送该sessionID去服务器找到该文件名，然后获取session。同服务器跨主域  由于sessionID只会在一个主域下面有效，所以要在另外一个域名下生成相应的sessionID。实现a.com&lt;?phpsession_start(...",
                          "content"  : "session跨域在*.a.com上保存session，在客户端浏览器中会生成一个sessionID，作用范围仅仅是在a.com这个域名下，这个sessionID就是对应该服务器存储session文件的文件名，在用户打开浏览器访问a.com，浏览器会发送该sessionID去服务器找到该文件名，然后获取session。同服务器跨主域  由于sessionID只会在一个主域下面有效，所以要在另外一个域名下生成相应的sessionID。实现a.com&lt;?phpsession_start();$ssid = session_id();$_SESSION['name'] = 'name';header('Location:http://www.b.com?ssid=' . $ssid);b.com&lt;?phpsession_id($_GET['ssid']);session_start();var_dump($_SESSION);这样就能在b.com域名下生成同样的sessionID，当然a.com和b.com找到是同个文件 有个问题： 如果传递不了sessionID，需要配置php.ini，让url支持或者使用p3p协议进行传输跨子域  只要设置session_set_cookie_params(1800 , ‘/’, ‘.a.com’);，就ok不同服务器跨主域  这个就比较蛋疼了，只能是把要设置session的参数传递到b.com，然后在该服务器下重新设置session，因为session文件在另外一台服务器不能被找到。跨子域  可以传递sessionID到b.com，然后生成相应的session文件，当然session文件内容也要传递过去。统一解决办法1.用两台服务器都能访问到的数据库服务器存储session  2.使用memcache"
                        } ,
                     
                        {
                          "title"    : "链表",
                          "category" : "",
                          "tags"     : " 数据结构",
                          "url"      : "/2016/11/13/link.html",
                          "date"     : "November 13, 2016",
                          "excerpt"  : "单链表查找temp = head, index = 0while (temp.data != input)  temp = temp.next , index++  if temp == null    return -1return index;插入  1.指定位置v = 90, k = 2Vertex temp1 = headwhile (--k!=0)  temp1 = temp1.nextVertex temp2 = temp1.nextVertex newVertex = new...",
                          "content"  : "单链表查找temp = head, index = 0while (temp.data != input)  temp = temp.next , index++  if temp == null    return -1return index;插入  1.指定位置v = 90, k = 2Vertex temp1 = headwhile (--k!=0)  temp1 = temp1.nextVertex temp2 = temp1.nextVertex newVertex = new Vertex(input)temp1.next = newVertexnewVertex.next = temp22.头部Vertex temp = new Vertex(input)temp.next = headhead = temp3.尾部Vertex temp = new Vertex(input)tail.next = temptail = temp删除  1.头部temp = headhead = head.nextdelete temp2.指定位置Vertex cur = headwhile (--k!=0)  cur = cur.nextVertex tobedeleted = cur.nextcur.next = cur.next.nextdelete tobedeleted3.尾部Vertex prev = headtemp = head.nextwhile (temp.next!=null)  temp = temp.next , prev = prev.nextprev.next = nulldelete temptail = prev堆栈插入Vertex temp = new Vertex(input)temp.next = headhead = temp取出temp = headhead = head.nextdelete temp队列入列Vertex temp = new Vertex(input)tail.next = temptail = temp出列temp = headhead = head.nextdelete temp双链表查找temp = head, index = 0while (temp.data != input)  temp = temp.next , index++  if temp == null    return -1return index;插入  1.指定位置Vertex temp1 = headwhile (--k!=0)  temp1 = temp1.nextVertex temp2 = temp1.nextVertex newVertex = new Vertex(input)newVertex.next = temp2 , temp2.prev = newVertextemp1.next = newVertex , newVertex.prev = temp12.头部Vertex temp = new Vertex(input)temp.next = headif (head!=null) head.prev = temphead = temp3.尾部Vertex temp = new Vertex(input)tail.next = temptemp.prev = tailtail = temp删除  1.头部temp = headhead = head.nextdelete tempif(head!=null) head.prev = null2.指定位置Vertex cur = headwhile (--k!=0)  cur = cur.nextVertex tobedeleted = cur.nextVertex temp = tobedeleted.nextdelete tobedeletedcur.next = temp, temp.prev = cur3.尾部temp = tailtail = tail.prevtail.next = nulldelete temp双端队列入列  1.头部Vertex temp = new Vertex(input)temp.next = headif (head!=null) head.prev = temphead = temp2.尾部Vertex temp = new Vertex(input)tail.next = temptemp.prev = tailtail = temp出列  1.头部temp = headhead = head.nextdelete tempif(head!=null) head.prev = null2.尾部temp = tailtail = tail.prevtail.next = nulldelete temp"
                        } ,
                     
                        {
                          "title"    : "jsonp实现异步请求跨域",
                          "category" : "",
                          "tags"     : " jsonp",
                          "url"      : "/2016/11/13/jsonp.html",
                          "date"     : "November 13, 2016",
                          "excerpt"  : "ajax 和 jsonp的区别  ajax是通过XmlHttpRequest来获取非本页内容，而jsonp是通过动态添加为什么jsonp能够跨服  因为在web调用js文件是不受跨服影响的，不仅如此，凡是拥有src属性的都有跨服的能力。实现一www.b.com/remote.jsalert(1)www.a.com/json.html&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www...",
                          "content"  : "ajax 和 jsonp的区别  ajax是通过XmlHttpRequest来获取非本页内容，而jsonp是通过动态添加为什么jsonp能够跨服  因为在web调用js文件是不受跨服影响的，不仅如此，凡是拥有src属性的都有跨服的能力。实现一www.b.com/remote.jsalert(1)www.a.com/json.html&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt; &lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;&lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;script type=\"text/javascript\" src=\"http://remoteserver.com/remote.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;实例二现在我们在jsonp.html页面定义一个函数，然后在远程remote.js中传入数据进行调用。  www.a.com/json.html&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;&lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;script type=\"text/javascript\"&gt;var localHandler = function(data){alert('我是本地函数，可以被跨域的remote.js文件调用，远程js带来的数据是：' + data.result);};&lt;/script&gt;&lt;script type=\"text/javascript\" src=\"http://remoteserver.com/remote.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;www.b.com/remote.jslocalHandler({\"result\":\"我是远程js带来的数据\"});实现三使用callback  www.a.com/json.html&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;&lt;head&gt;&lt;title&gt;&lt;/title&gt;&lt;script type=\"text/javascript\"&gt;// 得到航班信息查询结果后的回调函数var flightHandler = function(data){    alert('你查询的航班结果是：票价 ' + data.price + ' 元，' + '余票 ' + data.tickets + ' 张。');};// 提供jsonp服务的url地址（不管是什么类型的地址，最终生成的返回值都是一段javascript代码）var url = \"http://www.b.com/json.php?callback=flightHandler\";// 创建script标签，设置其属性var script = document.createElement('script');script.setAttribute('src', url);// 把script标签加入head，此时调用开始document.getElementsByTagName('head')[0].appendChild(script);&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;www.b.com/json.php&lt;?phpecho $_GET['callback'] . '(' . json_encode(1) . ')';exit;####实例四 使用jquery&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" &gt;&lt;head&gt;&lt;title&gt;Untitled Page&lt;/title&gt;&lt;script type=\"text/javascript\" src=\"jquery.min.js\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\"&gt;jQuery(document).ready(function(){    $.ajax({        type: \"get\",        async: false,        url: \"http://www.b.com/jsonp.php\",        dataType: \"jsonp\",        jsonp: \"callback\",//传递给请求处理程序或页面的，用以获得jsonp回调函数名的参数名(一般默认为:callback)        jsonpCallback:\"flightHandler\",//自定义的jsonp回调函数名称，默认为jQuery自动生成的随机函数名，也可以写\"?\"，jQuery会自动为你处理数据        success: function(json){            alert('您查询到航班信息：票价： ' + json.price + ' 元，余票： ' + json.tickets + ' 张。');        },        error: function(){            alert('fail');        }    });});&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;"
                        } ,
                     
                        {
                          "title"    : "哈希表",
                          "category" : "",
                          "tags"     : " 数据结构",
                          "url"      : "/2016/11/13/hash-table.html",
                          "date"     : "November 13, 2016",
                          "excerpt"  : "线性探查查找i = base = key%HT.length // get hashed indexwhile (true)  if (HT[i] == EMPTY) return \"not found\"  else if (HT[i] == key) return \"found at index i\"  else i = (base+step*1)%HT.length插入if HT is 1 item before full, prevent insertioni = base ...",
                          "content"  : "线性探查查找i = base = key%HT.length // get hashed indexwhile (true)  if (HT[i] == EMPTY) return \"not found\"  else if (HT[i] == key) return \"found at index i\"  else i = (base+step*1)%HT.length插入if HT is 1 item before full, prevent insertioni = base = key%HT.length // get hashed indexwhile (HT[i] != EMPTY || HT[i] != DELETED)  i = (base+step*1)%HT.lengthfound insertion point, insert key at HT[i]删除i = base = key%HT.length // get hashed indexwhile (true)  if (HT[i] == EMPTY) break // key not found  else if (HT[i] == key)    HT[i] = DELETED  else i = (base+step*1)%HT.length二次探查查找i = base = key%HT.length // get hashed indexwhile (true)  if (HT[i] == EMPTY) return \"not found\"  else if (HT[i] == key) return \"found at index i\"  else i = (base+step*step)%HT.length插入if HT is 1 item before full, prevent insertioni = base = key%HT.length // get hashed indexwhile (HT[i] != EMPTY || HT[i] != DELETED)  i = (base+step*step)%HT.lengthfound insertion point, insert key at HT[i]删除i = base = key%HT.length // get hashed indexwhile (true)  if (HT[i] == EMPTY) break // key not found  else if (HT[i] == key)    HT[i] = DELETED  else i = (base+step*step)%HT.length"
                        } ,
                     
                        {
                          "title"    : "位运算",
                          "category" : "",
                          "tags"     : " 算法",
                          "url"      : "/2016/11/13/bit-cal.html",
                          "date"     : "November 13, 2016",
                          "excerpt"  : "以S = 1001011,j = 0000000为例。获取第 i 标志位j = 0000001(shift left j) * iS AND j切换第 i 标志位j = 0000001(shift left j) * iS XOR j(XOR: 11 = 0 10 = 1 01 = 1 00 = 0)清除第 i 标志位j = 0000001(shift left j) * iinvert j(反转)S AND j获取最后一个有效位j = NOT(S)+1S AND jS = 1001011...",
                          "content"  : "以S = 1001011,j = 0000000为例。获取第 i 标志位j = 0000001(shift left j) * iS AND j切换第 i 标志位j = 0000001(shift left j) * iS XOR j(XOR: 11 = 0 10 = 1 01 = 1 00 = 0)清除第 i 标志位j = 0000001(shift left j) * iinvert j(反转)S AND j获取最后一个有效位j = NOT(S)+1S AND jS = 1001011j = 0000000获取第 i 标志位j = 0000001(shift left j) * iS AND j切换第 i 标志位j = 0000001(shift left j) * iS XOR j(XOR: 11 = 0 10 = 1 01 = 1 00 = 0)清除第 i 标志位j = 0000001(shift left j) * iinvert j(反转)S AND j获取最后一个有效位j = NOT(S)+1S AND jS = 1001011j = 0000000获取第 i 标志位j = 0000001(shift left j) * iS AND j切换第 i 标志位j = 0000001(shift left j) * iS XOR j(XOR: 11 = 0 10 = 1 01 = 1 00 = 0)清除第 i 标志位j = 0000001(shift left j) * iinvert j(反转)S AND j获取最后一个有效位j = NOT(S)+1S AND jS = 1001011j = 0000000获取第 i 标志位j = 0000001(shift left j) * iS AND j切换第 i 标志位j = 0000001(shift left j) * iS XOR j(XOR: 11 = 0 10 = 1 01 = 1 00 = 0)清除第 i 标志位j = 0000001(shift left j) * iinvert j(反转)S AND j获取最后一个有效位j = NOT(S)+1S AND j"
                        } ,
                     
                        {
                          "title"    : "php实现异步",
                          "category" : "",
                          "tags"     : " php",
                          "url"      : "/2016/11/12/php-async.html",
                          "date"     : "November 12, 2016",
                          "excerpt"  : "php在处理异步执行主要有以下四种方式来处理，其中第四种方式是最好的，推荐使用。1.ajax或嵌入img标签，在src中指向异步地址。  缺点 不能算是真正异步，主要用户关闭浏览器，异步脚本也就被终止掉了&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;img src=\"b.php\"&gt; &lt;script src=\"jquery.js\"&gt;&lt;/script&gt;&lt;script&gt;$(documen...",
                          "content"  : "php在处理异步执行主要有以下四种方式来处理，其中第四种方式是最好的，推荐使用。1.ajax或嵌入img标签，在src中指向异步地址。  缺点 不能算是真正异步，主要用户关闭浏览器，异步脚本也就被终止掉了&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;img src=\"b.php\"&gt; &lt;script src=\"jquery.js\"&gt;&lt;/script&gt;&lt;script&gt;$(document).ready(function(){    $.ajax({url:\"b.php\",async:false});});    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;2.popen  缺点 只能在命令行中执行本地脚本，如果访问量高，会产生大量进程pclose(popen(\"php -f /Users/zhongjunbin/Document/Kitematic/nginx/htdocs/b.php &amp;\", 'r'));3.curl  缺点 会有至少一秒的等待时间$ch = curl_init();$curl_opt = array(CURLOPT_URL, 'http://www.example.com/backend.php',                            CURLOPT_RETURNTRANSFER, 1,                            CURLOPT_TIMEOUT, 1,);curl_setopt_array($ch, $curl_opt);4.fsockopen 或 socker_stream_client  缺点 需要自己拼接http头信息&lt;?php$fp = fsockopen(\"192.168.99.100\", 80, $errno, $errstr, 30);if (!$fp) {    echo \"$errstr ($errno)&lt;br /&gt;\n\";} else {    $out = \"GET /b.php HTTP/1.1\r\n\";    $out .= \"Host: 192.168.99.100\r\n\";    $out .= \"Connection: Close\r\n\r\n\";    fwrite($fp, $out);    /*忽略执行结果    while (!feof($fp)) {        echo fgets($fp, 128);    }*/    fclose($fp);}&lt;?php$fp = stream_socket_client(\"192.168.99.100:80\", $errno, $errstr, 30);if (!$fp) {    echo \"$errstr ($errno)&lt;br /&gt;\n\";} else {    fwrite($fp, \"GET /b.php HTTP/1.0\r\nHost: 192.168.99.100\r\nAccept: */*\r\n\r\n\");    /*忽略执行结果    while (!feof($fp)) {         echo fgets($fp, 1024);    }*/    fclose($fp);}"
                        } ,
                     
                        {
                          "title"    : "NGINX+PHP运行原理",
                          "category" : "",
                          "tags"     : " php, nginx",
                          "url"      : "/2016/11/11/php-nginx.html",
                          "date"     : "November 11, 2016",
                          "excerpt"  : "前向代理与反向代理前向代理作为客户端的代理，将从互联网上获取的资源返回给一个或多个的客户端，服务器端（如Web服务器）只知道代理的IP地址而不知道客户端的IP地址。而反向代理是作为服务器端（如Web服务器）的代理使用，而不是客户端。客户端借由前向代理可以间接访问很多不同互联网服务器（簇）的资源，而反向代理是供很多客户端都通过它间接访问不同后端服务器上的资源，而不需要知道这些后端服务器的存在，而以为所有资源都来自于这个反向代理服务器。CGI通用网关接口（Common Gateway Inte...",
                          "content"  : "前向代理与反向代理前向代理作为客户端的代理，将从互联网上获取的资源返回给一个或多个的客户端，服务器端（如Web服务器）只知道代理的IP地址而不知道客户端的IP地址。而反向代理是作为服务器端（如Web服务器）的代理使用，而不是客户端。客户端借由前向代理可以间接访问很多不同互联网服务器（簇）的资源，而反向代理是供很多客户端都通过它间接访问不同后端服务器上的资源，而不需要知道这些后端服务器的存在，而以为所有资源都来自于这个反向代理服务器。CGI通用网关接口（Common Gateway Interface/CGI）是一种重要的互联网技术，可以让一个客户端，从网页浏览器向执行在网络服务器上的程序请求数据。CGI描述了服务器和请求处理程序之间传输数据的一种标准。CGI程序可以用任何脚本语言或者是完全独立编程语言实现，只要这个语言可以在这个系统上运行。除Perl外，像Unix shell script, Python, Ruby, PHP, Tcl, C/C++,和Visual Basic都可以用来编写CGI程序。工作方式  从Web服务器的角度看，是在特定的位置（比如：http://www.example.com/wiki.cgi）定义了可以运行CGI程序。当收到一个匹配URL的请求，相应的程序就会被调用，并将客户端发送的数据作为输入。程序的输出会由Web服务器收集，并加上合适的档头，再发送回客户端。缺点  一般每次的CGI请求都需要新生成一个程序的副本来运行，这样大的工作量会很快将服务器压垮，因此一些更有效的技术像mod_php，可以让脚本解释器直接作为模块集成在Web服务器（例如：Apache）中，这样就能避免重复载入和初始化解释器。不过这只是就那些需要解释器的高级语言（即解释语言）而言的，使用诸如C一类的编译语言则可以避免这种额外负荷。由于C及其他编译语言的程序与解释语言程序相比，前者的运行速度更快、对操作系统的负荷更小，使用编译语言程序是可能达到更高执行效率的，然而因为开发效率等原因，在目前直译性语言还是最合适的。FAST-CGI快速通用网关接口（Fast Common Gateway Interface／FastCGI）是一种让交互程序与Web服务器通信的协议。FastCGI是早期通用网关接口（CGI）的增强版本。  FastCGI致力于减少网页服务器与CGI程序之间交互的开销，从而使服务器可以同时处理更多的网页请求。CGI使外部程序与Web服务器之间交互成为可能。CGI程序运行在独立的进程中，并对每个Web请求创建一个进程，这种方法非常容易实现，但效率很差，难以扩展。面对大量请求，进程的大量创建和消亡使操作系统性能大大下降。此外，由于地址空间无法共享，也限制了资源重用。与为每个请求创建一个新的进程不同，FastCGI使用持续的进程来处理一连串的请求。这些进程由FastCGI服务器管理，而不是web服务器。 当进来一个请求时，web服务器把环境变量和这个页面请求通过一个socket比如FastCGI进程与web服务器（都位于本地）或者一个TCP connection（FastCGI进程在远端的server farm）传递给FastCGI进程。PHP-FPM全称php-Fastcgi Process Manager，是对FastCGI的实现，并提供了进程管理的功能。进程包含 master 进程和 worker 进程两种进程。master 进程只有一个，负责监听端口，接收来自 Web Server 的请求，而 worker 进程则一般有多个(具体数量根据实际需要配置)，每个进程内部都嵌入了一个 PHP 解释器，是 PHP 代码真正执行的地方。执行流程Nginx 不仅仅是一个 Web 服务器，也是一个功能强大的 Proxy 服务器，除了进行 http 请求的代理，也可以进行许多其他协议请求的代理，包括本文与 fpm 相关的 fastcgi 协议。为了能够使 Nginx 理解 fastcgi 协议，Nginx 提供了 fastcgi 模块来将 http 请求映射为对应的 fastcgi 请求。Nginx 的 fastcgi 模块提供了 fastcgi_param 指令来主要处理这些映射关系，下面 Ubuntu 下 Nginx 的一个配置文件，其主要完成的工作是将 Nginx 中的变量翻译成 PHP 中能够理解的变量。Nginx 的 fastcgi 模块提供了 fastcgi_param 指令来主要处理这些映射关系，下面 Ubuntu 下 Nginx 的一个配置文件，其主要完成的工作是将 Nginx 中的变量翻译成 PHP 中能够理解的变量。fastcgi_param  QUERY_STRING       $query_string;fastcgi_param  REQUEST_METHOD     $request_method;fastcgi_param  CONTENT_TYPE       $content_type;fastcgi_param  CONTENT_LENGTH     $content_length;fastcgi_param  SCRIPT_NAME        $fastcgi_script_name;fastcgi_param  REQUEST_URI        $request_uri;fastcgi_param  DOCUMENT_URI       $document_uri;fastcgi_param  DOCUMENT_ROOT      $document_root;fastcgi_param  SERVER_PROTOCOL    $server_protocol;fastcgi_param  REQUEST_SCHEME     $scheme;fastcgi_param  HTTPS              $https if_not_empty;fastcgi_param  GATEWAY_INTERFACE  CGI/1.1;fastcgi_param  SERVER_SOFTWARE    nginx/$nginx_version;fastcgi_param  REMOTE_ADDR        $remote_addr;fastcgi_param  REMOTE_PORT        $remote_port;fastcgi_param  SERVER_ADDR        $server_addr;fastcgi_param  SERVER_PORT        $server_port;fastcgi_param  SERVER_NAME        $server_name;# PHP only, required if PHP was built with --enable-force-cgi-redirectfastcgi_param  REDIRECT_STATUS    200;除此之外，非常重要的就是 fastcgi_pass 指令了，这个指令用于指定 fpm 进程监听的地址，Nginx 会把所有的 php 请求翻译成 fastcgi 请求之后再发送到这个地址。下面一个简单的可以工作的 Nginx 配置文件：server {    listen       80; #监听80端口，接收http请求    server_name  www.example.com; #就是网站地址    root /usr/local/etc/nginx/www/huxintong_admin; # 准备存放代码工程的路径    #路由到网站根目录www.example.com时候的处理    location / {        index index.php; #跳转到www.example.com/index.php        autoindex on;    }       #当请求网站下php文件的时候，反向代理到php-fpm    location ~ \.php$ {        include /usr/local/etc/nginx/fastcgi.conf; #加载nginx的fastcgi模块        fastcgi_intercept_errors on;        fastcgi_pass   127.0.0.1:9000; #这个指令用于指定 fpm 进程监听的地址，Nginx 会把所有的 php 请求翻译成 fastcgi 请求之后再发送到这个地址    }}具体流程如下： graph TD;    www.example.com--&gt;Nginx    Nginx--&gt;路由到www.example.com/index.php    路由到www.example.com/index.php--&gt;加载nginx的fast-cgi模块    加载nginx的fast-cgi模块--&gt;发送到127.0.0.1:9000地址    发送到127.0.0.1:9000地址--&gt;PHP-FPM监听到发送到这个端口的请求    PHP-FPM监听到发送到这个端口的请求--&gt;等待处理参考链接代理服务器-wiki  反向代理-wiki  通用网关接口-wiki  FastCGI-wiki  Nginx+Php-fpm运行原理详解  深入理解PHP之：Nginx 与 FPM 的工作机制"
                        } 
                     ,
                     
                       {
                         
                            "title"    : "Ninja",
                            "category" : "",
                            "tags"     : " Lorem",
                            "url"      : "/portfolio/ninja",
                            "date"     : "April 8, 2014",
                            "excerpt"  : "",
                            "content"  : "Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"
                         
                       } ,
                     
                       {
                         
                            "title"    : "Creative",
                            "category" : "",
                            "tags"     : " Ipsum",
                            "url"      : "/portfolio/safe",
                            "date"     : "August 16, 2014",
                            "excerpt"  : "",
                            "content"  : "Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?Use this area of the page to describe your project. The icon above is part of a free icon set by Flat Icons. On their website, you can download their free set with 16 icons, or you can purchase the entire set with 146 icons for only $12!"
                         
                       } ,
                     
                       {
                         
                            "title"    : "Circus",
                            "category" : "",
                            "tags"     : " Ipsum",
                            "url"      : "/portfolio/circus",
                            "date"     : "September 1, 2014",
                            "excerpt"  : "",
                            "content"  : "Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"
                         
                       } ,
                     
                       {
                         
                            "title"    : "Tower of Hanoi",
                            "category" : "",
                            "tags"     : " ",
                            "url"      : "/portfolio/hanoi",
                            "date"     : "September 1, 2014",
                            "excerpt"  : "",
                            "content"  : "Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"
                         
                       } ,
                     
                       {
                         
                            "title"    : "Tic tac toe",
                            "category" : "",
                            "tags"     : " ",
                            "url"      : "/portfolio/tictactoe",
                            "date"     : "September 1, 2014",
                            "excerpt"  : "",
                            "content"  : "Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"
                         
                       } ,
                     
                       {
                         
                            "title"    : "Cake",
                            "category" : "",
                            "tags"     : " Lorem, Ipsum, Portfolio",
                            "url"      : "/portfolio/cake",
                            "date"     : "September 27, 2015",
                            "excerpt"  : "",
                            "content"  : "Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?Use this area of the page to describe your project. The icon above is part of a free icon set by Flat Icons. On their website, you can download their free set with 16 icons, or you can purchase the entire set with 146 icons for only $12!"
                         
                       } ,
                     
                       {
                         
                            "title"    : "Jekyll",
                            "category" : "",
                            "tags"     : " ",
                            "url"      : "/portfolio/jekyllblog",
                            "date"     : "May 26, 2017",
                            "excerpt"  : "",
                            "content"  : "Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"
                         
                       } ,
                     
                       {
                         
                            "title"    : "Lorem Ipsum",
                            "category" : "",
                            "tags"     : " ",
                            "url"      : "/portfolio/submarine",
                            "date"     : "September 3, 2017",
                            "excerpt"  : "",
                            "content"  : "Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?Use this area of the page to describe your project. The icon above is part of a free icon set by Flat Icons. On their website, you can download their free set with 16 icons, or you can purchase the entire set with 146 icons for only $12!"
                         
                       } ,
                     
                       {
                         
                            "title"    : "Github",
                            "category" : "",
                            "tags"     : " Lorem, Portfolio",
                            "url"      : "/portfolio/gitlecture",
                            "date"     : "October 20, 2017",
                            "excerpt"  : "",
                            "content"  : "Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?"
                         
                       } 
                     
                    
                  ],
            searchResultTemplate: '<div class="search-title"><a href="{url}"><h3> {title}</h3></a><div class="meta">{date} <div class="right"><i class="fa fa-tag"></i> {tags}</div></div><p>{excerpt}</p></div><hr> ',
            noResultsText: 'No results found',
            limit: 10,
            fuzzy: false,
            exclude: []
        })
    </script>
</section>
</section>
    
    
  <!-- Tag list for portfolio -->
  
  


<footer>
  <div class="tag-list"></div>
</footer>

    
</article>

    </div>
    
<footer class="site-footer">
    <p class="text">Powered by <a href="https://jekyllrb.com/">Jekyll</a> with <a href="https://github.com/sylhare/Type-on-Strap">Type on Strap</a>
</p>
            <div class="footer-icons">
                <ul>
                <!-- Social icons from Font Awesome, if enabled -->
                
<li>
	<a href="http://localhost:4000/feed.xml" title="Follow RSS feed">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>















<li>
	<a href="https://github.com/shadowdragons" title="Follow on GitHub">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-github fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>
































                </ul>
            </div>
</footer>




  </body>
</html>
